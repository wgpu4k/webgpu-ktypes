"GPUBindingResource": |
  Represents a binding resource in the WebGPU API. This sealed interface can be one of several types:
  - [GPUSampler]
  - [GPUTextureView]
  - [GPUBufferBinding]
  - [GPUExternalTexture]
  
  This interface is used to specify the type of resource that can be bound in a bind group. 
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#typedefdef-gpubindingresource).
"GPUBufferBinding": |
  The `GPUBufferBinding` interface describes a buffer and an optional range to bind as a resource. This is used in the context of WebGPU to specify how buffers should be bound for shader access.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpubufferbinding).
"GPUBufferBinding#buffer": |
  The `buffer` property specifies the `GPUBuffer` to bind. This buffer will be exposed to shaders as a resource.
"GPUBufferBinding#offset": |
  The `offset` property specifies the offset, in bytes, from the beginning of the `buffer` to the start of the range exposed to the shader by the buffer binding. This value defaults to 0 if not specified.
"GPUBufferBinding#size": |
  The `size` property specifies the size, in bytes, of the buffer binding. If not provided, it specifies the range starting at `offset` and ending at the end of the `buffer`.
"GPUColor": |
  Represents a color in the RGBA format, which can be either a sequence of four `Double` values or a [GPUColorDict]. This interface provides access to the red, green, blue, and alpha channel values.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#gpucolor).
"GPUColor#r": |
  The red channel value of the color. This value is a `Double` representing the intensity of the red component in the RGBA color model.
"GPUColor#g": |
  The green channel value of the color. This value is a `Double` representing the intensity of the green component in the RGBA color model.
"GPUColor#b": |
  The blue channel value of the color. This value is a `Double` representing the intensity of the blue component in the RGBA color model.
"GPUColor#a": |
  The alpha channel value of the color. This value is a `Double` representing the opacity of the color, where 0.0 means fully transparent and 1.0 means fully opaque.
"GPUOrigin2D": |
  Represents a 2D origin point in GPU coordinates. This interface can be used to specify the starting point for various GPU operations, such as texture sampling or buffer updates.
  
  The `GPUOrigin2D` type is defined as either a sequence of two values or a dictionary with `x` and `y` properties. This allows for flexible initialization and usage in different contexts.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#gpuorigin2d).
"GPUOrigin2D#x": |
  The x-coordinate of the origin point. This value is of type `GPUIntegerCoordinate`.
  
  When using a sequence to represent `GPUOrigin2D`, this property refers to the first item in the sequence. If the sequence does not contain an item, the default value of 0 is used.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpuorigin2ddict-x).
"GPUOrigin2D#y": |
  The y-coordinate of the origin point. This value is of type `GPUIntegerCoordinate`.
  
  When using a sequence to represent `GPUOrigin2D`, this property refers to the second item in the sequence. If the sequence does not contain an item, the default value of 0 is used.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpuorigin2ddict-y).
"GPUOrigin3D": |
  Represents a 3D origin point in GPU coordinates. This interface can be used to specify the starting point for various GPU operations, such as texture sampling or buffer updates.
  
  The `GPUOrigin3D` type can be either a sequence of three [GPUIntegerCoordinate] values or an instance of [GPUOrigin3DDict]. When accessed, the properties `x`, `y`, and `z` will refer to the corresponding values in the sequence or dictionary.
  
  For more details, see the [WebGPU specification](https://www.w3.org/TR/webgpu/#gpuorigin3d).
"GPUOrigin3D#x": |
  The x-coordinate of the 3D origin point. This value is either the first item in a sequence of [GPUIntegerCoordinate] values or the `x` property of a [GPUOrigin3DDict].
"GPUOrigin3D#y": |
  The y-coordinate of the 3D origin point. This value is either the second item in a sequence of [GPUIntegerCoordinate] values or the `y` property of a [GPUOrigin3DDict].
"GPUOrigin3D#z": |
  The z-coordinate of the 3D origin point. This value is either the third item in a sequence of [GPUIntegerCoordinate] values or the `z` property of a [GPUOrigin3DDict].
"GPUObjectBase": |
  The `GPUObjectBase` interface is a mixin that provides a common base for all WebGPU objects. It includes properties such as a label, which can be used to identify the object in debugging and error messages.
  
  This interface is fundamental to the WebGPU API as it ensures that all WebGPU objects share a consistent set of properties and behaviors. The `label` property allows developers to assign meaningful names to their WebGPU objects, making it easier to debug and manage them.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#gpuobjectbase).
"GPUObjectBase#label": |
  A developer-provided label which is used in an implementation-defined way. It can be utilized by the browser, OS, or other tools to help identify the underlying internal object to the developer.
  
  This property is particularly useful for debugging purposes as it allows developers to assign meaningful names to their WebGPU objects. These labels can then be displayed in error messages, console warnings, and various debugging utilities.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpuobjectbase-label).
"GPUCompilationMessage": |
  The `GPUCompilationMessage` interface represents an informational, warning, or error message generated by the [GPUShaderModule] compiler. These messages are designed to be human-readable and assist developers in diagnosing issues with their shader code. Each message can correspond to a specific point in the shader code, a substring of the shader code, or may not correspond to any specific point at all.
  
  See also: [W3C Specification](https://www.w3.org/TR/webgpu/#dom-gpucompilationmessage)
"GPUCompilationMessage#message": |
  A human-readable string that describes the compilation message. This attribute provides detailed information about the issue, warning, or informational note generated during shader compilation.
  
  See also: [W3C Specification](https://www.w3.org/TR/webgpu/#dom-gpucompilationmessage-message)
"GPUCompilationMessage#type": |
  The type of the compilation message, which can be one of the following values from the `GPUCompilationMessageType` enum: "error", "warning", or "info". This attribute helps in categorizing the severity and nature of the message.
  
  See also: [W3C Specification](https://www.w3.org/TR/webgpu/#dom-gpucompilationmessage-type)
"GPUCompilationMessage#lineNum": |
  The line number within the shader code where the message originates. This attribute is an `ULong` value representing the zero-based index of the line.
  
  See also: [W3C Specification](https://www.w3.org/TR/webgpu/#dom-gpucompilationmessage-linenum)
"GPUCompilationMessage#linePos": |
  The position within the line where the message originates. This attribute is an `ULong` value representing the zero-based index of the character position.
  
  See also: [W3C Specification](https://www.w3.org/TR/webgpu/#dom-gpucompilationmessage-linepos)
"GPUCompilationMessage#offset": |
  The byte offset within the shader code where the message originates. This attribute is an `ULong` value representing the zero-based index of the byte.
  
  See also: [W3C Specification](https://www.w3.org/TR/webgpu/#dom-gpucompilationmessage-offset)
"GPUCompilationMessage#length": |
  The length in bytes of the substring within the shader code that the message refers to. This attribute is an `ULong` value representing the number of bytes.
  
  See also: [W3C Specification](https://www.w3.org/TR/webgpu/#dom-gpucompilationmessage-length)
"GPUCompilationInfo": |
  Represents the compilation information for a GPU shader module. This interface provides access to messages generated during the compilation process, which can be useful for debugging and optimization.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/).
"GPUCompilationInfo#messages": |
  A list of [GPUCompilationMessage] objects that contain detailed information about the compilation process. These messages can include warnings and errors that occurred during the compilation of a shader module.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#gpucompilationinfo).
"GPUPipelineBase": |
  The `GPUPipelineBase` interface represents the base class for GPU pipelines in WebGPU. It provides a method to retrieve bind group layouts, which are essential for configuring resources used by shaders.
  
  This interface is part of the WebGPU API and is designed to be implemented by specific pipeline types such as compute pipelines or render pipelines.
"GPUPipelineBase#getBindGroupLayout(index)": |
  Retrieves a `GPUBindGroupLayout` object at the specified index from the pipeline.
  
  **Parameters:**
  - `index`: A `UInt` representing the index of the bind group layout to retrieve. This value must be within the range of valid indices for the pipeline's bind group layouts.
  
  **Returns:**
  - A `GPUBindGroupLayout` object that describes the bindings for a specific set of resources used by the shader stages in the pipeline.
  
  This method is crucial for setting up resource bindings that shaders will use during execution. The `GPUBindGroupLayout` objects define how resources are bound to the pipeline, including buffers, textures, and samplers.
  
  **See also:**
  - [WebGPU Specification: GPUPipelineBase](https://www.w3.org/TR/webgpu/#gpupipelinebase)
"GPUBindingCommandsMixin": |
  The `GPUBindingCommandsMixin` interface extends the functionality of GPU command objects by providing methods to set bind groups. This mixin assumes the presence of `GPUObjectBase` and `GPUCommandsMixin` members on the same object.
  
  It includes device timeline properties for managing bind groups and dynamic offsets, which are essential for configuring the rendering pipeline in WebGPU.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#gpubindingcommandsmixin).
"GPUBindingCommandsMixin#setBindGroup(index, bindGroup, dynamicOffsetsData)": |
  Sets a bind group for a specific index in the rendering pipeline.
  
  @param index The index at which to set the bind group. This must be a valid `GPUIndex32` value.
  @param bindGroup The `GPUBindGroup` to set at the specified index. If `null`, the bind group at the specified index is unset.
  @param dynamicOffsetsData A list of unsigned integers representing dynamic offsets for the bind group. This parameter is optional and defaults to an empty list.
  
  This method updates the internal state of the command encoder to include the specified bind group and dynamic offsets at the given index. The `bind_group` parameter allows for flexible binding configurations, enabling efficient resource management in the rendering pipeline.
  
  For more information, see the [WebGPU specification on GPUBindingCommandsMixin](https://www.w3.org/TR/webgpu/#gpubindingcommandsmixin).
"GPURenderBundleEncoder": |
  The `GPURenderBundleEncoder` interface represents an encoder for creating render bundles in WebGPU. A render bundle is a collection of rendering commands that can be executed multiple times with different parameters, improving performance by reducing the overhead of command encoding.
  
  This interface inherits from several mixins and interfaces:
  - [GPUObjectBase]: Provides basic object properties such as `label`.
  - [GPUCommandsMixin]: Mixin for common GPU commands.
  - [GPUDebugCommandsMixin]: Mixin for debug-related commands.
  - [GPUBindingCommandsMixin]: Mixin for binding-related commands.
  - [GPURenderCommandsMixin]: Mixin for render-related commands.
  - [AutoCloseable]: Ensures that resources are closed properly.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/).
"GPURenderBundleEncoder#finish(descriptor)": |
  Encodes the render commands into a `GPURenderBundle` and finalizes the encoder.
  
  **Parameters:**
  - `descriptor`: An optional `GPURenderBundleDescriptor` that specifies additional parameters for creating the render bundle. If not provided, default values are used.
  
  **Returns:**
  - A `GPURenderBundle` object containing the encoded render commands.
  
  **See also:**
  - [WebGPU Specification: finish](https://www.w3.org/TR/webgpu/#dom-gpurenderbundleencoder-finish)
"GPUDeviceLostInfo": |
  Represents information about why a [GPUDevice](https://www.w3.org/TR/webgpu/#gpudevice) was lost. This interface provides details that can help developers understand the cause of device loss and take appropriate actions.
  
  **See also:**
  - [WebGPU Specification: GPUDeviceLostInfo](https://www.w3.org/TR/webgpu/#gpudevicelostinfo)
"GPUDeviceLostInfo#reason": |
  The reason why the GPU device was lost. This is an instance of [GPUDeviceLostReason](https://www.w3.org/TR/webgpu/#enumdef-gpudevicelostreason), which enumerates possible causes for device loss.
  
  **See also:**
  - [WebGPU Specification: GPUDeviceLostInfo.reason](https://www.w3.org/TR/webgpu/#dom-gpudevicelostinfo-reason)
"GPUDeviceLostInfo#message": |
  A message providing additional information about why the GPU device was lost. This string is implementation-defined and should not be parsed by applications.
  
  **Important:**
  The message may contain sensitive information and should be handled with care. It is intended for debugging purposes and should not be displayed to end-users without proper sanitization.
  
  **See also:**
  - [WebGPU Specification: GPUDeviceLostInfo.message](https://www.w3.org/TR/webgpu/#dom-gpudevicelostinfo-message)
"GPUValidationError": |
  A subtype of [GPUError] that indicates an operation did not satisfy all validation requirements. Validation errors are always indicative of an application error and are expected to fail the same way across all devices, assuming the same [[features]] and [[limits]] are in use.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#gpuvalidationerror).
  
  In this example, if an operation on the `GPUDevice` fails due to a validation error, it will be caught by the `catch` block, and the error message will be printed.
"GPUOutOfMemoryError": |
  Represents a subtype of GPUError that indicates an out-of-memory condition. This error occurs when there is insufficient free memory to complete the requested operation.
  
  The operation may succeed if attempted again with a lower memory requirement (e.g., using smaller texture dimensions), or if memory used by other resources is released first.
  
  **See Also:**
  - [GPUError](https://www.w3.org/TR/webgpu/#gpuerror)
"GPUInternalError": |
  A subtype of GPUError that indicates an operation failed for a system or implementation-specific reason, even when all validation requirements have been satisfied. This error may occur if the operation exceeds the capabilities of the implementation in ways not easily captured by the supported limits.
  
  For example, the same operation might succeed on other devices or under different circumstances.
  
  **See also:**
  - GPUError
  - [Supported Limits](https://www.w3.org/TR/webgpu/#supported-limits)
  
  **Related Operations:**
  - [Generate an Internal Error](https://www.w3.org/TR/webgpu/#generate-an-internal-error)
"GPUObjectDescriptorBase": |
  Represents the base descriptor for GPU objects. This interface is used to provide a common structure for labeling GPU objects, which can be helpful for debugging and identification purposes.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpuobjectdescriptorbase).
"GPUObjectDescriptorBase#label": |
  A string that labels the GPU object. This label can be used for debugging purposes to identify the object.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpuobjectdescriptorbase-label).
"GPUTextureViewDescriptor": |
  The `GPUTextureViewDescriptor` interface defines a set of properties that describe how to create a view on a texture. This descriptor is used when creating a [GPUTextureView](https://www.w3.org/TR/webgpu/#gputextureview) object, which represents a specific way to access the data in a texture.
  
  A texture view allows for different formats, dimensions, and usages of the underlying texture data. This is particularly useful for scenarios where you need to access the same texture data in multiple ways without duplicating the actual texture data.
"GPUTextureViewDescriptor#format": |
  `format` specifies the format of the texture view. This must be either the `format` of the texture or one of the `viewFormats` specified during its creation.
  
  See also: [WebGPU Specification - GPUTextureFormat](https://www.w3.org/TR/webgpu/#enumdef-gputextureformat).
"GPUTextureViewDescriptor#dimension": |
  `dimension` specifies the dimension to view the texture as. This property determines how the texture will be interpreted in terms of its dimensionality (e.g., 1D, 2D, or 3D).
  
  See also: [WebGPU Specification - GPUTextureViewDimension](https://www.w3.org/TR/webgpu/#enumdef-gputextureviewdimension).
"GPUTextureViewDescriptor#usage": |
  `usage` specifies the allowed usages for the texture view. This must be a subset of the `usage` flags of the texture. If set to 0, it defaults to the full set of usage flags of the texture.
  
  See also: [WebGPU Specification - GPUTextureUsageFlags](https://www.w3.org/TR/webgpu/#typedefdef-gputextureusageflags).
"GPUTextureViewDescriptor#aspect": |
  `aspect` specifies which aspects of the texture are accessible to the texture view. This property determines whether the view can access color, depth, stencil, or all aspects of the texture.
  
  See also: [WebGPU Specification - GPUTextureAspect](https://www.w3.org/TR/webgpu/#enumdef-gputextureaspect).
"GPUTextureViewDescriptor#baseMipLevel": |
  `baseMipLevel` specifies the first (most detailed) mipmap level accessible to the texture view. This property defines the starting point for mipmap levels that can be accessed by the view.
  
  See also: [WebGPU Specification - GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate).
"GPUTextureViewDescriptor#mipLevelCount": |
  `mipLevelCount` specifies how many mipmap levels, starting with `baseMipLevel`, are accessible to the texture view. This property defines the range of mipmap levels that can be accessed by the view.
  
  See also: [WebGPU Specification - GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate).
"GPUTextureViewDescriptor#baseArrayLayer": |
  `baseArrayLayer` specifies the index of the first array layer accessible to the texture view. This property defines the starting point for array layers that can be accessed by the view.
  
  See also: [WebGPU Specification - GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate).
"GPUBindGroupLayoutDescriptor": |
  Represents a descriptor for creating a GPUBindGroupLayout. This interface extends GPUObjectDescriptorBase and is used to define the layout of bind groups in WebGPU.
  
  A `GPUBindGroupLayoutDescriptor` specifies a list of entries that describe shader resource bindings. Each entry defines how resources are bound to shaders, including buffers, samplers, textures, and external textures.
"GPUBindGroupLayoutDescriptor#entries": |
  A required list of GPUBindGroupLayoutEntry objects that define the shader resource bindings for a bind group.
  
  Each entry in this list describes a single shader resource binding to be included in a `GPUBindGroupLayout`. The entries specify how resources are bound to shaders, including buffers, samplers, textures, and external textures.
  
  **See also**:
  - GPUBindGroupLayoutEntry
"GPUBindGroupLayoutEntry": |
  Represents a binding layout entry for a GPU bind group. This interface defines the structure of individual bindings within a [GPUBindGroupLayout](https://www.w3.org/TR/webgpu/#gpubindgrouplayout).
  
  A `GPUBindGroupLayoutEntry` specifies how resources are bound to shader stages, including buffers, samplers, textures, and storage textures. Only one type of binding (buffer, sampler, texture, storageTexture) can be defined for any given entry.
  
  **See also:**
  - [WebGPU Specification: GPUBindGroupLayoutEntry](https://www.w3.org/TR/webgpu/#dictdef-gpubindgrouplayoutentry)
"GPUBindGroupLayoutEntry#binding": |
  A unique identifier for a resource binding within the [GPUBindGroupLayout](https://www.w3.org/TR/webgpu/#gpubindgrouplayout). This ID corresponds to a `GPUBindGroupEntry.binding` and a `@binding` attribute in the [GPUShaderModule](https://www.w3.org/TR/webgpu/#gpushadermodule).
"GPUBindGroupLayoutEntry#visibility": |
  A bitset of the members of [GPUShaderStage](https://www.w3.org/TR/webgpu/#namespacedef-gpushaderstage). Each set bit indicates that a `GPUBindGroupLayoutEntry`'s resource will be accessible from the associated shader stage.
"GPUBindGroupLayoutEntry#buffer": |
  When provided, indicates that the binding resource type for this `GPUBindGroupLayoutEntry` is [GPUBufferBinding](https://www.w3.org/TR/webgpu/#dictdef-gpubufferbinding).
"GPUBindGroupLayoutEntry#sampler": |
  When provided, indicates that the binding resource type for this `GPUBindGroupLayoutEntry` is [GPUSampler](https://www.w3.org/TR/webgpu/#gpusampler).
"GPUBindGroupLayoutEntry#texture": |
  When provided, indicates that the binding resource type for this `GPUBindGroupLayoutEntry` is [GPUTextureView](https://www.w3.org/TR/webgpu/#gputextureview).
"GPUBufferBindingLayout": |
  Represents a layout for buffer bindings in WebGPU. This interface defines the properties required to specify how buffers should be bound to binding points in shaders.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#gpubufferbindinglayout-dictionary).
"GPUBufferBindingLayout#type": |
  Specifies the type required for buffers bound to this binding point. This property determines how the buffer will be used in the shader.
"GPUBufferBindingLayout#hasDynamicOffset": |
  Indicates whether this binding requires a dynamic offset. A dynamic offset allows for more flexible buffer binding, enabling the use of different buffer sizes at runtime.
"GPUBufferBindingLayout#minBindingSize": |
  Specifies the minimum size of a buffer binding used with this bind point. This value is used to validate that buffers bound to this layout meet the required size constraints.
  
  **Behavior:**
  - If `minBindingSize` is not `0`, pipeline creation validates that this value is greater than or equal to the minimum buffer binding size of the variable.
  - If `minBindingSize` is `0`, it is ignored during pipeline creation, and draw/dispatch commands validate that each binding in the [GPUBindGroup](https://www.w3.org/TR/webgpu/#gpubindgroup) satisfies the minimum buffer binding size of the variable.
"GPUTextureBindingLayout": |
  Represents the layout for a GPU texture binding. This interface defines the required properties for specifying how textures should be bound in a GPU pipeline.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gputexturebindinglayout).
"GPUTextureBindingLayout#sampleType": |
  Specifies the type required for texture views bound to this binding. This property determines how the texture data should be sampled.
  
  **Possible Values**:
  - `GPUTextureSampleType.FLOAT`
  - `GPUTextureSampleType.UNFILTERABLE_FLOAT`
  - `GPUTextureSampleType.DEPTH`
  - `GPUTextureSampleType.SINT`
  - `GPUTextureSampleType.UINT`
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gputexturesampletype).
"GPUTextureBindingLayout#viewDimension": |
  Specifies the required dimension for texture views bound to this binding. This property defines the dimensionality of the texture view.
  
  **Possible Values**:
  - `GPUTextureViewDimension._1D`
  - `GPUTextureViewDimension._2D`
  - `GPUTextureViewDimension._2D_ARRAY`
  - `GPUTextureViewDimension._3D`
  - `GPUTextureViewDimension.CUBE`
  - `GPUTextureViewDimension.CUBE_ARRAY`
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gputextureviewdimension).
"GPUTextureBindingLayout#multisampled": |
  Indicates whether texture views bound to this binding must be multisampled. This property is used to specify if the texture should support multisampling.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gputexturebindinglayout).
"GPUStorageTextureBindingLayout": |
  Represents the layout configuration for a storage texture binding in WebGPU. This interface defines how textures are accessed and used within shaders, specifying the access mode, format, and view dimension.
  
  For more details, refer to the [WebGPU specification on GPUStorageTextureBindingLayout](https://www.w3.org/TR/webgpu/#dictdef-gpustoragetexturebindinglayout).
"GPUStorageTextureBindingLayout#access": |
  Specifies the access mode for this binding, indicating whether the texture is readable, writable, or both. This property defaults to `GPUStorageTextureAccess.WriteOnly`.
"GPUStorageTextureBindingLayout#format": |
  Specifies the required format of texture views bound to this binding. This property is mandatory and defines how the texture data is interpreted.
"GPUStorageTextureBindingLayout#viewDimension": |
  Specifies the required dimension for texture views bound to this binding. This property defaults to `GPUTextureViewDimension.D2`.
"GPUBindGroupDescriptor": |
  The `GPUBindGroupDescriptor` interface represents a descriptor for creating bind groups in WebGPU. It extends the `GPUObjectDescriptorBase` and is used to specify the layout and entries of a bind group.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpubindgroupdescriptor).
"GPUBindGroupDescriptor#layout": |
  The `layout` property specifies the `GPUBindGroupLayout` that the entries of this bind group will conform to. This layout defines how resources are bound and accessed in shaders.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpubindgroupdescriptor-layout).
"GPUBindGroupDescriptor#entries": |
  The `entries` property is a list of `GPUBindGroupEntry` objects that describe the resources to expose to the shader for each binding described by the `layout`. Each entry specifies how a particular resource should be bound.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpubindgroupdescriptor-entries).
"GPUBindGroupEntry": |
  Represents a single resource to be bound in a [GPUBindGroup]. This interface is used to describe the binding of resources such as samplers, texture views, external textures, or buffer bindings within a bind group.
  
  For more details, refer to the [WebGPU specification on GPUBindGroupEntry](https://www.w3.org/TR/webgpu/#dictdef-gpubindgroupentry).
"GPUBindGroupEntry#binding": |
  A unique identifier for a resource binding within the [GPUBindGroup]. This identifier corresponds to a `GPUBindGroupLayoutEntry.binding` and a `@binding` attribute in the [GPUShaderModule].
"GPUBindGroupEntry#resource": |
  The resource to bind, which can be one of the following types:
  - [GPUSampler]
  - [GPUTextureView]
  - [GPUExternalTexture]
  - [GPUBufferBinding]
"GPUPipelineLayoutDescriptor": |
  The `GPUPipelineLayoutDescriptor` interface defines all the [GPUBindGroupLayout](https://www.w3.org/TR/webgpu/#dictdef-gpubindgrouplayout)s used by a pipeline. This descriptor is essential for configuring the layout of bind groups in a GPU pipeline, ensuring that shader modules can access resources correctly.
  
  **Inheritance**: This interface inherits from [GPUObjectDescriptorBase](https://www.w3.org/TR/webgpu/#dictdef-gpuobjectdescriptorbase).
  
  In this example, `bindGroupLayout1` and `bindGroupLayout2` are instances of [GPUBindGroupLayout]. The `bindGroupLayouts` list defines the layout of bind groups that the pipeline will use.
"GPUPipelineLayoutDescriptor#bindGroupLayouts": |
  A list of optional [GPUBindGroupLayout](https://www.w3.org/TR/webgpu/#dictdef-gpubindgrouplayout)s that the pipeline will use. Each element in this list corresponds to a `@group` attribute in the [GPUShaderModule], with the `N`th element corresponding to `@group(N)`.
  
  **Details**:
  - This list defines the layout of bind groups that the pipeline will use.
  - Each [GPUBindGroupLayout] in this list must match the corresponding `@group` attribute in the shader module.
  
  In this example, `bindGroupLayout1` and `bindGroupLayout2` are instances of [GPUBindGroupLayout]. The `bindGroupLayouts` list defines the layout of bind groups that the pipeline will use.
"GPUShaderModuleCompilationHint": |
  Represents a hint for compiling a GPUShaderModule. This interface provides information about the entry point and layout that may be used with the shader module in future pipeline creation calls.
  
  For more details, refer to the WebGPU specification on Shader Module Compilation Information: https://www.w3.org/TR/webgpu/#shader-module-compilation-information.
"GPUShaderModuleCompilationHint#entryPoint": |
  The entry point of the shader module. This is a required field and must be specified.
  
  Type: String (https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-string/).
"GPUShaderModuleCompilationHint#layout": |
  A GPUPipelineLayout that the shader module may be used with in future pipeline creation calls. If set to null, the default pipeline layout for the entry point associated with this hint will be used.
  
  Type: GPUPipelineLayout or GPUAutoLayoutMode.
"GPUPipelineDescriptorBase": |
  Represents the base descriptor for a GPU pipeline. This interface extends [GPUObjectDescriptorBase] and is used to define the layout of a GPU pipeline.
  
  The `layout` property specifies either a [GPUPipelineLayout] or an automatic layout mode (`"auto"`). When `"auto"` is specified, the pipeline layout is generated automatically.
"GPUPipelineDescriptorBase#layout": |
  Specifies the layout for this pipeline. This can be either a [GPUPipelineLayout] object or the string `"auto"` to generate the pipeline layout automatically.

  **Behavior**:
  - If a [GPUPipelineLayout] is provided, it defines the specific layout for the pipeline.
  - If `"auto"` is specified, the pipeline layout is generated automatically. However, this means that the pipeline cannot share [GPUBindGroup]s with any other pipelines.
  
  **See also**: [GPUAutoLayoutMode], [GPUBindGroup]
"GPUComputePipelineDescriptor": |
  Represents a descriptor for creating a compute pipeline in WebGPU. This interface extends [GPUPipelineDescriptorBase] and is used to define the configuration for a compute pipeline, which executes compute shaders.
  
  A compute pipeline is responsible for performing general-purpose computations on the GPU. It does not render graphics but can be used for tasks such as data processing, simulations, and other parallel computations.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpucomputepipelinedescriptor).
"GPUComputePipelineDescriptor#compute": |
  Specifies the compute shader stage for the pipeline. This member is required and must be set to a valid [GPUProgrammableStage] object that describes the compute shader entry point.
  
  The compute shader is responsible for executing the compute operations defined in the shader code. It does not produce visual output but can perform parallel computations on data.
"GPURenderPipelineDescriptor": |
  The `GPURenderPipelineDescriptor` interface extends `GPUPipelineDescriptorBase` and defines the configuration for a render pipeline in WebGPU. It specifies the vertex, primitive, depth-stencil, multisample, and fragment states required to create a render pipeline. For more details, refer to the [W3C specification](https://www.w3.org/TR/webgpu/#dictdef-gpurenderpipelinedescriptor).
"GPURenderPipelineDescriptor#vertex": |
  `vertex` of type `GPUVertexState`. Describes the vertex shader entry point of the pipeline and its input buffer layouts. This is a required field. For more details, refer to the [W3C specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpipelinedescriptor-vertex).
"GPURenderPipelineDescriptor#primitive": |
  `primitive` of type `GPUPrimitiveState`, defaulting to `{}` if not provided. Describes the primitive-related properties of the pipeline, such as topology and strip index format. For more details, refer to the [W3C specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpipelinedescriptor-primitive).
"GPURenderPipelineDescriptor#depthStencil": |
  `depthStencil` of type `GPUDepthStencilState?`. Describes the optional depth-stencil properties, including testing, operations, and bias. This field is nullable. For more details, refer to the [W3C specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpipelinedescriptor-depthstencil).
"GPURenderPipelineDescriptor#multisample": |
  `multisample` of type `GPUMultisampleState`, defaulting to `{}` if not provided. Describes the multi-sampling properties of the pipeline, such as count and mask. For more details, refer to the [W3C specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpipelinedescriptor-multisample).
"GPURenderPipelineDescriptor#fragment": |
  `fragment` of type `GPUFragmentState?`. Describes the fragment shader entry point of the pipeline and its output colors. If not provided, the [no color output mode](https://www.w3.org/TR/webgpu/#no-color-output) is enabled. This field is nullable. For more details, refer to the [W3C specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpipelinedescriptor-fragment).
"GPUMultisampleState": |
  Represents the multisampling state used by a [GPURenderPipeline](https://www.w3.org/TR/webgpu/#gpurenderpipeline) to interact with render pass attachments that support multisampling.
  
  This interface defines how many samples per pixel are used, which samples are written to, and whether alpha-to-coverage is enabled. The multisample state is crucial for rendering high-quality images by reducing aliasing artifacts.
  
  **See also:**
  - [GPUMultisampleState dictionary in the WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpumultisamplestate)
"GPUMultisampleState#count": |
  Specifies the number of samples per pixel. This value determines the level of multisampling used during rendering.
  
  **Constraints:**
  - Must be either 1 or 4.
  - If `alphaToCoverageEnabled` is `true`, `count` must be greater than 1.
  
  **See also:**
  - [count member in the WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpumultisamplestate-count)
"GPUMultisampleState#mask": |
  Determines which samples are written to during rendering. This mask allows for selective sampling, which can be useful for optimizing performance or achieving specific visual effects.

  **See also:**
  - [mask member in the WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpumultisamplestate-mask)
"GPUMultisampleState#alphaToCoverageEnabled": |
  When set to `true`, enables alpha-to-coverage, which uses the fragment's alpha channel to generate a sample coverage mask. This can improve the quality of antialiased edges.
  
  **Constraints:**
  - If `alphaToCoverageEnabled` is `true`, `count` must be greater than 1.
  
  **See also:**
  - [alphaToCoverageEnabled member in the WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpumultisamplestate-alphatocoverageenabled)
"GPUFragmentState": |
  Represents a fragment state in WebGPU, which is a type of programmable stage that defines how fragments are processed during rendering. This interface extends [GPUProgrammableStage] and includes specific configurations for color targets.
  
  The `GPUFragmentState` interface is used to configure the fragment shader stage of a GPU pipeline, specifying how the colors are written to the render target. This is crucial for defining the visual output of a rendering operation.
  
  **See also:**
  - [WebGPU Specification: GPUProgrammableStage](https://www.w3.org/TR/webgpu/#gpuprogrammablestage)
"GPUFragmentState#targets": |
  A list of [GPUColorTargetState] objects that define the formats and behaviors of the color targets this pipeline writes to. Each `GPUColorTargetState` in the list specifies how a particular color target should be handled during rendering.
  
  **See also:**
  - [WebGPU Specification: GPUFragmentState](https://www.w3.org/TR/webgpu/#dictdef-gpufragmentstate)
"GPUColorTargetState": |
  Represents the state of a color target in a GPU render pipeline. This interface defines the format, blending behavior, and write mask for a color attachment in a render pass.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpucolortargetstate).
"GPUColorTargetState#format": |
  The format of this color target. The pipeline will only be compatible with render pass encoders which use a texture view of this format in the corresponding color attachment.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpucolortargetstate-format).
"GPUColorTargetState#blend": |
  The blending behavior for this color target. If left undefined, disables blending for this color target.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpucolortargetstate-blend).
"GPUColorTargetState#writeMask": |
  Bitmask controlling which channels are written to when drawing to this color target. Defaults to `0xF` (all channels).
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpucolortargetstate-writemask).
"GPUBlendState": |
  Represents the blend state used in rendering operations, defining how colors and alpha values are blended.
  
  This interface is part of the WebGPU API and corresponds to the `GPUBlendState` dictionary defined in the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpublendstate).
  
  The `GPUBlendState` interface includes two properties: `color` and `alpha`, both of type `GPUBlendComponent`. These properties specify the blending behavior for color channels and alpha channels, respectively.
"GPUBlendComponent": |
  Represents a blend component used in blending operations for color or alpha components of a fragment. This interface defines how the source and destination colors are combined during rendering.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpublendcomponent).
"GPUBlendComponent#operation": |
  Defines the [GPUBlendOperation] used to calculate the values written to the target attachment components.
  
  This property specifies the blending operation to be performed. The default value is `add`.

  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpublendcomponent-operation).
"GPUBlendComponent#srcFactor": |
  Defines the [GPUBlendFactor] operation to be performed on values from the fragment shader.
  
  This property specifies the blending factor for the source color. The default value is `one`.

  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpublendcomponent-srcfactor).
"GPUBlendComponent#dstFactor": |
  Defines the [GPUBlendFactor] operation to be performed on values from the target attachment.
  
  This property specifies the blending factor for the destination color. The default value is `zero`.

  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpublendcomponent-dstfactor).
"GPUStencilFaceState": |
  Represents a set of stencil face state parameters that define how stencil tests and operations are performed. This interface is used to configure the behavior of the stencil buffer for front or back-facing triangles in a render pipeline.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpustencilfacestate).
"GPUStencilFaceState#compare": |
  Specifies the comparison function used for stencil tests. This determines how the current stencil value is compared to the reference value.
  
  **See Also:**
  - [W3C WebGPU specification: GPUStencilFaceState.compare](https://www.w3.org/TR/webgpu/#dom-gpustencilfacestate-compare)
"GPUStencilFaceState#failOp": |
  Specifies the operation to perform when the stencil test fails. This defines what action to take if the comparison function does not pass.
  
  **See Also:**
  - [W3C WebGPU specification: GPUStencilFaceState.failOp](https://www.w3.org/TR/webgpu/#dom-gpustencilfacestate-failop)
"GPUStencilFaceState#depthFailOp": |
  Specifies the operation to perform when the stencil test passes but the depth test fails. This defines what action to take if the comparison function passes but the depth test does not.
  
  **See Also:**
  - [W3C WebGPU specification: GPUStencilFaceState.depthFailOp](https://www.w3.org/TR/webgpu/#dom-gpustencilfacestate-depthfailop)
"GPUStencilFaceState#passOp": |
  Specifies the operation to perform when both the stencil test and the depth test pass. This defines what action to take if both tests are successful.
  
  **See Also:**
  - [W3C WebGPU specification: GPUStencilFaceState.passOp](https://www.w3.org/TR/webgpu/#dom-gpustencilfacestate-passop)
"GPUVertexState": |
  Represents a vertex state in the WebGPU API, defining how vertex data is laid out and processed. This interface extends [GPUProgrammableStage], allowing it to be used as part of a render pipeline.
  
  A `GPUVertexState` object specifies the layout of vertex attribute data in vertex buffers. Each buffer's layout is defined by a list of `GPUVertexBufferLayout` objects, which describe the structure and stride of the vertex data.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#vertex-state).
"GPUVertexState#buffers": |
  A list of `GPUVertexBufferLayout` objects that define the layout of vertex attribute data in each vertex buffer used by this pipeline.
  
  Each `GPUVertexBufferLayout` specifies how the vertex data is structured, including the stride between elements and the attributes that describe the members of the structure. This allows the GPU to correctly interpret the vertex data during rendering.

  For more information, see the [W3C WebGPU specification on GPUVertexBufferLayout](https://www.w3.org/TR/webgpu/#dictdef-gpuvertexbufferlayout).
"GPUVertexBufferLayout": |
  Represents the layout of a vertex buffer in WebGPU. This interface defines how vertices are structured and accessed, including the stride between elements, the step mode (whether data is per-vertex or per-instance), and the attributes that describe the vertex data.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpuvertexbufferlayout).
"GPUVertexBufferLayout#arrayStride": |
  The stride, in bytes, between elements of this array. This value specifies how much memory is allocated for each vertex or instance in the buffer.
"GPUVertexBufferLayout#stepMode": |
  Specifies whether each element of this array represents per-vertex data or per-instance data. The default value is `GPUVertexStepMode.VERTEX`.
"GPUVertexBufferLayout#attributes": |
  An array defining the layout of the vertex attributes within each element. This sequence describes how the vertex data is structured and accessed.
"GPUVertexAttribute": |
  Represents a vertex attribute in the WebGPU API. This interface defines the format, offset, and shader location of a vertex attribute.
  
  A `GPUVertexAttribute` is used to describe how data from a vertex buffer should be interpreted by the GPU. It specifies the format of the data (e.g., float32, uint32), the byte offset within the vertex buffer where the data starts, and the shader location that corresponds to this attribute.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpuvertexattribute).
"GPUVertexAttribute#format": |
  The format of the vertex attribute. This specifies how the data should be interpreted by the GPU.

  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpuvertexattribute-format).
"GPUVertexAttribute#offset": |
  The offset, in bytes, from the beginning of the vertex buffer element to the data for this attribute.

  This value must be a multiple of the minimum of 4 and the byte size of the format specified by `format`. It defines where within the vertex buffer the data for this attribute begins.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpuvertexattribute-offset).
"GPUVertexAttribute#shaderLocation": |
  The numeric location associated with this attribute. This corresponds to a `@location` attribute declared in the vertex module of the shader.

  This value must be less than the maximum number of vertex attributes supported by the device, as specified by `device.limits.maxVertexAttributes`.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpuvertexattribute-shaderlocation).
"GPUCommandBufferDescriptor": |
  The `GPUCommandBufferDescriptor` interface represents a descriptor for creating command buffers in WebGPU. This interface inherits from [GPUObjectDescriptorBase], providing a base set of properties and methods that are common to all GPU object descriptors.
  
  A command buffer is a sequence of commands that can be submitted to the GPU for execution. The `GPUCommandBufferDescriptor` specifies the configuration options for creating these command buffers, such as label and usage flags.
  
  This interface is used when calling [GPUDevice.createCommandBuffer] to create a new command buffer with the specified configuration.
  
  **See also:**
  - [WebGPU Specification: GPUCommandBufferDescriptor](https://www.w3.org/TR/webgpu/#dictdef-gpucommandbufferdescriptor)
"GPUCommandEncoderDescriptor": |
  The `GPUCommandEncoderDescriptor` interface represents a descriptor used to create a [GPUCommandEncoder](https://www.w3.org/TR/webgpu/#gpucommandencoder) object. This descriptor inherits from the base descriptor interface [GPUObjectDescriptorBase](https://www.w3.org/TR/webgpu/#dictdef-gpuobjectdescriptorbase).
  
  The `GPUCommandEncoderDescriptor` is used to specify configuration options for the command encoder, such as label and device.
  
  **See Also:**
  - [GPUObjectDescriptorBase](https://www.w3.org/TR/webgpu/#dictdef-gpuobjectdescriptorbase)
"GPUComputePassTimestampWrites": |
  Represents a dictionary that specifies the query set and indices where timestamps will be written during a compute pass. This interface is used to measure the duration of compute passes by recording timestamps at the beginning and end of the pass.
  
  For more details, refer to the [WebGPU specification on GPUComputePassTimestampWrites](https://www.w3.org/TR/webgpu/#dictdef-gpucomputepasstimestampwrites).
"GPUComputePassTimestampWrites#querySet": |
  The `GPUQuerySet` of type "timestamp" that the query results will be written to. This set contains the queries where the timestamps will be recorded.
"GPUComputePassTimestampWrites#beginningOfPassWriteIndex": |
  If defined, indicates the query index in `querySet` into which the timestamp at the beginning of the compute pass will be written. This value is of type [GPUSize32](https://www.w3.org/TR/webgpu/#typedefdef-gpusize32).
"GPUComputePassTimestampWrites#endOfPassWriteIndex": |
  If defined, indicates the query index in `querySet` into which the timestamp at the end of the compute pass will be written. This value is of type [GPUSize32](https://www.w3.org/TR/webgpu/#typedefdef-gpusize32).
"GPUComputePassDescriptor": |
  Represents a descriptor for configuring a compute pass in WebGPU. This interface extends [GPUObjectDescriptorBase] and is used to specify the details of a compute pass, including timestamp writes.
  
  For more information, see the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpucomputepassdescriptor).
"GPUComputePassDescriptor#timestampWrites": |
  Defines which timestamp values will be written for this pass and where to write them.
  
  This property is of type [GPUComputePassTimestampWrites].
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpucomputepassdescriptor-timestampwrites).
"GPURenderPassTimestampWrites": |
  Represents a dictionary that specifies the query set and indices where timestamps will be written during a render pass. This interface is used to capture timing information at the beginning and end of a render pass.
  
  For more details, refer to the [WebGPU specification on GPURenderPassTimestampWrites](https://www.w3.org/TR/webgpu/#dom-gpurenderpasstimestampwrites).
"GPURenderPassTimestampWrites#querySet": |
  The GPUQuerySet of type `timestamp` that the query results will be written to.
  
  This property is required and specifies the query set where the timestamps will be recorded.
"GPURenderPassTimestampWrites#beginningOfPassWriteIndex": |
  An optional index in the [querySet] that indicates where the timestamp at the beginning of the render pass will be written.
  
  If defined, this property specifies the exact query index within the `querySet` where the start timestamp of the render pass will be recorded.
"GPURenderPassTimestampWrites#endOfPassWriteIndex": |
  An optional index in the [querySet] that indicates where the timestamp at the end of the render pass will be written.
  
  If defined, this property specifies the exact query index within the `querySet` where the end timestamp of the render pass will be recorded.
"GPURenderPassDescriptor": |
  The `GPURenderPassDescriptor` interface defines the configuration for a render pass in WebGPU. It specifies the color attachments, depth/stencil attachment, occlusion query set, timestamp writes, and maximum draw count for the render pass.
  
  This descriptor is used to configure the rendering process by specifying how different types of data will be handled during the render pass. The `colorAttachments` property defines which color buffers will receive the output from the render pass. The `depthStencilAttachment` specifies the depth/stencil buffer that will be used for depth testing and stencil operations. The `occlusionQuerySet` allows for occlusion queries to be performed, and the `timestampWrites` can be used to write timestamps during the render pass.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpurenderpassdescriptor).
"GPURenderPassDescriptor#colorAttachments": |
  The `colorAttachments` property is a list of `GPURenderPassColorAttachment` objects that define the color attachments for the render pass. Each attachment specifies how the output from the render pass will be written to a particular color buffer.
  
  Due to usage compatibility, no color attachment may alias another attachment or any resource used inside the render pass.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpassdescriptor-colorattachments).
"GPURenderPassDescriptor#depthStencilAttachment": |
  The `depthStencilAttachment` property specifies a `GPURenderPassDepthStencilAttachment` object that defines the depth/stencil attachment for the render pass. This attachment is used for depth testing and stencil operations during the rendering process.
  
  Due to usage compatibility, no writable depth/stencil attachment may alias another attachment or any resource used inside the render pass.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpassdescriptor-depthstencilattachment).
"GPURenderPassDescriptor#occlusionQuerySet": |
  The `occlusionQuerySet` property specifies a `GPUQuerySet` object that defines where the occlusion query results will be stored for this render pass. Occlusion queries are used to determine whether certain pixels were rendered during the pass.
"GPURenderPassDescriptor#timestampWrites": |
  The `timestampWrites` property allows you to specify a list of `GPUQuerySet` objects that define where timestamp query results will be stored for this render pass. Timestamps are used to measure the time taken by different parts of the rendering process.
"GPURenderPassDescriptor#maxDrawCount": |
  The `maxDrawCount` property specifies the maximum number of draw calls that can be made during the render pass. This is useful for optimizing performance and managing resources efficiently.
  
  Setting an appropriate value for `maxDrawCount` helps in preventing resource exhaustion and ensures smooth rendering.
"GPURenderBundleDescriptor": |
  Represents a descriptor for creating a [GPURenderBundle]. This interface inherits from [GPUObjectDescriptorBase], which provides common properties and methods for GPU objects.
  
  The `GPURenderBundleDescriptor` is used to specify the configuration options when creating a render bundle. A render bundle encapsulates a sequence of rendering commands that can be executed multiple times with different parameters, improving performance by reducing the overhead of command encoding.
"GPURenderBundleEncoderDescriptor": |
  Represents a descriptor for creating a GPURenderBundleEncoder. This interface extends the GPURenderPassLayout and is used to specify whether the depth or stencil components of a render pass are read-only.
  
  @see [WebGPU Specification - GPURenderBundleEncoderDescriptor](https://www.w3.org/TR/webgpu/#dictdef-gpurenderbundleencoderdescriptor)
"GPURenderBundleEncoderDescriptor#depthReadOnly": |
  Indicates whether the render bundle modifies the depth component of the GPURenderPassDepthStencilAttachment in any render pass it is executed in.
  
  If set to true, the depth component is read-only. This can be useful for optimizing performance by avoiding unnecessary writes to the depth buffer.
  
  @return A Boolean value indicating whether the depth component is read-only.
  @default false
"GPURenderBundleEncoderDescriptor#stencilReadOnly": |
  Indicates whether the render bundle modifies the stencil component of the GPURenderPassDepthStencilAttachment in any render pass it is executed in.
  
  If set to true, the stencil component is read-only. This can be useful for optimizing performance by avoiding unnecessary writes to the stencil buffer.
  
  @return A Boolean value indicating whether the stencil component is read-only.
  @default false
"GPUQuerySetDescriptor": |
  Represents a descriptor for creating a [GPUQuerySet](https://www.w3.org/TR/webgpu/#gpuqueryset) object. This interface extends [GPUObjectDescriptorBase], providing the necessary configuration parameters to define the type and count of queries managed by the query set.
  
  **See also:**
  - [WebGPU Specification: GPUQuerySetDescriptor](https://www.w3.org/TR/webgpu/#dictdef-gpuquerysetdescriptor)
"GPUQuerySetDescriptor#type": |
  Specifies the type of queries managed by the [GPUQuerySet]. This property is required and must be set to one of the values defined in the [GPUQueryType](https://www.w3.org/TR/webgpu/#enumdef-gpuquerytype) enum.
  
  **See also:**
  - [WebGPU Specification: type](https://www.w3.org/TR/webgpu/#dom-gpuquerysetdescriptor-type)
"GPUQuerySetDescriptor#count": |
  Specifies the number of queries managed by the [GPUQuerySet]. This property is required and must be set to a valid [GPUSize32](https://www.w3.org/TR/webgpu/#typedefdef-gpusize32) value.
  
  **See also:**
  - [WebGPU Specification: count](https://www.w3.org/TR/webgpu/#dom-gpuquerysetdescriptor-count)
"GPUTextureViewDescriptor#arrayLayerCount": |
  `arrayLayerCount` specifies how many array layers, starting with `baseArrayLayer`, are accessible to the texture view. This property defines the range of array layers that can be accessed by the view.
  
  See also: [WebGPU Specification - GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate).
"GPUSamplerBindingLayout": |
  Represents a binding layout for samplers in WebGPU. This interface defines the type of sampler that can be bound to a specific binding.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpusamplerbindinglayout).
"GPUSamplerBindingLayout#type": |
  Specifies the type of sampler that can be bound to this binding layout. This is an enumeration value that indicates whether the sampler is used for filtering, non-filtering, or comparison operations.
  
  This property determines how the sampler will be utilized in the shader. For example, a filtering sampler might be used for texture sampling with mipmapping, while a non-filtering sampler might be used for shadow mapping.
"GPUBlendState#color": |
  Defines the blending behavior of the corresponding render target for color channels.
  
  This property is of type `GPUBlendComponent` and specifies how the color channels are blended during rendering. 
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpublendstate-color).
"GPUBlendState#alpha": |
  Defines the blending behavior of the corresponding render target for the alpha channel.
  
  This property is of type `GPUBlendComponent` and specifies how the alpha channel is blended during rendering. 
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpublendstate-alpha).
"GPURenderPassLayout": |
  Represents the layout of a render pass, specifying the formats and sample counts for color and depth/stencil attachments.
  
  This interface is used to define the configuration of a render pass, which includes the formats of the color attachments and the optional depth/stencil attachment. It also specifies the number of samples per pixel in the attachments.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#gpurenderpasslayout).
"GPURenderPassLayout#colorFormats": |
  A list of the [GPUTextureFormat](https://www.w3.org/TR/webgpu/#enumdef-gputextureformat)s of the color attachments for this pass or bundle.
  
  This property specifies the formats of the color attachments that will be used in the render pass. Each format corresponds to a texture view that will be rendered to during the pass.
"GPURenderPassLayout#depthStencilFormat": |
  The [GPUTextureFormat](https://www.w3.org/TR/webgpu/#enumdef-gputextureformat) of the depth/stencil attachment for this pass or bundle.
  
  This property specifies the format of the depth/stencil attachment that will be used in the render pass. It is optional and can be `null` if no depth/stencil attachment is required.
"GPURenderPassLayout#sampleCount": |
  Number of samples per pixel in the attachments for this pass or bundle.
  
  This property specifies the number of samples per pixel for multisampling. The default value is `1`, which means no multisampling.
"GPUExtent3D": |
  Represents a 3-dimensional extent, which defines the size of a texture or other GPU resources. This interface can be used to specify dimensions in three axes: width, height, and depth or array layers.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#gpuextent3d).
  
  @see [GPUExtent3DDict](https://www.w3.org/TR/webgpu/#dictdef-gpuextent3ddict)
"GPUExtent3D#width": |
  The width of the extent.
  
  This property corresponds to the `width` field in the [GPUExtent3DDict](https://www.w3.org/TR/webgpu/#dictdef-gpuextent3ddict).
  
  @return The width as a [GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate).
"GPUExtent3D#height": |
  The height of the extent.
  
  This property corresponds to the `height` field in the [GPUExtent3DDict](https://www.w3.org/TR/webgpu/#dictdef-gpuextent3ddict), which defaults to 1 if not specified.
  
  @return The height as a [GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate).
"GPUExtent3D#depthOrArrayLayers": |
  The depth of the extent or the number of array layers it contains.
  
  This property corresponds to the `depthOrArrayLayers` field in the [GPUExtent3DDict](https://www.w3.org/TR/webgpu/#dictdef-gpuextent3ddict), which defaults to 1 if not specified. If used with a [GPUTexture](https://www.w3.org/TR/webgpu/#gputexture) with a dimension of `"3d"`, it defines the depth of the texture. If used with a `GPUTexture` with a dimension of `"2d"`, it defines the number of array layers in the texture.
  
  @return The depth or number of array layers as a [GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate).
"GPUSampler": |
  The `GPUSampler` interface encodes transformations and filtering information that can be used in a shader to interpret texture resource data.
    
  This interface is created via the [GPUDevice.createSampler()] method.
   
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#gpusampler).
"GPUTextureView": |
  A `GPUTextureView` represents a view onto some subset of the texture subresources defined by a particular [GPUTexture]. This interface allows for efficient access and manipulation of specific portions of a texture, enabling optimized rendering and data processing.
  
  The `GPUTextureView` is part of the WebGPU API and is designed to be used in conjunction with other GPU resources such as [GPUBindGroup] and [GPURenderPipeline]. It provides a way to bind specific texture views to shaders, enabling advanced rendering techniques.
  
  This interface inherits from `GPUBindingResource` and `GPUObjectBase`, which means it can be used as a binding resource in various GPU operations. Additionally, it implements the `AutoCloseable` interface, allowing for proper resource management and cleanup.
  
  **See also:**
  - [WebGPU Specification: GPUTextureView](https://www.w3.org/TR/webgpu/#gputextureview)
"GPUSupportedLimits": |
  The `GPUSupportedLimits` interface provides access to the supported limits of a GPU adapter or device.
  These limits define the maximum capabilities and constraints for various resources and operations,
  such as texture dimensions, bind groups, buffers, and shader stages. This information is crucial
  for optimizing performance and ensuring compatibility with the underlying hardware.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#gpusupportedlimits).
"GPUSupportedLimits#maxTextureDimension1D": |
  The maximum size for a 1D texture dimension. This value represents the largest allowable width
  for a 1D texture in texels.
"GPUSupportedLimits#maxTextureDimension2D": |
  The maximum size for a 2D texture dimension. This value represents the largest allowable width or height
  for a 2D texture in texels.
"GPUSupportedLimits#maxTextureDimension3D": |
  The maximum size for a 3D texture dimension. This value represents the largest allowable depth
  for a 3D texture in texels.
"GPUSupportedLimits#maxTextureArrayLayers": |
  The maximum number of layers in a texture array. This value represents the largest allowable number
  of layers for a texture array.
"GPUSupportedLimits#maxBindGroups": |
  The maximum number of bind groups that can be used in a single pipeline. This value represents the largest allowable
  number of bind groups for a pipeline.
"GPUSupportedLimits#maxBindGroupsPlusVertexBuffers": |
  The maximum number of bind groups plus vertex buffers that can be used in a single pipeline. This value represents the largest allowable
  combined count of bind groups and vertex buffers for a pipeline.
"GPUSupportedLimits#maxBindingsPerBindGroup": |
  The maximum number of bindings per bind group. This value represents the largest allowable number of bindings for a single bind group.
"GPUSupportedLimits#maxDynamicUniformBuffersPerPipelineLayout": |
  The maximum number of dynamic uniform buffers per pipeline layout. This value represents the largest allowable number of dynamic uniform buffers for a single pipeline layout.
"GPUAdapterInfo": |
  The `GPUAdapterInfo` interface exposes various identifying information about an adapter. None of the members in `GPUAdapterInfo` are guaranteed to be populated with any particular value; if no value is provided, the attribute will return the empty string " ". It is at the user agent’s discretion which values to reveal, and it is likely that on some devices none of the values will be populated. As such, applications **must** be able to handle any possible `GPUAdapterInfo` values, including the absence of those values.
  
  The `GPUAdapterInfo` for an adapter is exposed via [GPUAdapter.info](https://www.w3.org/TR/webgpu/#dom-gpuadapter-info) and [GPUDevice.adapterInfo](https://www.w3.org/TR/webgpu/#dom-gpudevice-adapterinfo). This info is immutable: for a given adapter, each `GPUAdapterInfo` attribute will return the same value every time it’s accessed.
  
  **Note:** Though the `GPUAdapterInfo` attributes are immutable *once accessed*, an implementation may delay the decision on what to expose for each attribute until the first time it is accessed.
"GPUAdapterInfo#vendor": |
  The `vendor` property returns a string identifying the vendor of the GPU adapter. This value may be an empty string if the user agent chooses not to reveal this information.
"GPUAdapterInfo#architecture": |
  The `architecture` property returns a string identifying the architecture of the GPU adapter. This value may be an empty string if the user agent chooses not to reveal this information.
"GPUAdapterInfo#device": |
  The `device` property returns a string identifying the device name of the GPU adapter. This value may be an empty string if the user agent chooses not to reveal this information.
"GPUAdapterInfo#description": |
  The `description` property returns a string providing a description of the GPU adapter. This value may be an empty string if the user agent chooses not to reveal this information.
"GPUAdapterInfo#subgroupMinSize": |
  The `subgroupMinSize` property returns the minimum size of a subgroup for the GPU adapter. This value is represented as an unsigned integer (`UInt`).
"GPUAdapterInfo#subgroupMaxSize": |
  The `subgroupMaxSize` property returns the maximum size of a subgroup for the GPU adapter. This value is represented as an unsigned integer (`UInt`).
"GPUAdapterInfo#isFallbackAdapter": |
  The `isFallbackAdapter` property returns a boolean indicating whether the adapter is a fallback adapter. A fallback adapter is used when the preferred adapter is not available.
"GPUAdapter": |
  The `GPUAdapter` interface encapsulates a GPU adapter and describes its capabilities, including supported features and limits. This interface is essential for interacting with the underlying GPU hardware and obtaining a `GPUDevice` to perform rendering operations.
  
  To obtain a `GPUAdapter`, use the `requestAdapter()` method provided by the `GPU` object. The `GPUAdapter` provides read-only access to its features, limits, and information about the adapter.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#gpuadapter).
"GPUAdapter#features": |
  Represents the set of features supported by the GPU adapter. This property is read-only and provides information about the capabilities of the underlying hardware.
  
  The `features` attribute contains a `GPUSupportedFeatures` object, which includes boolean flags indicating whether specific features are supported.
"GPUAdapter#limits": |
  Represents the limits imposed by the GPU adapter. This property is read-only and provides information about the constraints of the underlying hardware.
  
  The `limits` attribute contains a `GPUSupportedLimits` object, which includes various limit values such as maximum texture dimensions, maximum bind groups, etc.
"GPUAdapter#info": |
  Provides information about the physical adapter underlying this `GPUAdapter`. This property is read-only and returns a `GPUAdapterInfo` object.
  
  The `info` attribute contains details such as the name of the adapter, vendor ID, device ID, etc. These values are constant over time for a given `GPUAdapter`.
"GPUAdapter#requestDevice(descriptor)": |
  Asynchronously requests a `GPUDevice` from the adapter. This method returns a `Result<GPUDevice>`, which resolves to a `GPUDevice` instance if successful.
  
  The `descriptor` parameter is optional and allows specifying configuration options for the device, such as enabling specific features or setting default queue properties.
"GPUDevice": |
  The `GPUDevice` interface encapsulates a GPU device and exposes the functionality of that device. It is the top-level interface through which WebGPU interfaces are created.
  
  To obtain a `GPUDevice`, use the `requestDevice()` method on a `GPUAdapter`.
  
  **See also:**
  - [WebGPU Specification: GPUDevice](https://www.w3.org/TR/webgpu/#gpudevice)
"GPUDevice#features": |
  Represents the supported features of the GPU device.
  
  **See also:**
  - [WebGPU Specification: GPUSupportedFeatures](https://www.w3.org/TR/webgpu/#gpusupportedfeatures)
"GPUDevice#limits": |
  Represents the supported limits of the GPU device.
  
  **See also:**
  - [WebGPU Specification: GPUSupportedLimits](https://www.w3.org/TR/webgpu/#gpusupportedlimits)
"GPUDevice#adapterInfo": |
  Provides information about the GPU adapter associated with this device.
  
  **See also:**
  - [WebGPU Specification: GPUAdapterInfo](https://www.w3.org/TR/webgpu/#gpuadapterinfo)
"GPUDevice#queue": |
  Represents the command queue associated with this device.
  
  **See also:**
  - [WebGPU Specification: GPUQueue](https://www.w3.org/TR/webgpu/#gpuqueue)
"GPUDevice#createBuffer(descriptor)": |
  Creates a new buffer object based on the provided descriptor.
  
  **Parameters:**
  - `descriptor`: A [GPUBufferDescriptor] that specifies the properties of the buffer to be created.
  
  **Returns:** A new [GPUBuffer] object.
  
  **See also:**
  - [WebGPU Specification: createBuffer](https://www.w3.org/TR/webgpu/#dom-gpudevice-createbuffer)
"GPUDevice#createTexture(descriptor)": |
  Creates a new texture object based on the provided descriptor.
  
  **Parameters:**
  - `descriptor`: A [GPUTextureDescriptor] that specifies the properties of the texture to be created.
  
  **Returns:** A new [GPUTexture] object.
  
  **See also:**
  - [WebGPU Specification: createTexture](https://www.w3.org/TR/webgpu/#dom-gpudevice-createtexture)
"GPUDevice#createSampler(descriptor)": |
  Creates a new sampler object based on the provided descriptor.
  
  **Parameters:**
  - `descriptor`: An optional [GPUSamplerDescriptor] that specifies the properties of the sampler to be created. If not provided, default values are used.
  
  **Returns:** A new [GPUSampler] object.
  
  **See also:**
  - [WebGPU Specification: createSampler](https://www.w3.org/TR/webgpu/#dom-gpudevice-createsampler)
"GPUBuffer": |
  The `GPUBuffer` interface represents a block of memory that can be used in GPU operations. Data is stored in linear layout, meaning each byte of the allocation can be addressed by its offset from the start of the buffer, subject to alignment restrictions depending on the operation. Some buffers can be mapped, making the block of memory accessible via an `ArrayBuffer` called its mapping.
  
  Buffers are created via [GPUDevice.createBuffer()](https://www.w3.org/TR/webgpu/#dom-gpudevice-createbuffer). Buffers may be [mappedAtCreation](https://www.w3.org/TR/webgpu/#dom-gpubufferdescriptor-mappedatcreation).
  
  Refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#gpubuffer) for more details.
"GPUBuffer#size": |
  The `size` property returns the size of the buffer in bytes. This value is read-only and represents the total allocated memory for this buffer.
"GPUBuffer#usage": |
  The `usage` property specifies how the buffer can be used. This value is read-only and represents a combination of flags indicating the allowed operations on this buffer.
"GPUBuffer#mapState": |
  The `mapState` property indicates the current mapping state of the buffer. This value is read-only and can be one of the following: `unmapped`, `pending`, or `mapped`.
"GPUBuffer#mapAsync(mode, offset, size)": |
  The `mapAsync` function asynchronously maps the buffer into an `ArrayBuffer`. This operation is non-blocking and returns a [Result](https://kotlinlang.org/api/latest/kotlinx-coroutines/kotlinx-coroutines-core/kotlinx.coroutines/-result/) indicating success or failure.
  
  **Parameters:**
  - `mode`: The mapping mode, which can be either [GPUMapModeRead] or [GPUMapModeWrite].
  - `offset`: (Optional) The offset within the buffer to start mapping. Defaults to 0.
  - `size`: (Optional) The size of the range to map. If null, maps from the offset to the end of the buffer.
  
  **Returns:** A [Result](https://kotlinlang.org/api/latest/kotlinx-coroutines/kotlinx-coroutines-core/kotlinx.coroutines/-result/) indicating success or failure.
"GPUBuffer#getMappedRange(offset, size)": |
  The `getMappedRange` function returns an `ArrayBuffer` representing the mapped range of the buffer. This method can only be called when the buffer is in the `mapped` state.
  
  **Parameters:**
  - `offset`: (Optional) The offset within the buffer to start mapping. Defaults to 0.
  - `size`: (Optional) The size of the range to map. If null, maps from the offset to the end of the buffer.
  
  **Returns:** An [ArrayBuffer](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/ArrayBuffer) containing the mapped data.
"GPUBuffer#unmap()": |
  The `unmap` function unmaps the buffer, making it no longer accessible via an `ArrayBuffer`. This method can only be called when the buffer is in the `mapped` state.
"GPUBindGroupLayout": |
  The `GPUBindGroupLayout` interface defines the structure that specifies how resources are bound in a [GPUBindGroup] and made accessible to shader stages. This layout is crucial for organizing and managing bindings efficiently within the WebGPU pipeline.
  
  **Inheritance:**
  - Implements `AutoCloseable`
  - Inherits from [GPUObjectBase]
  
  **Notes:**
  - The `GPUBindGroupLayout` is immutable once created.
  - It must be properly closed to free up resources when no longer needed.
  
  **See Also:**
  - [WebGPU Specification: GPUBindGroupLayout](https://www.w3.org/TR/webgpu/#gpubindgrouplayout)
"GPUBindGroup": |
  A `GPUBindGroup` defines a set of resources to be bound together in a group and specifies how these resources are used in shader stages. This interface is essential for managing the binding of buffers, textures, samplers, and other resources that shaders need during rendering.
  
  The `GPUBindGroup` interface extends [GPUObjectBase], which provides common functionality for GPU objects such as reference counting and lifecycle management. It also implements `AutoCloseable`, allowing for proper resource cleanup when the bind group is no longer needed.
  
  For more details, refer to the [WebGPU specification section on GPUBindGroup](https://www.w3.org/TR/webgpu/#gpubindgroup).
  
  **See Also:**
  - [GPUObjectBase]
"GPUPipelineLayout": |
  A [GPUPipelineLayout](https://www.w3.org/TR/webgpu/#gpupipelinelayout) defines the mapping between resources of all [GPUBindGroup](https://www.w3.org/TR/webgpu/#gpubindgroup) objects set up during command encoding in [setBindGroup()](https://www.w3.org/TR/webgpu/#dom-gpubindingcommandsmixin-setbindgroup), and the shaders of the pipeline set by [GPURenderCommandsMixin.setPipeline] or [GPUComputePassEncoder.setPipeline].
  
  This interface extends [GPUObjectBase] and implements [AutoCloseable], allowing for proper resource management.
  
  **See Also:**
  - [GPUObjectBase]
  - [AutoCloseable](https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-auto-closeable/)
"GPUShaderModule": |
  The `GPUShaderModule` interface represents a reference to an internal shader module object in the WebGPU API. This interface is used to manage and interact with shader modules, which contain the compiled code for shaders.
  
  A shader module is created from shader source code or precompiled binary data and can be used to create pipeline objects that define how rendering operations are performed.
  
  For more details, refer to the [WebGPU specification on GPUShaderModule](https://www.w3.org/TR/webgpu/#shader-module).
  
  **Inheritance:**
  - `GPUObjectBase`
  - `AutoCloseable`
"GPUShaderModule#getCompilationInfo()": |
  Retrieves the compilation information for the shader module. This method returns a `Result` object that contains either the `GPUCompilationInfo` or an error indicating why the compilation failed.
  
  **Returns:**
  - A `Result<GPUCompilationInfo>` containing the compilation information if successful, or an error otherwise.
"GPUComputePipeline": |
  A [GPUComputePipeline](https://www.w3.org/TR/webgpu/#gpucomputepipeline) is a specialized type of pipeline that controls the compute shader stage. It is used within a [GPUComputePassEncoder](https://www.w3.org/TR/webgpu/#gpucomputepassencoder) to execute compute shaders, which are essential for general-purpose computations on the GPU.
  
  This interface extends [GPUObjectBase], [GPUPipelineBase], and implements [AutoCloseable](https://kotlinlang.org/api/latest/jvm/stdlib/kotlin.io/-auto-closeable/). It provides methods to manage the lifecycle of compute pipelines, ensuring that resources are properly released when they are no longer needed.
  
  **Important Notes:**
  - Ensure that the `pipelineDescriptor` is correctly configured with the necessary shader module and other parameters.
  - Properly manage the lifecycle of the pipeline by closing it when it is no longer needed to avoid memory leaks.
  
  **See Also:**
  - [GPUComputePassEncoder](https://www.w3.org/TR/webgpu/#gpucomputepassencoder)
  - [GPUPipelineBase]
"GPUCommandBuffer": |
  The `GPUCommandBuffer` interface represents a command buffer in the WebGPU API. It is used to encapsulate a list of GPU commands that can be executed on the [Queue timeline](https://www.w3.org/TR/webgpu/#queue-timeline).
  
  This interface inherits from [`GPUObjectBase`](https://www.w3.org/TR/webgpu/#gpuobjectbase) and implements `AutoCloseable`, allowing for proper resource management.
  
  ### Device Timeline Properties
  
  - **[[command_list]]**: A read-only list of [GPU commands](https://www.w3.org/TR/webgpu/#gpu-command) to be executed when this command buffer is submitted. This property is essential for managing the sequence of operations that will be performed on the GPU.
  
  - **[[renderState]]**: The current state used by any render pass commands being executed. Initially, this property is `null`, but it can be set to a valid [RenderState](https://www.w3.org/TR/webgpu/#renderstate) during the execution of render passes.
  
  In this example, a `GPUCommandBuffer` is created using the `device.createCommandBuffer()` method. Commands are added to the command buffer within a render pass, and finally, the command buffer is submitted to the queue for execution.
  
  ### Notes
  
  - The `GPUCommandBuffer` interface is designed to be used in conjunction with other WebGPU interfaces such as [`GPUDevice`](https://www.w3.org/TR/webgpu/#gpudevice) and [`GPUQueue`](https://www.w3.org/TR/webgpu/#gpuqueue).
  - Proper management of command buffers is crucial for efficient GPU resource utilization. Always ensure that command buffers are properly closed after use to avoid memory leaks.
"GPUCommandEncoder": |
  The `GPUCommandEncoder` interface represents a command encoder that allows the creation of command buffers for rendering and compute operations. It is part of the WebGPU API, which provides low-level access to GPU capabilities.
  
  This interface includes methods for beginning render and compute passes, copying data between buffers and textures, clearing buffers, resolving query sets, and finishing command encoding.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#command-encoder).
  
  **Included Interfaces:**
  - `GPUObjectBase`: Provides base functionality for GPU objects.
  - `GPUCommandsMixin`: Mixin interface for common GPU commands.
  - `GPUDebugCommandsMixin`: Mixin interface for debug-related GPU commands.
  
  **See Also:**
  - [GPURenderPassEncoder](https://www.w3.org/TR/webgpu/#gpurenderpassencoder)
  - [GPUComputePassEncoder](https://www.w3.org/TR/webgpu/#gpucomputepassencoder)
"GPUCommandEncoder#beginRenderPass(descriptor)": |
  Begins a render pass using the specified descriptor. This method returns a `GPURenderPassEncoder` that can be used to record rendering commands.
  
  **Parameters:**
  - `descriptor`: A `GPURenderPassDescriptor` object that specifies the configuration for the render pass.
  
  **Returns:**
  - A `GPURenderPassEncoder` instance that can be used to record rendering commands within the render pass.
  
  **See Also:**
  - [GPURenderPassDescriptor](https://www.w3.org/TR/webgpu/#dictdef-gpurenderpassdescriptor)
"GPUCommandEncoder#beginComputePass(descriptor)": |
  Begins a compute pass using the specified descriptor. This method returns a `GPUComputePassEncoder` that can be used to record compute commands.
  
  **Parameters:**
  - `descriptor`: An optional `GPUComputePassDescriptor` object that specifies the configuration for the compute pass. If not provided, default values are used.
  
  **Returns:**
  - A `GPUComputePassEncoder` instance that can be used to record compute commands within the compute pass.
  
  **See Also:**
  - [GPUComputePassDescriptor](https://www.w3.org/TR/webgpu/#dictdef-gpucomputepassdescriptor)
"GPUCommandEncoder#copyBufferToBuffer(source, sourceOffset, destination, destinationOffset, size)": |
  Copies data from one buffer to another. This method allows for efficient data transfer between GPU buffers.
  
  **Parameters:**
  - `source`: The source `GPUBuffer` from which data will be copied.
  - `sourceOffset`: The offset within the source buffer where the copy operation will start.
  - `destination`: The destination `GPUBuffer` to which data will be copied.
  - `destinationOffset`: The offset within the destination buffer where the copy operation will start.
  - `size`: An optional parameter specifying the size of the data to be copied. If not provided, the entire range from `sourceOffset` to the end of the source buffer is copied.
  
  **See Also:**
  - [GPUBuffer](https://www.w3.org/TR/webgpu/#gpubuffer)
"GPUComputePassEncoder": |
  The `GPUComputePassEncoder` interface represents a compute pass encoder, which is used to encode commands for a compute pass. This interface allows you to set the pipeline, dispatch workgroups, and end the compute pass.
  
  A compute pass encoder is created by a [GPUCommandEncoder] and is used to record commands that will be executed on the GPU. The primary purpose of this interface is to manage the execution of compute shaders, which are used for general-purpose computations on the GPU.
  
  **Inherited from:**
  - [GPUObjectBase]
  - [GPUCommandsMixin]
  - [GPUDebugCommandsMixin]
  - [GPUBindingCommandsMixin]
  
  **Device Timeline Properties:**
  - `[[command_encoder]]`: The GPUCommandEncoder that created this compute pass encoder.
  - `[[endTimestampWrite]]`: A GPU command, if any, writing a timestamp when the pass ends. Defaults to null.
  - `[[pipeline]]`: The current [GPUComputePipeline]. Initially null.
"GPUComputePassEncoder#setPipeline(pipeline)": |
  Sets the compute pipeline for this compute pass encoder.
  
  **Parameters:**
  - `pipeline`: The [GPUComputePipeline] to set for this compute pass encoder.
  
  **Returns:** Nothing
"GPUComputePassEncoder#dispatchWorkgroups(workgroupCountX, workgroupCountY, workgroupCountZ)": |
  Dispatches the specified number of workgroups to be executed by the compute pipeline.
  
  **Parameters:**
  - `workgroupCountX`: The number of workgroups to dispatch in the X dimension. Must be greater than 0.
  - `workgroupCountY`: (Optional) The number of workgroups to dispatch in the Y dimension. Defaults to 1 if not specified.
  - `workgroupCountZ`: (Optional) The number of workgroups to dispatch in the Z dimension. Defaults to 1 if not specified.
  
  **Returns:** Nothing
"GPUComputePassEncoder#dispatchWorkgroupsIndirect(indirectBuffer, indirectOffset)": |
  Dispatches the specified number of workgroups to be executed by the compute pipeline using an indirect buffer.
  
  **Parameters:**
  - `indirectBuffer`: The [GPUBuffer] containing the indirect parameters.
  - `indirectOffset`: The offset in bytes within the indirect buffer where the indirect parameters start.
  
  **Returns:** Nothing
"GPUComputePassEncoder#end()": |
  Ends the compute pass encoder.
  
  **Returns:** Nothing
  
  This method finalizes the commands recorded by the `GPUComputePassEncoder`. It must be called to complete the encoding of a compute pass. After calling this method, no further commands can be added to the encoder.
"GPURenderCommandsMixin": |
  The `GPURenderCommandsMixin` interface defines rendering commands that are common to both [GPURenderPassEncoder](https://www.w3.org/TR/webgpu/#gpurenderpassencoder) and [GPURenderBundleEncoder](https://www.w3.org/TR/webgpu/#gpurenderbundleencoder). This mixin is used to encapsulate the rendering commands that can be executed within a render pass or bundle.
  
  The `GPURenderCommandsMixin` assumes the presence of members from [GPUObjectBase](https://www.w3.org/TR/webgpu/#gpuobjectbase), [GPUCommandsMixin](https://www.w3.org/TR/webgpu/#gpucommandsmixin), and [GPUBindingCommandsMixin](https://www.w3.org/TR/webgpu/#gpubindingcommandsmixin) on the same object. It must only be included by interfaces that also include those mixins.
"GPURenderCommandsMixin#setPipeline(pipeline)": |
  Sets the rendering pipeline to be used for subsequent drawing commands.
  
  **Parameters:**
  - `pipeline`: The [GPURenderPipeline](https://www.w3.org/TR/webgpu/#gpurenderpipeline) to set as the current pipeline.
"GPURenderCommandsMixin#setIndexBuffer(buffer, indexFormat, offset, size)": |
  Sets the index buffer to be used for indexed drawing commands.
  
  **Parameters:**
  - `buffer`: The [GPUBuffer](https://www.w3.org/TR/webgpu/#gpubuffer) containing the index data.
  - `indexFormat`: The format of the indices in the buffer, specified as a [GPUIndexFormat](https://www.w3.org/TR/webgpu/#enumdef-gpuindexformat).
  - `offset`: An optional offset within the buffer where the index data starts. Defaults to 0.
  - `size`: An optional size of the index data in bytes. If not specified, the entire buffer is used.
"GPURenderCommandsMixin#setVertexBuffer(slot, buffer, offset, size)": |
  Sets the vertex buffer at a specific slot to be used for subsequent drawing commands.
  
  **Parameters:**
  - `slot`: The index of the vertex buffer slot.
  - `buffer`: The [GPUBuffer](https://www.w3.org/TR/webgpu/#gpubuffer) containing the vertex data. Can be null to unset the buffer.
  - `offset`: An optional offset within the buffer where the vertex data starts. Defaults to 0.
  - `size`: An optional size of the vertex data in bytes. If not specified, the entire buffer is used.
"GPURenderCommandsMixin#draw(vertexCount, instanceCount, firstVertex, firstInstance)": |
  Issues a draw command to render vertices.
  
  **Parameters:**
  - `vertexCount`: The number of vertices to draw.
  - `instanceCount`: An optional number of instances to draw. Defaults to 1.
  - `firstVertex`: An optional offset into the vertex buffer. Defaults to 0.
  - `firstInstance`: An optional offset into the instance data. Defaults to 0.
"GPUQueue": |
  The `GPUQueue` interface represents a queue that allows for the submission of command buffers and other operations related to GPU execution. It is part of the WebGPU API, providing a way to manage and execute commands on the GPU.
  
  This interface inherits from [GPUObjectBase](https://www.w3.org/TR/webgpu/#gpuobjectbase), which provides basic object management functionality.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#gpuqueue).
"GPUQueue#submit(commandBuffers)": |
  Submits a list of command buffers to the GPU queue for execution. This method allows you to enqueue commands that will be processed by the GPU in the order they are submitted.
  
  @param commandBuffers A list of [GPUCommandBuffer](https://www.w3.org/TR/webgpu/#gpucommandbuffer) objects to be executed.
"GPUQueue#onSubmittedWorkDone()": |
  Returns a promise that resolves when all previously submitted work is complete. This method can be used to synchronize GPU operations and ensure that certain tasks have finished executing before proceeding with other operations.
  
  @return A [Result](https://kotlinlang.org/api/latest/kotlinx-coroutines/core/kotlinx.coroutines/-result/) object that completes when the submitted work is done.
"GPUQueue#writeBuffer(buffer, bufferOffset, data, dataOffset, size)": |
  Writes data from a buffer source to a GPU buffer. This method allows you to transfer data from a host buffer (e.g., an ArrayBuffer) to a GPU buffer for use in GPU operations.
  
  @param buffer The [GPUBuffer](https://www.w3.org/TR/webgpu/#gpubuffer) object to which the data will be written.
  @param bufferOffset The offset within the GPU buffer where the data will be written.
  @param data The source data to be written to the GPU buffer. This can be an [ArrayBuffer](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/ArrayBuffer).
  @param dataOffset The offset within the source data from which to start reading. Defaults to 0.
  @param size The number of bytes to write. If null, the entire buffer is written.
"GPUQueue#writeTexture(destination, data, dataLayout, size)": |
  Writes texture data from a buffer source to a GPU texture. This method allows you to transfer texture data from a host buffer to a GPU texture for use in rendering operations.
  
  @param destination The [GPUTexelCopyTextureInfo](https://www.w3.org/TR/webgpu/#gputexelcopytextureinfo) object specifying the destination texture and its properties.
  @param data The source data to be written to the GPU texture. This can be an [ArrayBuffer](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/ArrayBuffer).
  @param dataLayout The [GPUTexelCopyBufferLayout](https://www.w3.org/TR/webgpu/#gputexelcopybufferlayout) object specifying the layout of the source data.
  @param size The extent of the texture data to be written.
"GPUQuerySet": |
  Represents a set of queries in the WebGPU API. A `GPUQuerySet` is used to manage and retrieve information about GPU operations such as occlusion queries, pipeline statistics queries, etc.
  
  This interface inherits from [GPUObjectBase](https://www.w3.org/TR/webgpu/#gpuobjectbase) and implements [AutoCloseable](https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-auto-closeable/) to ensure proper resource management. The `destroy` method must be called to release the resources associated with this query set.
  
  For more details, refer to the [WebGPU specification on GPUQuerySet](https://www.w3.org/TR/webgpu/#gpuqueryset).
"GPUQuerySet#type": |
  The type of the queries managed by this `GPUQuerySet`. This property is read-only and specifies the kind of queries that can be performed using this query set.
"GPUQuerySet#count": |
  The number of queries managed by this `GPUQuerySet`. This property is read-only and indicates the total count of queries that can be performed using this query set.
"GPUError": |
  The `GPUError` interface represents the base class for all errors that can be surfaced from WebGPU operations. This includes errors returned by [popErrorScope()] and those triggered by the `uncapturederror` event.
  
  **Context:** Errors are generated under specific conditions defined in the respective algorithms of WebGPU operations. No errors are generated from a lost device. For more details, refer to the [Errors & Debugging section] of the WebGPU specification.
  
  **Note:** Future versions of this specification may introduce new subtypes of `GPUError`. Applications should handle this possibility by using the error's `message` property when possible and specializing using `instanceof`. Use `error.constructor.name` for serialization purposes, such as generating debug reports.
"GPUError#message": |
  A read-only string that provides a human-readable message describing the error.
  
  **Behavior:** This property contains a descriptive message that can be used to understand the nature of the error. It is particularly useful for debugging and logging purposes.
"GPUDeviceDescriptor": |
  The `GPUDeviceDescriptor` interface describes a device request. It specifies the features, limits, and default queue descriptor required by the GPU device.
  
  This interface is used to configure the creation of a [GPUDevice] object, which represents a GPU adapter and provides methods for creating GPU resources such as buffers, textures, and pipelines.
  
  For more details, refer to the [WebGPU specification on `GPUDeviceDescriptor`](https://www.w3.org/TR/webgpu/#gpudevicedescriptor).
"GPUDeviceDescriptor#requiredFeatures": |
  Specifies the features that are required by the device request. The request will fail if the adapter cannot provide these features.
  
  Exactly the specified set of features, and no more or less, will be allowed in validation of API calls on the resulting device.
  
  For more details, refer to the [WebGPU specification on `requiredFeatures`](https://www.w3.org/TR/webgpu/#dom-gpudevicedescriptor-requiredfeatures).
"GPUDeviceDescriptor#requiredLimits": |
  Specifies the limits that are required by the device request. The request will fail if the adapter cannot provide these limits.
  
  Each key with a non-`undefined` value must be the name of a member of [supported limits](https://www.w3.org/TR/webgpu/#supported-limits).
  
  API calls on the resulting device perform validation according to the exact limits of the device (not the adapter; see [§ 3.6.2 Limits](https://www.w3.org/TR/webgpu/#limits)).
  
  For more details, refer to the [WebGPU specification on `requiredLimits`](https://www.w3.org/TR/webgpu/#dom-gpudevicedescriptor-requiredlimits).
"GPUDeviceDescriptor#defaultQueue": |
  The descriptor for the default [GPUQueue].
  
  For more details, refer to the [WebGPU specification on `defaultQueue`](https://www.w3.org/TR/webgpu/#dom-gpudevicedescriptor-defaultqueue).
"GPUDeviceDescriptor#onUncapturedError": |
  An optional callback function used to handle uncaptured GPU errors associated with a GPU device.
  
  This property can be set to a user-defined [GPUUncapturedErrorCallback] to intercept and process
  uncaptured errors triggered by WebGPU operations. These errors might otherwise not be explicitly
  handled by the application, such as those originating from the `uncapturederror` event.
  
  Assigning a value to this property provides a mechanism for developers to log, debug, or respond
  to uncaptured errors in a centralized manner, improving error-handling workflows for GPU-related
  operations.
  
  If set to `null`, no callback will be executed for uncaptured errors.
"GPUBufferDescriptor": |
  Represents a descriptor for creating GPU buffers. This interface extends [GPUObjectDescriptorBase](https://www.w3.org/TR/webgpu/#gpuobjectdescriptorbase) and is used to specify the properties of a buffer, such as its size, usage flags, and whether it should be mapped at creation.
  
  For more details, refer to the [WebGPU specification on GPUBufferDescriptor](https://www.w3.org/TR/webgpu/#gpubufferdescriptor).
"GPUBufferDescriptor#size": |
  The size of the buffer in bytes. This value must be a multiple of 4 and greater than or equal to 4.
"GPUBufferDescriptor#usage": |
  Specifies the allowed usages for the buffer. This is a bitmask of [GPUBufferUsageFlags](https://www.w3.org/TR/webgpu/#typedefdef-gpubufferusageflags) that indicates how the buffer will be used.
"GPUBufferDescriptor#mappedAtCreation": |
  Indicates whether the buffer should be created in an already mapped state. If `true`, the buffer can be immediately accessed using [getMappedRange()](https://www.w3.org/TR/webgpu/#dom-gpubuffer-getmappedrange). This is useful for setting the buffer's initial data.
"GPUTextureDescriptor": |
  Represents a descriptor for creating GPU textures. This interface extends [GPUObjectDescriptorBase](https://www.w3.org/TR/webgpu/#gpuobjectdescriptorbase) and defines the properties required to specify the characteristics of a texture.
  
  For more details, refer to the [WebGPU specification on GPUTextureDescriptor](https://www.w3.org/TR/webgpu/#gputexturedescriptor).
"GPUTextureDescriptor#size": |
  Specifies the size of the texture in 3D space. This is a required property.
"GPUTextureDescriptor#mipLevelCount": |
  Specifies the number of mipmap levels in the texture. The default value is 1.
"GPUTextureDescriptor#sampleCount": |
  Specifies the number of samples for multisampling. The default value is 1.
"GPUTextureDescriptor#dimension": |
  Specifies the dimension of the texture. The default value is "2d".
"GPUTextureDescriptor#format": |
  Specifies the format of the texture data. This is a required property.
"GPUTexelCopyBufferLayout": |
  The `GPUTexelCopyBufferLayout` interface describes the layout of texels in a buffer of bytes during a texel copy operation. This interface is used to define how data is organized in a [GPUBuffer](https://www.w3.org/TR/webgpu/#gpubuffer) or an [AllowSharedBufferSource](https://webidl.spec.whatwg.org/#AllowSharedBufferSource) when performing texel copy operations.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#gputexelcopybufferlayout).
"GPUTexelCopyBufferLayout#offset": |
  The `offset` property specifies the starting offset in bytes from the beginning of the buffer where the texel data begins. This value is of type [GPUSize64], which represents a 64-bit unsigned integer.
"GPUTexelCopyBufferLayout#bytesPerRow": |
  The `bytesPerRow` property specifies the number of bytes per row in the texel data. This value is of type [GPUSize32], which represents a 32-bit unsigned integer.
"GPUTexelCopyBufferLayout#rowsPerImage": |
  The `rowsPerImage` property specifies the number of rows per image in the texel data. This value is of type [GPUSize32], which represents a 32-bit unsigned integer.
"GPUTexelCopyBufferInfo": |
  The `GPUTexelCopyBufferInfo` interface describes the information about a buffer source or destination of a texel copy operation. This includes details such as the buffer itself and its layout.
  
  Together with the `copySize`, it defines the footprint of a region of texels in a [GPUBuffer](https://www.w3.org/TR/webgpu/#gpubuffer). This interface is essential for operations that involve copying texel data between buffers and textures.
  
  For more details, refer to the [WebGPU specification on GPUTexelCopyBufferInfo](https://www.w3.org/TR/webgpu/#gputexelcopybufferinfo).
"GPUTexelCopyBufferInfo#buffer": |
  The `buffer` property represents a buffer that either contains texel data to be copied or will store the texel data being copied, depending on the method it is being passed to.
  
  This property is of type [GPUBuffer](https://www.w3.org/TR/webgpu/#gpubuffer) and must be a valid GPU buffer. The validity of this buffer is checked during the validation process of `GPUTexelCopyBufferInfo`.
"GPUQueueDescriptor": |
  The `GPUQueueDescriptor` interface describes a queue request in the WebGPU API. This dictionary inherits from [GPUObjectDescriptorBase](https://www.w3.org/TR/webgpu/#dictdef-gpuobjectdescriptorbase), which means it includes all properties and methods defined by that base class.
  
  The `GPUQueueDescriptor` is used to configure and create GPU queues, which are responsible for submitting commands to the GPU. This interface does not define any additional properties beyond those inherited from [GPUObjectDescriptorBase].
  
  **See Also:**
  - [GPUObjectDescriptorBase](https://www.w3.org/TR/webgpu/#dictdef-gpuobjectdescriptorbase) for inherited properties and methods.
"GPUSupportedLimits#maxDynamicStorageBuffersPerPipelineLayout": |
  The maximum number of dynamic storage buffers per pipeline layout. This value represents the largest allowable number of dynamic storage buffers for a single pipeline layout.
"GPUSupportedLimits#maxSampledTexturesPerShaderStage": |
  The maximum number of sampled textures per shader stage. This value represents the largest allowable number of sampled textures for a single shader stage.
"GPUSupportedLimits#maxSamplersPerShaderStage": |
  The maximum number of samplers per shader stage. This value represents the largest allowable number of samplers for a single shader stage.
"GPUSupportedLimits#maxStorageBuffersPerShaderStage": |
  The maximum number of storage buffers per shader stage. This value represents the largest allowable number of storage buffers for a single shader stage.
"GPUSupportedLimits#maxStorageTexturesPerShaderStage": |
  The maximum number of storage textures per shader stage. This value represents the largest allowable number of storage textures for a single shader stage.
"GPUSupportedLimits#maxUniformBuffersPerShaderStage": |
  The maximum number of uniform buffers per shader stage. This value represents the largest allowable number of uniform buffers for a single shader stage.
"GPUSupportedLimits#maxUniformBufferBindingSize": |
  The maximum size of a uniform buffer binding. This value represents the largest allowable size for a single uniform buffer binding in bytes.
"GPUSupportedLimits#maxStorageBufferBindingSize": |
  The maximum size of a storage buffer binding. This value represents the largest allowable size for a single storage buffer binding in bytes.
"GPUSupportedLimits#minUniformBufferOffsetAlignment": |
  The minimum alignment for uniform buffer offsets. This value represents the smallest allowable offset alignment for a uniform buffer in bytes.
"GPUSupportedLimits#minStorageBufferOffsetAlignment": |
  The minimum alignment for storage buffer offsets. This value represents the smallest allowable offset alignment for a storage buffer in bytes.
"GPUSupportedLimits#maxVertexBuffers": |
  The maximum number of vertex buffers that can be used in a single pipeline. This value represents the largest allowable number of vertex buffers for a pipeline.
"GPUSupportedLimits#maxBufferSize": |
  The maximum size of a buffer. This value represents the largest allowable size for a single buffer in bytes.
"GPUSupportedLimits#maxVertexAttributes": |
  The maximum number of vertex attributes that can be used in a single pipeline. This value represents the largest allowable number of vertex attributes for a pipeline.
"GPUSupportedLimits#maxVertexBufferArrayStride": |
  The maximum stride for a vertex buffer array. This value represents the largest allowable stride for a single vertex buffer array in bytes.
"GPUSupportedLimits#maxInterStageShaderVariables": |
  The maximum number of inter-stage shader variables that can be used in a single pipeline. This value represents the largest allowable number of inter-stage shader variables for a pipeline.
"GPUSupportedLimits#maxColorAttachments": |
  The maximum number of color attachments that can be used in a single render pass. This value represents the largest allowable number of color attachments for a render pass.
"GPUSupportedLimits#maxColorAttachmentBytesPerSample": |
  The maximum number of bytes per sample for a color attachment. This value represents the largest allowable number of bytes per sample for a single color attachment.
"GPUSupportedLimits#maxComputeWorkgroupStorageSize": |
  The maximum size of storage for a compute workgroup. This value represents the largest allowable size for a single compute workgroup's storage in bytes.
"GPUSupportedLimits#maxComputeInvocationsPerWorkgroup": |
  The maximum number of compute invocations per workgroup. This value represents the largest allowable number of compute invocations for a single workgroup.
"GPUSupportedLimits#maxComputeWorkgroupSizeX": |
  The maximum size for the X dimension of a compute workgroup. This value represents the largest allowable size for the X dimension of a single compute workgroup.
"GPUSupportedLimits#maxComputeWorkgroupSizeY": |
  The maximum size for the Y dimension of a compute workgroup. This value represents the largest allowable size for the Y dimension of a single compute workgroup.
"GPUSupportedLimits#maxComputeWorkgroupSizeZ": |
  The maximum size for the Z dimension of a compute workgroup. This value represents the largest allowable size for the Z dimension of a single compute workgroup.
"GPUSupportedLimits#maxComputeWorkgroupsPerDimension": |
  The maximum number of compute workgroups per dimension. This value represents the largest allowable number of compute workgroups for a single dimension.
"GPUDevice#createBindGroupLayout(descriptor)": |
  Creates a new bind group layout object based on the provided descriptor.
  
  **Parameters:**
  - `descriptor`: A [GPUBindGroupLayoutDescriptor] that specifies the properties of the bind group layout to be created.
  
  **Returns:** A new [GPUBindGroupLayout] object.
  
  **See also:**
  - [WebGPU Specification: createBindGroupLayout](https://www.w3.org/TR/webgpu/#dom-gpudevice-createbindgrouplayout)
"GPUDevice#createPipelineLayout(descriptor)": |
  Creates a new pipeline layout object based on the provided descriptor.
  
  **Parameters:**
  - `descriptor`: A [GPUPipelineLayoutDescriptor] that specifies the properties of the pipeline layout to be created.
  
  **Returns:** A new [GPUPipelineLayout] object.
  
  **See also:**
  - [WebGPU Specification: createPipelineLayout](https://www.w3.org/TR/webgpu/#dom-gpudevice-createpipelinelayout)
"GPUDevice#createBindGroup(descriptor)": |
  Creates a new bind group object based on the provided descriptor.
  
  **Parameters:**
  - `descriptor`: A [GPUBindGroupDescriptor] that specifies the properties of the bind group to be created.
  
  **Returns:** A new [GPUBindGroup] object.
  
  **See also:**
  - [WebGPU Specification: createBindGroup](https://www.w3.org/TR/webgpu/#dom-gpudevice-createbindgroup)
"GPUDevice#createShaderModule(descriptor)": |
  Creates a new shader module object based on the provided descriptor.
  
  **Parameters:**
  - `descriptor`: A [GPUShaderModuleDescriptor] that specifies the properties of the shader module to be created.
  
  **Returns:** A new [GPUShaderModule] object.
  
  **See also:**
  - [WebGPU Specification: createShaderModule](https://www.w3.org/TR/webgpu/#dom-gpudevice-createshadermodule)
"GPUDevice#createComputePipeline(descriptor)": |
  Creates a new compute pipeline object based on the provided descriptor.
  
  **Parameters:**
  - `descriptor`: A [GPUComputePipelineDescriptor] that specifies the properties of the compute pipeline to be created.
  
  **Returns:** A new [GPUComputePipeline] object.
  
  **See also:**
  - [WebGPU Specification: createComputePipeline](https://www.w3.org/TR/webgpu/#dom-gpudevice-createcomputepipeline)
"GPUDevice#createRenderPipeline(descriptor)": |
  Creates a new render pipeline object based on the provided descriptor.
  
  **Parameters:**
  - `descriptor`: A [GPURenderPipelineDescriptor] that specifies the properties of the render pipeline to be created.
  
  **Returns:** A new [GPURenderPipeline] object.
  
  **See also:**
  - [WebGPU Specification: createRenderPipeline](https://www.w3.org/TR/webgpu/#dom-gpudevice-createrenderpipeline)
"GPUDevice#createComputePipelineAsync(descriptor)": |
  Asynchronously creates a new compute pipeline object based on the provided descriptor.
  
  **Parameters:**
  - `descriptor`: A [GPUComputePipelineDescriptor] that specifies the properties of the compute pipeline to be created.
  
  **Returns:** A [Result] containing the newly created [GPUComputePipeline] object or an error if the creation fails.
  
  **See also:**
  - [WebGPU Specification: createComputePipelineAsync](https://www.w3.org/TR/webgpu/#dom-gpudevice-createcomputepipelineasync)
"GPUDevice#createRenderPipelineAsync(descriptor)": |
  Asynchronously creates a new render pipeline object based on the provided descriptor.
  
  **Parameters:**
  - `descriptor`: A [GPURenderPipelineDescriptor] that specifies the properties of the render pipeline to be created.
  
  **Returns:** A [Result] containing the newly created [GPURenderPipeline] object or an error if the creation fails.
  
  **See also:**
  - [WebGPU Specification: createRenderPipelineAsync](https://www.w3.org/TR/webgpu/#dom-gpudevice-createrenderpipelineasync)
"GPUDevice#createCommandEncoder(descriptor)": |
  Creates a new command encoder object based on the provided descriptor.
  
  **Parameters:**
  - `descriptor`: An optional [GPUCommandEncoderDescriptor] that specifies the properties of the command encoder to be created. If not provided, default values are used.
  
  **Returns:** A new [GPUCommandEncoder] object.
  
  **See also:**
  - [WebGPU Specification: createCommandEncoder](https://www.w3.org/TR/webgpu/#dom-gpudevice-createcommandencoder)
"GPUDevice#createRenderBundleEncoder(descriptor)": |
  Creates a new render bundle encoder object based on the provided descriptor.
  
  **Parameters:**
  - `descriptor`: A [GPURenderBundleEncoderDescriptor] that specifies the properties of the render bundle encoder to be created.
  
  **Returns:** A new [GPURenderBundleEncoder] object.
  
  **See also:**
  - [WebGPU Specification: createRenderBundleEncoder](https://www.w3.org/TR/webgpu/#dom-gpudevice-createrenderbundleencoder)
"GPUDevice#createQuerySet(descriptor)": |
  Creates a new query set object based on the provided descriptor.
  
  **Parameters:**
  - `descriptor`: A [GPUQuerySetDescriptor] that specifies the properties of the query set to be created.
  
  **Returns:** A new [GPUQuerySet] object.
  
  **See also:**
  - [WebGPU Specification: createQuerySet](https://www.w3.org/TR/webgpu/#dom-gpudevice-createqueryset)
"GPUDevice#pushErrorScope(filter)": |
  Pushes an error scope onto the device's error stack with the specified filter.
  
  **Parameters:**
  - `filter`: A [GPUErrorFilter] that specifies which errors should be captured within this scope.
  
  **See also:**
  - [WebGPU Specification: pushErrorScope](https://www.w3.org/TR/webgpu/#dom-gpudevice-pusherrorscope)
"GPUDevice#popErrorScope()": |
  Pops the top error scope from the device's error stack and returns any captured errors.
  
  **Returns:** A [Result] containing a [GPUError] object if an error was captured, or `null` if no error occurred.
  
  **See also:**
  - [WebGPU Specification: popErrorScope](https://www.w3.org/TR/webgpu/#dom-gpudevice-poperrorscope)
"GPUTexture": |
  Represents a texture in the WebGPU API. A texture is composed of 1D, 2D, or 3D arrays of data that can contain multiple values per element to represent things like colors.
  Textures can be read and written in various ways depending on their usage flags. They are often stored in GPU memory with a layout optimized for multidimensional access.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#texture-interface).
"GPUTexture#width": |
  Represents the width of the texture in texels.
"GPUTexture#height": |
  Represents the height of the texture in texels.
"GPUTexture#depthOrArrayLayers": |
  Represents the depth of the texture in texels for 3D textures or the number of array layers for 2D array textures.
"GPUTexture#mipLevelCount": |
  Represents the number of mipmap levels in the texture.
"GPUTexture#sampleCount": |
  Represents the number of samples per pixel in the texture.
"GPUTexture#dimension": |
  Specifies the dimension of the texture (1D, 2D, or 3D).
"GPUTexture#format": |
  Specifies the format of the texture data.
"GPUTexture#usage": |
  Specifies the usage flags for the texture, indicating how it can be used (e.g., as a render target, sampler, etc.).
"GPUTexture#createView(descriptor)": |
  Creates a view of the texture.
  
  **Parameters:**
  - `descriptor`: An optional [GPUTextureViewDescriptor](https://www.w3.org/TR/webgpu/#dictdef-gputextureviewdescriptor) that specifies the parameters for creating the texture view. If not provided, default values are used.
  
  **Return Type:** [GPUTextureView](https://www.w3.org/TR/webgpu/#gputextureview)
"GPUCommandEncoder#copyBufferToTexture(source, destination, copySize)": |
  Copies data from a buffer to a texture. This method allows for efficient transfer of data from a GPU buffer to a GPU texture.
  
  **Parameters:**
  - `source`: A `GPUTexelCopyBufferInfo` object that specifies the source buffer and its layout.
  - `destination`: A `GPUTexelCopyTextureInfo` object that specifies the destination texture and its layout.
  - `copySize`: A `GPUExtent3D` object that specifies the size of the data to be copied.
  
  **See Also:**
  - [GPUTexelCopyBufferInfo](https://www.w3.org/TR/webgpu/#gputexelcopybufferinfo)
  - [GPUTexelCopyTextureInfo](https://www.w3.org/TR/webgpu/#gputexelcopytextureinfo)
"GPUCommandEncoder#copyTextureToBuffer(source, destination, copySize)": |
  Copies data from a texture to a buffer. This method allows for efficient transfer of data from a GPU texture to a GPU buffer.
  
  **Parameters:**
  - `source`: A `GPUTexelCopyTextureInfo` object that specifies the source texture and its layout.
  - `destination`: A `GPUTexelCopyBufferInfo` object that specifies the destination buffer and its layout.
  - `copySize`: A `GPUExtent3D` object that specifies the size of the data to be copied.
  
  **See Also:**
  - [GPUTexelCopyTextureInfo](https://www.w3.org/TR/webgpu/#gputexelcopytextureinfo)
  - [GPUTexelCopyBufferInfo](https://www.w3.org/TR/webgpu/#gputexelcopybufferinfo)
"GPUCommandEncoder#copyTextureToTexture(source, destination, copySize)": |
  Copies data from one texture to another. This method allows for efficient transfer of data between GPU textures.
  
  **Parameters:**
  - `source`: A `GPUTexelCopyTextureInfo` object that specifies the source texture and its layout.
  - `destination`: A `GPUTexelCopyTextureInfo` object that specifies the destination texture and its layout.
  - `copySize`: A `GPUExtent3D` object that specifies the size of the data to be copied.
  
  **See Also:**
  - [GPUTexelCopyTextureInfo](https://www.w3.org/TR/webgpu/#gputexelcopytextureinfo)
"GPUCommandEncoder#clearBuffer(buffer, offset, size)": |
  Clears the contents of a buffer. This method sets the specified range of the buffer to zero.
  
  **Parameters:**
  - `buffer`: The `GPUBuffer` to be cleared.
  - `offset`: An optional parameter specifying the starting offset within the buffer where the clear operation will begin. Defaults to 0 if not provided.
  - `size`: An optional parameter specifying the size of the range to be cleared. If not provided, the entire range from `offset` to the end of the buffer is cleared.
  
  **See Also:**
  - [GPUBuffer](https://www.w3.org/TR/webgpu/#gpubuffer)
"GPUCommandEncoder#resolveQuerySet(querySet, firstQuery, queryCount, destination, destinationOffset)": |
  Resolves a set of queries and writes the results to a buffer. This method is used for performance monitoring and debugging.
  
  **Parameters:**
  - `querySet`: The `GPUQuerySet` containing the queries to be resolved.
  - `firstQuery`: The index of the first query in the query set to resolve.
  - `queryCount`: The number of queries to resolve starting from `firstQuery`.
  - `destination`: The `GPUBuffer` where the results of the resolved queries will be written.
  - `destinationOffset`: The offset within the destination buffer where the results will be written.
  
  **See Also:**
  - [GPUQuerySet](https://www.w3.org/TR/webgpu/#gpuqueryset)
"GPUCommandEncoder#finish(descriptor)": |
  Finishes the command encoding process and returns a `GPUCommandBuffer` that can be submitted to the GPU for execution.
  
  **Parameters:**
  - `descriptor`: An optional `GPUCommandBufferDescriptor` object that specifies configuration options for the command buffer. If not provided, default values are used.
  
  **Returns:**
  - A `GPUCommandBuffer` instance that contains all the recorded commands and can be submitted to the GPU.
  
  **See Also:**
  - [GPUCommandBuffer](https://www.w3.org/TR/webgpu/#gpucommandbuffer)
"GPURenderPassEncoder": |
  The `GPURenderPassEncoder` interface represents a render pass encoder, which is used to encode commands into a render pass. This interface allows for the configuration of various rendering states and the execution of draw calls within a render pass.
  
  A render pass encoder is created by a [GPUCommandEncoder] and is used to record commands that will be executed on the GPU. The `GPURenderPassEncoder` interface includes methods for setting viewport, scissor rectangle, blend constant, stencil reference, beginning and ending occlusion queries, executing render bundles, and ending the render pass.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#gpurenderpassencoder).
"GPURenderPassEncoder#setViewport(x, y, width, height, minDepth, maxDepth)": |
  Sets the viewport for the render pass. The viewport defines a clipping rectangle in normalized device coordinates (NDC) that specifies the region of the render target to which rendering commands are directed.
  
  **Parameters:**
  - `x`: The x-coordinate of the viewport's origin.
  - `y`: The y-coordinate of the viewport's origin.
  - `width`: The width of the viewport.
  - `height`: The height of the viewport.
  - `minDepth`: The minimum depth value for the viewport.
  - `maxDepth`: The maximum depth value for the viewport.
"GPURenderPassEncoder#setScissorRect(x, y, width, height)": |
  Sets the scissor rectangle for the render pass. The scissor rectangle defines a clipping region in pixel coordinates that restricts rendering to a specific area of the render target.
  
  **Parameters:**
  - `x`: The x-coordinate of the scissor rectangle's origin.
  - `y`: The y-coordinate of the scissor rectangle's origin.
  - `width`: The width of the scissor rectangle.
  - `height`: The height of the scissor rectangle.
"GPURenderPassEncoder#setBlendConstant(color)": |
  Sets the blend constant color for the render pass. The blend constant color is used in blending operations to provide a constant color value that can be blended with the source and destination colors.
  
  **Parameters:**
  - `color`: The blend constant color, represented as a [GPUColor](https://www.w3.org/TR/webgpu/#typedefdef-gpucolor).
"GPURenderPassEncoder#setStencilReference(reference)": |
  Sets the stencil reference value for the render pass. The stencil reference value is used in stencil testing to compare against the stencil buffer values.
  
  **Parameters:**
  - `reference`: The stencil reference value, represented as a [GPUStencilValue](https://www.w3.org/TR/webgpu/#typedefdef-gpustencilvalue).
"GPURenderPassEncoder#beginOcclusionQuery(queryIndex)": |
  Begins an occlusion query at the specified index. Occlusion queries are used to determine whether a specific region of the render target is visible or occluded by other geometry.
  
  **Parameters:**
  - `queryIndex`: The index of the occlusion query, represented as a [GPUSize32](https://www.w3.org/TR/webgpu/#typedefdef-gpusize32).
"GPURenderPassEncoder#endOcclusionQuery()": |
  Ends the current occlusion query. This method should be called after the commands that are to be tested for occlusion have been recorded.
"GPURenderPassEncoder#executeBundles(bundles)": |
  Executes a list of render bundles within the render pass. Render bundles are pre-recorded sequences of commands that can be executed multiple times with different parameters.
  
  **Parameters:**
  - `bundles`: A list of [GPURenderBundle](https://www.w3.org/TR/webgpu/#gpurenderbundle) objects to execute.
"GPURenderPassEncoder#end()": |
  Ends the render pass. This method should be called after all rendering commands have been recorded to finalize the render pass.
"GPURenderCommandsMixin#drawIndexed(indexCount, instanceCount, firstIndex, baseVertex, firstInstance)": |
  Issues an indexed draw command to render vertices using indices.
  
  **Parameters:**
  - `indexCount`: The number of indices to draw.
  - `instanceCount`: An optional number of instances to draw. Defaults to 1.
  - `firstIndex`: An optional offset into the index buffer. Defaults to 0.
  - `baseVertex`: An optional base vertex offset. Defaults to 0.
  - `firstInstance`: An optional offset into the instance data. Defaults to 0.
"GPURenderCommandsMixin#drawIndirect(indirectBuffer, indirectOffset)": |
  Issues an indirect draw command to render vertices using data from a buffer.
  
  **Parameters:**
  - `indirectBuffer`: The [GPUBuffer](https://www.w3.org/TR/webgpu/#gpubuffer) containing the indirect draw parameters.
  - `indirectOffset`: The offset within the buffer where the indirect draw parameters start.
"GPURenderCommandsMixin#drawIndexedIndirect(indirectBuffer, indirectOffset)": |
  Issues an indirect indexed draw command to render vertices using data from a buffer.
  
  **Parameters:**
  - `indirectBuffer`: The [GPUBuffer](https://www.w3.org/TR/webgpu/#gpubuffer) containing the indirect indexed draw parameters.
  - `indirectOffset`: The offset within the buffer where the indirect indexed draw parameters start.
"GPUTextureDescriptor#usage": |
  Specifies the usage flags for the texture. This is a required property.
"GPUTextureDescriptor#viewFormats": |
  Specifies a list of formats that can be used to create views of the texture. The default value is an empty list.
"GPUBindGroupLayoutEntry#storageTexture": |
  When provided, indicates that the binding resource type for this `GPUBindGroupLayoutEntry` is [GPUTextureView](https://www.w3.org/TR/webgpu/#gputextureview).
"GPUShaderModuleDescriptor": |
  Represents a descriptor for creating a [GPUShaderModule] in WebGPU. This interface extends `GPUObjectDescriptorBase` and is used to specify the WGSL source code and compilation hints required to create a shader module. The shader module is a compiled version of the shader code that can be used in rendering or compute pipelines.
  
  **See also:**
  - [W3C WebGPU Specification: GPUShaderModuleDescriptor](https://www.w3.org/TR/webgpu/#dictdef-gpushadermoduledescriptor)
"GPUShaderModuleDescriptor#code": |
  The WGSL source code for the shader module. This string contains the shader program written in the WebGPU Shading Language (WGSL). The shader code defines the vertex and fragment shaders or compute shaders that will be used in the rendering or compute pipeline.
  
  **See also:**
  - [W3C WebGPU Specification: GPUShaderModuleDescriptor.code](https://www.w3.org/TR/webgpu/#dom-gpushadermoduledescriptor-code)
"GPUShaderModuleDescriptor#compilationHints": |
  A list of `GPUShaderModuleCompilationHint` objects that provide additional information to the compiler about the shader module. These hints can include details about entry points, resource bindings, and other compilation-specific information. Providing these hints can improve performance by allowing the compiler to perform more optimizations during the creation of the shader module.

  **See also:**
  - [W3C WebGPU Specification: GPUShaderModuleDescriptor.compilationHints](https://www.w3.org/TR/webgpu/#dom-gpushadermoduledescriptor-compilationhints)
"GPUProgrammableStage": |
  Represents a programmable stage in a GPU pipeline. This interface describes the entry point in a user-provided [GPUShaderModule] that controls one of the programmable stages of a pipeline.
  Entry point names follow the rules defined in [WGSL identifier comparison](https://gpuweb.github.io/gpuweb/wgsl/#identifier-comparison).
"GPUProgrammableStage#module": |
  The shader module containing the entry point for this programmable stage. This is a required field and must be provided when creating an instance of [GPUProgrammableStage].
"GPUProgrammableStage#entryPoint": |
  The name of the entry point in the shader module. This is an optional field and can be null if not specified.
  Entry point names must follow the rules defined in [WGSL identifier comparison](https://gpuweb.github.io/gpuweb/wgsl/#identifier-comparison).
"GPUProgrammableStage#constants": |
  A map of constant values that can be passed to the shader module. The keys are strings representing the names of the constants, and the values are of type [GPUPipelineConstantValue].
  This field is optional and defaults to an empty map if not provided.
"GPUPrimitiveState": |
  Represents the state of a primitive in WebGPU, defining how primitives are rendered. This interface is used to configure various aspects of primitive rendering such as topology, strip index format, front face orientation, cull mode, and depth clipping behavior.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpuprimitivestate).
"GPUPrimitiveState#topology": |
  Specifies the type of primitive topology used for rendering. This determines how vertices are interpreted when drawing primitives.
  
  **See Also:**
  - [GPUPrimitiveTopology](https://www.w3.org/TR/webgpu/#enumdef-gpuprimitivetopology)
"GPUPrimitiveState#stripIndexFormat": |
  Specifies the format of the strip index buffer, if used. This is relevant when rendering primitives that use strip indexing.
  
  **See Also:**
  - [GPUIndexFormat](https://www.w3.org/TR/webgpu/#enumdef-gpuindexformat)
"GPUPrimitiveState#frontFace": |
  Specifies the orientation of the front face of primitives. This determines which side of a triangle is considered the front face for culling and other operations.
  
  **See Also:**
  - [GPUFrontFace](https://www.w3.org/TR/webgpu/#enumdef-gpufrontface)
"GPUPrimitiveState#cullMode": |
  Specifies the culling mode for primitives. This determines which faces of a primitive are discarded during rendering.
  
  **See Also:**
  - [GPUCullMode](https://www.w3.org/TR/webgpu/#enumdef-gpucullmode)
"GPUPrimitiveState#unclippedDepth": |
  Specifies whether depth values are clipped or unclipped. This feature requires the `"depth-clip-control"` feature to be enabled.
  
  **See Also:**
  - [WebGPU Features](https://www.w3.org/TR/webgpu/#features)
"GPUDepthStencilState": |
  Represents the depth and stencil state configuration for a GPU render pipeline. This interface defines various properties that control how depth and stencil tests are performed during rendering.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#depth-stencil-state).
"GPUDepthStencilState#format": |
  Specifies the format of the depth/stencil texture. This property determines how depth and stencil values are stored in the texture.
"GPUDepthStencilState#depthWriteEnabled": |
  Indicates whether depth values are written to the depth buffer. When set to `true`, depth values are written; when set to `false` or `null`, depth values are not written.
"GPUDepthStencilState#depthCompare": |
  Specifies the comparison function used for depth tests. This property determines how the current depth value is compared to the stored depth value.
"GPUDepthStencilState#stencilFront": |
  Defines the stencil state for front-facing primitives. This property configures how stencil tests are performed for front-facing geometry.
"GPUDepthStencilState#stencilBack": |
  Defines the stencil state for back-facing primitives. This property configures how stencil tests are performed for back-facing geometry.
"GPUDepthStencilState#stencilReadMask": |
  Specifies the mask used for reading stencil values. This property determines which bits of the stencil value are considered during read operations.
"GPUDepthStencilState#stencilWriteMask": |
  Specifies the mask used for writing stencil values. This property determines which bits of the stencil value are modified during write operations.
"GPUDepthStencilState#depthBias": |
  Specifies the depth bias value. This property is used to adjust the depth values for polygon offset.
"GPUDepthStencilState#depthBiasSlopeScale": |
  Specifies the slope scale factor for depth bias. This property is used to adjust the depth bias based on the slope of the polygon.
"GPUDepthStencilState#depthBiasClamp": |
  Specifies the clamp value for depth bias. This property limits the maximum depth bias that can be applied.
"GPURenderPassDepthStencilAttachment": |
  The `GPURenderPassDepthStencilAttachment` interface represents a depth/stencil attachment for a render pass. It specifies the texture view and various operations to be performed on the depth and stencil components of that view during the render pass.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#gpurenderpassdepthstencilattachment).
"GPURenderPassDepthStencilAttachment#view": |
  A `GPUTextureView` describing the texture subresource that will be output to and read from for this depth/stencil attachment.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpassdepthstencilattachment-view).
"GPURenderPassDepthStencilAttachment#depthClearValue": |
  Indicates the value to clear the `view`'s depth component to prior to executing the render pass. This value is ignored if `depthLoadOp` is not set to `GPULoadOp.CLEAR`. The value must be between 0.0 and 1.0, inclusive.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpassdepthstencilattachment-depthclearvalue).
"GPURenderPassDepthStencilAttachment#depthLoadOp": |
  Indicates the load operation to perform on the `view`'s depth component prior to executing the render pass. It is recommended to prefer clearing; see `GPULoadOp.CLEAR` for details.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpassdepthstencilattachment-depthloadop).
"GPURenderPassDepthStencilAttachment#depthStoreOp": |
  The store operation to perform on the `view`'s depth component after executing the render pass.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpassdepthstencilattachment-depthstoreop).
"GPURenderPassDepthStencilAttachment#depthReadOnly": |
  Indicates that the depth component of the `view` is read-only. Defaults to `false`.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpassdepthstencilattachment-depthreadonly).
"GPURenderPassDepthStencilAttachment#stencilClearValue": |
  Indicates the value to clear the `view`'s stencil component to prior to executing the render pass. This value is ignored if `stencilLoadOp` is not set to `GPULoadOp.CLEAR`. The value will be converted to the type of the stencil aspect of the `view` by taking the same number of least significant bits (LSBs) as the number of bits in the stencil aspect of one texel of the `view`.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpassdepthstencilattachment-stencilclearvalue).
"GPURenderPassDepthStencilAttachment#stencilLoadOp": |
  Indicates the load operation to perform on the `view`'s stencil component prior to executing the render pass. It is recommended to prefer clearing; see `GPULoadOp.CLEAR` for details.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpassdepthstencilattachment-stencilloadop).
"GPURenderPassDepthStencilAttachment#stencilStoreOp": |
  The store operation to perform on the `view`'s stencil component after executing the render pass.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpassdepthstencilattachment-stencilstoreop).
"GPURenderPassDepthStencilAttachment#stencilReadOnly": |
  Indicates that the stencil component of the `view` is read-only. Defaults to `false`.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpassdepthstencilattachment-stencilreadonly).
"GPUCommandsMixin": |
  The `GPUCommandsMixin` interface defines state common to all interfaces which encode commands. This mixin does not include any methods but serves as a base for other command-encoding interfaces in the WebGPU API.
  
  **Context and Purpose:**
  This interface is part of the WebGPU specification and is used to provide a consistent way to manage command encoding across different GPU-related interfaces. It ensures that all command-encoding interfaces share a common set of properties or behaviors, even if it does not define any methods itself.
  
  **References:**
  - [WebGPU Specification: GPUCommandsMixin](https://www.w3.org/TR/webgpu/#gpucommandsmixin)
"GPURenderBundle": |
  Represents a render bundle in the WebGPU API. A `GPURenderBundle` encapsulates a list of GPU commands that can be executed by a [GPURenderPassEncoder](https://www.w3.org/TR/webgpu/#dom-gpurenderpassencoder).
    
  This interface is part of the WebGPU API, which provides a low-level, cross-platform graphics API for the web. For more details, refer to the [official W3C specification](https://www.w3.org/TR/webgpu/#gpurenderbundle).
    
  @see [GPUObjectBase](https://www.w3.org/TR/webgpu/#dom-gpuobjectbase)
"GPURequestAdapterOptions": |
  The `GPURequestAdapterOptions` interface provides hints to the user agent indicating what configuration is suitable for the application. This interface allows developers to specify preferences and constraints for the GPU adapter selection process.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpurequestadapteroptions).
"GPURequestAdapterOptions#featureLevel": |
  The `featureLevel` property specifies the feature level for the adapter request. This string value influences which features of the GPU are enabled or restricted.
  
  **Allowed Values:**
  - "core": No effect.
  - "compatibility": Reserved for future use to opt into additional validation restrictions. Applications should not use this value at this time.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurequestadapteroptions-featurelevel).
"GPURequestAdapterOptions#powerPreference": |
  The `powerPreference` property provides a hint indicating what class of adapter should be selected from the system’s available adapters. This value can influence which GPU is used in a multi-GPU system, affecting power consumption and performance.
  
  **Allowed Values:**
  - null: Provides no hint to the user agent.
  - "low-power": Indicates a request to prioritize power savings over performance.
  - "high-performance": Indicates a request to prioritize performance over power consumption.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurequestadapteroptions-powerpreference).
"GPURequestAdapterOptions#forceFallbackAdapter": |
  The `forceFallbackAdapter` property indicates whether only a fallback adapter may be returned. If set to `true`, the user agent will return a fallback adapter if available, or `null` if not supported.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurequestadapteroptions-forcefallbackadapter).
"GPURequestAdapterOptions#xrCompatible": |
  The `xrCompatible` property indicates whether the best adapter for rendering to a WebXR session must be returned. If set to `true`, the user agent will prioritize adapters suitable for WebXR rendering.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurequestadapteroptions-xrcompatible).
"GPUSamplerDescriptor": |
  The `GPUSamplerDescriptor` interface defines the properties of a sampler used in WebGPU. This descriptor specifies how textures are sampled during rendering, including addressing modes, filtering modes, and level-of-detail (LOD) clamping. It is part of the GPUObjectDescriptorBase hierarchy and is used to create `GPUSampler` objects.
  
  For more details, refer to the [WebGPU specification on GPUSamplerDescriptor](https://www.w3.org/TR/webgpu/#dictdef-gpusamplerdescriptor).
"GPUSamplerDescriptor#addressModeU": |
  Specifies the addressing mode for the U coordinate of the texture. This determines how texture coordinates are handled when they extend beyond the bounds of the texture. The default value is `GPUAddressMode.CLAMP_TO_EDGE`.
  
  For more details, refer to the [WebGPU specification on GPUAddressMode](https://www.w3.org/TR/webgpu/#enumdef-gpuaddressmode).
"GPUSamplerDescriptor#addressModeV": |
  Specifies the addressing mode for the V coordinate of the texture. This determines how texture coordinates are handled when they extend beyond the bounds of the texture. The default value is `GPUAddressMode.CLAMP_TO_EDGE`.
  
  For more details, refer to the [WebGPU specification on GPUAddressMode](https://www.w3.org/TR/webgpu/#enumdef-gpuaddressmode).
"GPUSamplerDescriptor#addressModeW": |
  Specifies the addressing mode for the W coordinate of the texture. This determines how texture coordinates are handled when they extend beyond the bounds of the texture. The default value is `GPUAddressMode.CLAMP_TO_EDGE`.
  
  For more details, refer to the [WebGPU specification on GPUAddressMode](https://www.w3.org/TR/webgpu/#enumdef-gpuaddressmode).
"GPUSamplerDescriptor#magFilter": |
  Specifies the filtering mode used when the sampled area is smaller than or equal to one texel. The default value is `GPUFilterMode.NEAREST`.
  
  For more details, refer to the [WebGPU specification on GPUFilterMode](https://www.w3.org/TR/webgpu/#enumdef-gpufiltermode).
"GPUSamplerDescriptor#minFilter": |
  Specifies the filtering mode used when the sampled area is larger than one texel. The default value is `GPUFilterMode.NEAREST`.
  
  For more details, refer to the [WebGPU specification on GPUFilterMode](https://www.w3.org/TR/webgpu/#enumdef-gpufiltermode).
"GPUSamplerDescriptor#mipmapFilter": |
  Specifies the filtering mode used when sampling between mipmap levels. The default value is `GPUMipmapFilterMode.NEAREST`.
  
  For more details, refer to the [WebGPU specification on GPUMipmapFilterMode](https://www.w3.org/TR/webgpu/#enumdef-gpumipmapfiltermode).
"GPUSamplerDescriptor#lodMinClamp": |
  Specifies the minimum level of detail (LOD) used internally when sampling a texture. The default value is `0.0`.
  
  For more details, refer to the [WebGPU specification on levels of detail](https://www.w3.org/TR/webgpu/#levels-of-detail).
"GPUSamplerDescriptor#lodMaxClamp": |
  Specifies the maximum level of detail (LOD) used internally when sampling a texture. The default value is `32.0`.
  
  For more details, refer to the [WebGPU specification on levels of detail](https://www.w3.org/TR/webgpu/#levels-of-detail).
"GPUSamplerDescriptor#compare": |
  Specifies the comparison function used by a comparison sampler. When provided, the sampler will be a comparison sampler with the specified `GPUCompareFunction`. Comparison samplers may use filtering, but the sampling results will be implementation-dependent and may differ from the normal filtering rules.
  
  For more details, refer to the [WebGPU specification on GPUCompareFunction](https://www.w3.org/TR/webgpu/#enumdef-gpucomparefunction).
"GPUSamplerDescriptor#maxAnisotropy": |
  Specifies the maximum anisotropy value clamp used by the sampler. Anisotropic filtering is enabled when `maxAnisotropy` is greater than 1 and the implementation supports it. The default value is `1`.
  
  For more details, refer to the [WebGPU specification on anisotropic filtering](https://www.w3.org/TR/webgpu/#dom-gpusamplerdescriptor-maxanisotropy).
"GPUTexelCopyTextureInfo": |
  Represents the information about a texture source or destination for a texel copy operation. This interface describes the sub-region of a texture that spans one or more contiguous texture subresources at the same mip-map level.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#gputexelcopytextureinfo).
"GPUTexelCopyTextureInfo#texture": |
  The texture to copy to or from. This is a required field and must be specified.
"GPUTexelCopyTextureInfo#mipLevel": |
  The mip-map level of the texture to copy to or from. This field defaults to `0` if not specified.
"GPUTexelCopyTextureInfo#origin": |
  Defines the origin of the copy, which is the minimum corner of the texture sub-region to copy to or from. Together with `copySize`, this defines the full copy sub-region. This field defaults to `{}` if not specified.
"GPUTexelCopyTextureInfo#aspect": |
  Defines which aspects of the texture to copy to or from. This field defaults to `all` if not specified.
"GPURenderPassColorAttachment": |
  Represents a color attachment for a render pass in the WebGPU API. This interface defines the properties required to configure how colors are rendered and stored during a rendering operation.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpurenderpasscolorattachment).
"GPURenderPassColorAttachment#view": |
  A GPUTextureView describing the texture subresource that will be output to for this color attachment.
  
  This property is required and must be a valid renderable texture view. The format of the view must be a color renderable format.
"GPURenderPassColorAttachment#depthSlice": |
  Indicates the depth slice index of the GPUTextureView that will be output to for this color attachment when the view's dimension is "3d".
  
  This property is optional and must only be provided if the GPUTextureView's dimension is "3d"
"GPURenderPassColorAttachment#resolveTarget": |
  A GPUTextureView describing the texture subresource that will receive the resolved output for this color attachment if the GPUTextureView is multisampled.
  
  This property is optional and must only be provided if the GPUTextureView's sample count is greater than 1. The resolve target must have a sample count of 1.
"GPURenderPassColorAttachment#clearValue": |
  Indicates the value to clear the GPUTextureView to prior to executing the render pass.
  
  This property is optional and defaults to {r: 0, g: 0, b: 0, a: 0} if not provided. It is ignored if the loadOp is not "clear". The components of clearValue are converted to a texel value of the texture format matching the render attachment.
"GPURenderPassColorAttachment#loadOp": |
  Indicates the load operation to perform on the GPUTextureView prior to executing the render pass.
  
  This property is required and specifies how the contents of the view should be handled before rendering. It can be one of the following values: "clear", "load", or "dont-care".
"GPURenderPassColorAttachment#storeOp": |
  The store operation to perform on the GPUTextureView after executing the render pass.
  
  This property is required and specifies how the contents of the view should be handled after rendering. It can be one of the following values: "store", or "dont-store"
"GPURenderPipeline": |
  A [GPURenderPipeline](https://www.w3.org/TR/webgpu/#gpurenderpipeline) is a type of pipeline that controls the vertex and fragment shader stages. It can be used in both [GPURenderPassEncoder] and [GPURenderBundleEncoder].
  
  This interface extends [GPUObjectBase](https://www.w3.org/TR/webgpu/#gpuobjectbase), [GPUPipelineBase](https://www.w3.org/TR/webgpu/#gpupipelinebase), and implements [AutoCloseable](https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-auto-closeable/) to manage resource lifecycle.
  
  ### Render Pipeline Inputs
  - **Bindings**: According to the given [GPUPipelineLayout].
  - **Vertex and Index Buffers**: Described by [GPUVertexState](https://www.w3.org/TR/webgpu/#dictdef-gpuvertexstate).
  - **Color Attachments**: Described by [GPUColorTargetState](https://www.w3.org/TR/webgpu/#dictdef-gpucolortargetstate).
  - **Depth-Stencil Attachment** (optional): Described by [GPUDepthStencilState](https://www.w3.org/TR/webgpu/#dictdef-gpudepthstencilstate).
"GPUDebugCommandsMixin": |
  The `GPUDebugCommandsMixin` interface provides methods to apply debug labels to groups of commands or insert a single label into the command sequence. This is useful for debugging and profiling purposes, allowing developers to create a hierarchy of labeled commands that can be visualized in browser developer tools.
  
  Debug groups can be nested to create a hierarchy of labeled commands. These groups must be well-balanced, meaning every `pushDebugGroup` call must have a corresponding `popDebugGroup` call. Like [object labels](https://www.w3.org/TR/webgpu/#dom-gpuobjectbase-label), these labels have no required behavior but may be shown in error messages and browser developer tools, and may be passed to native API backends.
  
  This interface assumes the presence of `GPUObjectBase` and `GPUCommandsMixin` members on the same object. It must only be included by interfaces which also include those mixins.
"GPUDebugCommandsMixin#pushDebugGroup(groupLabel)": |
  Pushes a debug group onto the command buffer with the specified label.
  
  @param groupLabel The label for the debug group. This is a string that will be used to identify the group in debugging tools. @throws IllegalArgumentException if `groupLabel` is null or empty.
"GPUDebugCommandsMixin#popDebugGroup()": |
  Pops the topmost debug group from the command buffer.
  
  This method must be called after a corresponding `pushDebugGroup` call to maintain a well-balanced hierarchy of debug groups. @throws IllegalStateException if there is no debug group to pop (i.e., the stack is empty).
"GPUDebugCommandsMixin#insertDebugMarker(markerLabel)": |
  Inserts a debug marker into the command buffer with the specified label.
  
  This method is useful for inserting single labels at specific points in the command sequence, which can be helpful for debugging and profiling. @param markerLabel The label for the debug marker. This is a string that will be used to identify the marker in debugging tools. @throws IllegalArgumentException if `markerLabel` is null or empty.
"GPUAddressMode": |
  The `GPUAddressMode` enum defines how texture coordinates are handled outside the range [0.0, 1.0]. This enumeration is used to specify the addressing mode for sampling textures in WebGPU. For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuaddressmode).
  
  **Possible values:**
  - `ClampToEdge`: Texture coordinates are clamped between 0.0 and 1.0, inclusive.
  - `Repeat`: Texture coordinates wrap to the other side of the texture.
  - `MirrorRepeat`: Texture coordinates wrap to the other side of the texture, but the texture is flipped when the integer part of the coordinate is odd.
"GPUAddressMode#ClampToEdge": |
  Texture coordinates are clamped between 0.0 and 1.0, inclusive. This means that any coordinate outside this range will be snapped to the nearest edge of the texture.
"GPUAddressMode#Repeat": |
  Texture coordinates wrap to the other side of the texture. This means that coordinates outside the range [0.0, 1.0] will be wrapped around to the opposite side of the texture.
"GPUAddressMode#MirrorRepeat": |
  Texture coordinates wrap to the other side of the texture, but the texture is flipped when the integer part of the coordinate is odd. This creates a mirroring effect as the coordinates wrap around.
"GPUBlendFactor": |
  The `GPUBlendFactor` enum defines how either a source or destination blend factor is calculated. This enum is used to specify the blending factors for color components in the rendering pipeline. 
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpublendfactor).
"GPUBlendOperation": |
  The `GPUBlendOperation` enum defines the algorithm used to combine source and destination blend factors in WebGPU. This is crucial for controlling how colors are blended during rendering operations.
  
  For more details, refer to the [WebGPU specification on GPUBlendOperation](https://www.w3.org/TR/webgpu/#enumdef-gpublendoperation).
"GPUBufferBindingType": |
  Represents the type of binding for a buffer in WebGPU. This enum defines the possible types of buffer bindings that can be used when creating bind groups.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpubufferbindingtype).
"GPUBufferMapState": |
  Represents the mapping state of a GPU buffer. This enum is used to indicate whether a buffer is unmapped, pending a map operation, or currently mapped.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpubuffermapstate).
"GPUCompareFunction": |
  The `GPUCompareFunction` enum defines the possible comparison functions used in depth and stencil operations within WebGPU. These functions determine how values are compared during rendering processes, such as depth testing or stencil testing.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpucomparefunction).
"GPUCompareFunction#Never": |
  The `Never` comparison function ensures that no values pass the comparison test. This means that the test will always fail, regardless of the input values.
"GPUCompareFunction#Equal": |
  The `Equal` comparison function allows a provided value to pass the test if it is equal to the sampled value. This can be used in stencil testing to perform exact comparisons.
"GPUCompareFunction#LessEqual": |
  The `LessEqual` comparison function allows a provided value to pass the test if it is less than or equal to the sampled value. This is useful in depth testing for scenarios where equality should also allow the fragment to pass.
"GPUCompareFunction#Greater": |
  The `Greater` comparison function allows a provided value to pass the test if it is greater than the sampled value. This can be used in reverse depth testing scenarios.
"GPUCompareFunction#NotEqual": |
  The `NotEqual` comparison function allows a provided value to pass the test if it is not equal to the sampled value. This is useful in stencil testing for scenarios where inequality should allow the fragment to pass.
"GPUCompareFunction#GreaterEqual": |
  The `GreaterEqual` comparison function allows a provided value to pass the test if it is greater than or equal to the sampled value. This can be used in depth testing for scenarios where equality should also allow the fragment to pass.
"GPUCompareFunction#Always": |
  The `Always` comparison function ensures that all values pass the comparison test. This means that the test will always succeed, regardless of the input values.
"GPUCompilationMessageType": |
  The `GPUCompilationMessageType` enum defines the types of messages that can be generated during the compilation of GPU shaders. These messages provide information, warnings, or errors to help developers diagnose issues with their shader code.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#gpucompilationmessagetype).
"GPUCullMode": |
  Represents the culling mode used in rasterization, specifying which faces of a primitive to discard during rendering.\n\nThis enum corresponds to the `GPUCullMode` defined in the [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpucullmode).\n\nThe possible values are:\n- [None]: No culling is performed.\n- [Front]: Front-facing triangles are culled.\n- [Back]: Back-facing triangles are culled.
"GPUCullMode#None": |
  Specifies that no culling is performed. Both front-facing and back-facing triangles are rendered.\n\n**See also:**\n- [WebGPU specification: `none`](https://www.w3.org/TR/webgpu/#dom-gpucullmode-none)
"GPUCullMode#Front": |
  Specifies that front-facing triangles are culled. Only back-facing triangles are rendered.\n\n**See also:**\n- [WebGPU specification: `front`](https://www.w3.org/TR/webgpu/#dom-gpucullmode-front)
"GPUCullMode#Back": |
  Specifies that back-facing triangles are culled. Only front-facing triangles are rendered.\n\n**See also:**\n- [WebGPU specification: `back`](https://www.w3.org/TR/webgpu/#dom-gpucullmode-back)
"GPUDeviceLostReason": |
  The `GPUDeviceLostReason` enum represents the reasons why a GPU device might be lost. This is crucial for handling errors and managing resources in WebGPU applications.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpudevicelostreason).
"GPUErrorFilter": |
  The `GPUErrorFilter` enum defines the types of errors that should be caught when calling [pushErrorScope]. This enum is used to specify which kinds of GPU errors are to be monitored within a particular scope.
  
  For more details, refer to the [W3C WebGPU specification on GPUErrorFilter](https://www.w3.org/TR/webgpu/#enumdef-gpuerrorfilter).
"GPUErrorFilter#Validation": |
  Indicates that the error scope will catch a `GPUValidationError`. This is useful for catching errors related to validation failures in GPU operations.
  
  For more details, refer to the [W3C WebGPU specification on GPUValidationError](https://www.w3.org/TR/webgpu/#gpuvalidationerror).
"GPUErrorFilter#OutOfMemory": |
  Indicates that the error scope will catch a `GPUOutOfMemoryError`. This is useful for catching errors related to memory allocation failures in GPU operations.
  
  For more details, refer to the [W3C WebGPU specification on GPUOutOfMemoryError](https://www.w3.org/TR/webgpu/#gpuoutofmemoryerror).
"GPUErrorFilter#Internal": |
  Indicates that the error scope will catch a `GPUInternalError`. This is useful for catching internal errors that occur within the GPU implementation.
  
  For more details, refer to the [W3C WebGPU specification on GPUInternalError](https://www.w3.org/TR/webgpu/#gpuinternalerror).
"GPUFeatureName": |
  "The `GPUFeatureName` enum defines a set of feature names that identify specific functionalities available in WebGPU. Each feature name corresponds to an additional usage of WebGPU that would otherwise be invalid if the feature is not supported.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#gpufeaturename)."
"GPUFilterMode": |
  Represents the filtering mode used for sampling textures. This enum defines how texture coordinates map to texel values.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpufiltermode).
"GPUFrontFace": |
  The `GPUFrontFace` enum defines which polygons are considered front-facing by a [GPURenderPipeline](https://www.w3.org/TR/webgpu/#gpurenderpipeline). This is crucial for determining the visibility of polygons during rendering. For more details, refer to the [Polygon Rasterization section](https://www.w3.org/TR/webgpu/#polygon-rasterization) of the WebGPU specification.
  
  **Enum Values:**
  - `CCW`: Counter-clockwise winding order.
  - `CW`: Clockwise winding order.
"GPUFrontFace#CCW": |
  Specifies that polygons with vertices whose framebuffer coordinates are given in counter-clockwise order are considered front-facing. This is useful for determining the visibility of polygons during rendering.
"GPUFrontFace#CW": |
  Specifies that polygons with vertices whose framebuffer coordinates are given in clockwise order are considered front-facing. This is useful for determining the visibility of polygons during rendering.
"GPUIndexFormat": |
  Represents the format of index data used in WebGPU. This enum defines two possible formats for indices: `Uint16` and `Uint32`. These formats specify whether the indices are stored as 16-bit or 32-bit unsigned integers.
  
  For more details, refer to the [WebGPU specification on GPUIndexFormat](https://www.w3.org/TR/webgpu/#enumdef-gpuindexformat).
"GPULoadOp": |
  Represents the operations that can be performed to load values into an attachment during a render pass.
  
  This enum defines two possible operations: `Load` and `Clear`. These operations determine how the initial value for an attachment is handled at the beginning of a render pass. 
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuloadop).
"GPULoadOp#Load": |
  Loads the existing value for this attachment into the render pass.
  
  This operation is used when you want to preserve the current contents of the attachment and use it as the starting point for the render pass. 
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpuloadop-load).
"GPULoadOp#Clear": |
  Loads a clear value for this attachment into the render pass.
  
  This operation is used when you want to start with a cleared (typically zeroed or black) value for the attachment. On some GPU hardware, particularly mobile devices, using `Clear` can be more efficient because it avoids loading data from main memory into tile-local memory. 
  
  **Note:** It is recommended to use `Clear` in cases where the initial value doesn't matter, such as when the render target will be cleared using a skybox.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpuloadop-clear).
"GPUMipmapFilterMode": |
  Represents the filtering mode used for mipmapping in WebGPU. This enum defines two possible values: `Nearest` and `Linear`.
  
  For more details, refer to the [WebGPU specification on GPUMipmapFilterMode](https://www.w3.org/TR/webgpu/#enumdef-gpumipmapfiltermode).
"GPUPowerPreference": |
  Represents the power preference for GPU operations. This enum is used to specify whether the application prefers low power consumption or high performance.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpupowerpreference).
"GPUPrimitiveTopology": |
  The `GPUPrimitiveTopology` enum defines the types of primitives that can be used in draw calls made with a [GPURenderPipeline](https://www.w3.org/TR/webgpu/#gpurenderpipeline). This enumeration specifies how vertices are interpreted to form geometric primitives during rendering. For more details, see the [Rasterization section](https://www.w3.org/TR/webgpu/#rasterization) of the WebGPU specification.
"GPUPrimitiveTopology#PointList": |
  Each vertex defines a point primitive. This is useful for rendering individual points, such as particles or markers.
"GPUPrimitiveTopology#LineList": |
  Each consecutive pair of two vertices defines a line primitive. This is useful for rendering lines, such as wireframes or outlines.
"GPUPrimitiveTopology#LineStrip": |
  Each vertex after the first defines a line primitive between it and the previous vertex. This is useful for rendering connected lines, such as polylines.
"GPUPrimitiveTopology#TriangleList": |
  Each consecutive triplet of three vertices defines a triangle primitive. This is the most common topology for rendering 3D models and scenes.
"GPUPrimitiveTopology#TriangleStrip": |
  Each vertex after the first two defines a triangle primitive between it and the previous two vertices. This is useful for rendering connected triangles, such as in terrain or mesh rendering.
"GPUQueryType": |
  Represents the type of query that can be performed using the WebGPU API. This enum defines two types of queries: occlusion and timestamp.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuquerytype).
"GPUSamplerBindingType": |
  Represents the type of sampler binding used in WebGPU. This enum defines how textures are sampled when bound to a pipeline.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpusamplerbindingtype).
"GPUSamplerBindingType#BindingNotUsed": |
  Indicates that no sampler binding is used. This can be useful for bindings that do not require sampling operations.
"GPUSamplerBindingType#Filtering": |
  Specifies that filtering is applied when sampling textures. This is typically used for mipmapping and anisotropic filtering.
"GPUSamplerBindingType#NonFiltering": |
  Indicates that no filtering is applied when sampling textures. This can be used for performance-critical applications where filtering is not required.
"GPUSamplerBindingType#Comparison": |
  Specifies that comparison sampling is used. This is typically employed for depth textures and shadow mapping.
"GPUStencilOperation": |
  Represents the operations that can be performed on the stencil buffer during rendering. This enum is used to specify how the stencil values are modified in a [render pass](https://www.w3.org/TR/webgpu/#dom-gpurenderpass).
  
  The `GPUStencilOperation` enum defines several constants, each representing a different operation that can be applied to the stencil buffer. These operations control how the stencil test affects the stencil values during rendering.
  
  **See also:**
  - [WebGPU Specification: GPUStencilOperation](https://www.w3.org/TR/webgpu/#enumdef-gpustenciloperation)
"GPUStencilOperation#Keep": |
  Keeps the current stencil value unchanged. This operation does not modify the stencil buffer.
"GPUStencilOperation#Zero": |
  Sets the stencil value to `0`. This operation replaces the current stencil value with zero.
"GPUStencilOperation#Replace": |
  Sets the stencil value to the reference value specified in the [render state](https://www.w3.org/TR/webgpu/#dom-renderstate-stencilreference-slot). This operation replaces the current stencil value with the reference value.
"GPUStencilOperation#Invert": |
  Bitwise-inverts the current stencil value. This operation flips all the bits of the current stencil value.
"GPUStencilOperation#IncrementClamp": |
  Increments the current stencil value, clamping it to the maximum representable value of the depth-stencil attachment's stencil aspect. This operation increases the stencil value but ensures it does not exceed the maximum value.
"GPUStencilOperation#DecrementClamp": |
  Decrements the current stencil value, clamping it to `0`. This operation decreases the stencil value but ensures it does not go below zero.
"GPUStencilOperation#IncrementWrap": |
  Increments the current stencil value, wrapping it to zero if it exceeds the maximum representable value of the depth-stencil attachment's stencil aspect. This operation increases the stencil value and wraps around to zero if necessary.
"GPUStencilOperation#DecrementWrap": |
  Decrements the current stencil value, wrapping it to the maximum representable value of the depth-stencil attachment's stencil aspect if it goes below `0`. This operation decreases the stencil value and wraps around to the maximum value if necessary.
"GPUStorageTextureAccess": |
  Represents the access mode for a storage texture binding, indicating whether the texture can be read from, written to, or both. This enum is used to specify the intended usage of a texture in a GPU pipeline.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpustoragetextureaccess).
"GPUStorageTextureAccess#BindingNotUsed": |
  Indicates that the binding is not used. This value can be used when a texture binding is intentionally left unused in a pipeline.
"GPUStorageTextureAccess#WriteOnly": |
  Specifies that the texture can only be written to. This mode is useful for scenarios where the texture is used as an output target, such as render targets or storage textures.
"GPUStorageTextureAccess#ReadOnly": |
  Specifies that the texture can only be read from. This mode is suitable for textures that are used as input sources, such as samplers or storage textures that are read by shaders.
"GPUStorageTextureAccess#ReadWrite": |
  Specifies that the texture can be both read from and written to. This mode is used for textures that need to be updated and read within the same pipeline stage.
"GPUStoreOp": |
  The `GPUStoreOp` enum defines operations that specify how to handle the resulting value of a render pass for an attachment. This is used in conjunction with [GPUTextureView] and [GPURenderPassDescriptor] to control whether the rendered output should be stored or discarded.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpustoreop).
"GPUTextureAspect": |
  Represents the different aspects of a texture that can be accessed. This enum is used to specify which parts of a texture format are accessible when creating a [GPUTextureView](https://www.w3.org/TR/webgpu/#dom-gputextureview).
  
  Each value in this enum corresponds to a set of aspects, defining what parts of the texture data can be accessed. This is crucial for operations that need to read from or write to specific components of a texture.
  
  **See also:**
  - [GPUTextureView](https://www.w3.org/TR/webgpu/#dom-gputextureview)
"GPUTextureDimension": |
  Represents the dimensionality of a texture in WebGPU. This enum defines three possible dimensions for textures: one-dimensional, two-dimensional, and three-dimensional.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gputexturedimension).
"GPUTextureDimension#OneD": |
  Specifies a texture that has one dimension, width. "OneD" textures cannot have mipmaps, be multisampled, use compressed or depth/stencil formats, or be used as a render target.
"GPUTextureDimension#TwoD": |
  Specifies a texture that has a width and height, and may have layers.
"GPUTextureDimension#ThreeD": |
  Specifies a texture that has a width, height, and depth. "ThreeD" textures cannot be multisampled, and their format must support 3D textures (all [plain color formats](https://www.w3.org/TR/webgpu/#plain-color-formats) and some [packed/compressed formats](https://www.w3.org/TR/webgpu/#packed-formats)).
"GPUTextureFormat": |
  The `GPUTextureFormat` enum defines various texture formats that can be used with the WebGPU API. Each format specifies how pixel data is stored and interpreted, including details such as color channels, bit depth, and compression methods.
  
  For more information, refer to the [WebGPU specification on GPUTextureFormat](https://www.w3.org/TR/webgpu/#enumdef-gputextureformat).
"GPUTextureFormat#R8Unorm": |
  Represents an 8-bit unsigned normalized format. Each pixel component is stored as an 8-bit value, where 0 represents the minimum value and 255 represents the maximum value.
"GPUTextureFormat#R8Snorm": |
  Represents an 8-bit signed normalized format. Each pixel component is stored as an 8-bit value, where -128 represents the minimum value and 127 represents the maximum value.
"GPUTextureFormat#R8Uint": |
  Represents an 8-bit unsigned integer format. Each pixel component is stored as an 8-bit unsigned integer, ranging from 0 to 255.
"GPUTextureFormat#R8Sint": |
  Represents an 8-bit signed integer format. Each pixel component is stored as an 8-bit signed integer.
"GPUTextureFormat#R16Uint": |
  Represents a 16-bit unsigned integer format. Each pixel component is stored as a 16-bit unsigned integer.
"GPUTextureFormat#R16Sint": |
  Represents a 16-bit signed integer format. Each pixel component is stored as a 16-bit signed integer.
"GPUTextureFormat#R16Float": |
  Represents a 16-bit floating-point format. Each pixel component is stored as a 16-bit floating-point value.
"GPUTextureFormat#RG8Unorm": |
  Represents an 8-bit unsigned normalized format for two channels (red and green). Each channel is stored as an 8-bit value, where 0 represents the minimum value and 255 represents the maximum value.
"GPUTextureFormat#RG8Snorm": |
  Represents an 8-bit signed normalized format for two channels (red and green). Each channel is stored as an 8-bit value, where -128 represents the minimum value and 127 represents the maximum value.
"GPUTextureFormat#RG8Uint": |
  Represents an 8-bit unsigned integer format for two channels (red and green). Each channel is stored as an 8-bit unsigned integer, ranging from 0 to 255.
"GPUTextureFormat#RG8Sint": |
  Represents an 8-bit signed integer format for two channels (red and green). Each channel is stored as an 8-bit signed integer.
"GPUTextureFormat#R32Float": |
  Represents a 32-bit floating-point format. Each pixel component is stored as a 32-bit floating-point value.
"GPUTextureFormat#R32Uint": |
  Represents a 32-bit unsigned integer format. Each pixel component is stored as a 32-bit unsigned integer.
"GPUTextureFormat#R32Sint": |
  Represents a 32-bit signed integer format. Each pixel component is stored as a 32-bit signed integer.
"GPUTextureFormat#RG16Uint": |
  Represents a 16-bit unsigned integer format for two channels (red and green). Each channel is stored as a 16-bit unsigned integer.
"GPUTextureFormat#RG16Sint": |
  Represents a 16-bit signed integer format for two channels (red and green). Each channel is stored as a 16-bit signed integer.
"GPUTextureFormat#RG16Float": |
  Represents a 16-bit floating-point format for two channels (red and green). Each channel is stored as a 16-bit floating-point value.
"GPUTextureFormat#RGBA8Unorm": |
  Represents an 8-bit unsigned normalized format for four channels (red, green, blue, alpha). Each channel is stored as an 8-bit value, where 0 represents the minimum value and 255 represents the maximum value.
"GPUTextureFormat#RGBA8UnormSrgb": |
  Represents an 8-bit unsigned normalized format for four channels (red, green, blue, alpha) in sRGB color space. Each channel is stored as an 8-bit value, where 0 represents the minimum value and 255 represents the maximum value.
"GPUTextureFormat#RGBA8Snorm": |
  Represents an 8-bit signed normalized format for four channels (red, green, blue, alpha). Each channel is stored as an 8-bit value, where -128 represents the minimum value and 127 represents the maximum value.
"GPUTextureFormat#RGBA8Uint": |
  Represents an 8-bit unsigned integer format for four channels (red, green, blue, alpha). Each channel is stored as an 8-bit unsigned integer, ranging from 0 to 255.
"GPUTextureFormat#RGBA8Sint": |
  Represents an 8-bit signed integer format for four channels (red, green, blue, alpha). Each channel is stored as an 8-bit signed integer.
"GPUTextureFormat#BGRA8Unorm": |
  Represents an 8-bit unsigned normalized format for four channels (blue, green, red, alpha). Each channel is stored as an 8-bit value, where 0 represents the minimum value and 255 represents the maximum value.
"GPUTextureFormat#BGRA8UnormSrgb": |
  Represents an 8-bit unsigned normalized format for four channels (blue, green, red, alpha) in sRGB color space. Each channel is stored as an 8-bit value, where 0 represents the minimum value and 255 represents the maximum value.
"GPUTextureFormat#RGB10A2Uint": |
  Represents a packed 32-bit unsigned integer format for four channels (red, green, blue, alpha). The red, green, and blue channels are each 10 bits, and the alpha channel is 2 bits.
"GPUTextureFormat#RGB10A2Unorm": |
  Represents a packed 32-bit unsigned normalized format for four channels (red, green, blue, alpha). The red, green, and blue channels are each 10 bits, and the alpha channel is 2 bits.
"GPUTextureFormat#RG11B10Ufloat": |
  Represents a packed 32-bit unsigned floating-point format for three channels (red, green, blue). The red and green channels are each 11 bits, and the blue channel is 10 bits.
"GPUTextureFormat#RGB9E5Ufloat": |
  Represents a packed 32-bit unsigned floating-point format for three channels (red, green, blue) with a shared exponent. The red, green, and blue channels are each 9 bits, and the shared exponent is 5 bits.
"GPUTextureFormat#RG32Float": |
  Represents a 64-bit floating-point format for two channels (red, green). Each channel is stored as a 32-bit floating-point value.
"GPUTextureFormat#RG32Uint": |
  Represents a 64-bit unsigned integer format for two channels (red, green). Each channel is stored as a 32-bit unsigned integer.
"GPUTextureFormat#RG32Sint": |
  Represents a 64-bit signed integer format for two channels (red, green). Each channel is stored as a 32-bit signed integer.
"GPUTextureFormat#RGBA16Uint": |
  Represents a 64-bit unsigned integer format for four channels (red, green, blue, alpha). Each channel is stored as a 16-bit unsigned integer.
"GPUTextureFormat#RGBA16Sint": |
  Represents a 64-bit signed integer format for four channels (red, green, blue, alpha). Each channel is stored as a 16-bit signed integer.
"GPUTextureFormat#RGBA16Float": |
  Represents a 64-bit floating-point format for four channels (red, green, blue, alpha). Each channel is stored as a 16-bit floating-point value.
"GPUTextureFormat#RGBA32Float": |
  Represents a 128-bit floating-point format for four channels (red, green, blue, alpha). Each channel is stored as a 32-bit floating-point value.
"GPUTextureFormat#RGBA32Uint": |
  Represents a 128-bit unsigned integer format for four channels (red, green, blue, alpha). Each channel is stored as a 32-bit unsigned integer.
"GPUTextureFormat#RGBA32Sint": |
  Represents a 128-bit signed integer format for four channels (red, green, blue, alpha). Each channel is stored as a 32-bit signed integer.
"GPUTextureFormat#Stencil8": |
  Represents an 8-bit stencil format. This format is used for storing stencil values in depth-stencil textures.
"GPUTextureFormat#Depth16Unorm": |
  Represents a 16-bit unsigned normalized depth format. This format is used for storing depth values in depth textures.
"GPUTextureFormat#Depth24Plus": |
  Represents a 24-bit or 32-bit unsigned normalized depth format. This format is used for storing depth values in depth textures.
"GPUTextureFormat#Depth24PlusStencil8": |
  Represents a combined 24-bit or 32-bit unsigned normalized depth and 8-bit stencil format. This format is used for storing both depth and stencil values in depth-stencil textures.
"GPUTextureFormat#Depth32Float": |
  Represents a 32-bit floating-point depth format. This format is used for storing high-precision depth values in depth textures.
"GPUTextureFormat#Depth32FloatStencil8": |
  Represents a combined 32-bit floating-point depth and 8-bit stencil format. This format is used for storing both high-precision depth and stencil values in depth-stencil textures.
"GPUTextureFormat#BC1RGBAUnorm": |
  Represents a BC1 (DXT1) compressed format for RGBA textures with unsigned normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#BC1RGBAUnormSrgb": |
  Represents a BC1 (DXT1) compressed format for RGBA textures with unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.
"GPUTextureFormat#BC2RGBAUnorm": |
  Represents a BC2 (DXT3) compressed format for RGBA textures with unsigned normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#BC2RGBAUnormSrgb": |
  Represents a BC2 (DXT3) compressed format for RGBA textures with unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.
"GPUTextureFormat#BC3RGBAUnorm": |
  Represents a BC3 (DXT5) compressed format for RGBA textures with unsigned normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#BC3RGBAUnormSrgb": |
  Represents a BC3 (DXT5) compressed format for RGBA textures with unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.
"GPUTextureFormat#BC4RUnorm": |
  Represents a BC4 compressed format for R textures with unsigned normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#BC4RSnorm": |
  Represents a BC4 compressed format for R textures with signed normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#BC5RGUnorm": |
  Represents a BC5 compressed format for RG textures with unsigned normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#BC5RGSnorm": |
  Represents a BC5 compressed format for RG textures with signed normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#BC6HRGBUfloat": |
  Represents a BC6H compressed format for RGB textures with unsigned floating-point values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#BC6HRGBFloat": |
  Represents a BC6H compressed format for RGB textures with floating-point values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#BC7RGBAUnorm": |
  Represents a BC7 compressed format for RGBA textures with unsigned normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#BC7RGBAUnormSrgb": |
  Represents a BC7 compressed format for RGBA textures with unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ETC2RGB8Unorm": |
  Represents an ETC2 compressed format for RGB textures with unsigned normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ETC2RGB8UnormSrgb": |
  Represents an ETC2 compressed format for RGB textures with unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ETC2RGB8A1Unorm": |
  Represents an ETC2 compressed format for RGB textures with 1-bit alpha channel and unsigned normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ETC2RGB8A1UnormSrgb": |
  Represents an ETC2 compressed format for RGB textures with 1-bit alpha channel and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ETC2RGBA8Unorm": |
  Represents an ETC2 compressed format for RGBA textures with unsigned normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ETC2RGBA8UnormSrgb": |
  Represents an ETC2 compressed format for RGBA textures with unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.
"GPUTextureFormat#EACR11Unorm": |
  Represents an EAC compressed format for R textures with 11-bit unsigned normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#EACR11Snorm": |
  Represents an EAC compressed format for R textures with 11-bit signed normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#EACRG11Unorm": |
  Represents an EAC compressed format for RG textures with 11-bit unsigned normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#EACRG11Snorm": |
  Represents an EAC compressed format for RG textures with 11-bit signed normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC4x4Unorm": |
  Represents an ASTC compressed format for textures with 4x4 block size and unsigned normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC4x4UnormSrgb": |
  Represents an ASTC compressed format for textures with 4x4 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC5x4Unorm": |
  Represents an ASTC compressed format for textures with 5x4 block size and unsigned normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC5x4UnormSrgb": |
  Represents an ASTC compressed format for textures with 5x4 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC5x5Unorm": |
  Represents an ASTC compressed format for textures with 5x5 block size and unsigned normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC5x5UnormSrgb": |
  Represents an ASTC compressed format for textures with 5x5 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC6x5Unorm": |
  Represents an ASTC compressed format for textures with 6x5 block size and unsigned normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC6x5UnormSrgb": |
  Represents an ASTC compressed format for textures with 6x5 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC6x6Unorm": |
  Represents an ASTC compressed format for textures with 6x6 block size and unsigned normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC6x6UnormSrgb": |
  Represents an ASTC compressed format for textures with 6x6 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC8x5Unorm": |
  Represents an ASTC compressed format for textures with 8x5 block size and unsigned normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC8x5UnormSrgb": |
  Represents an ASTC compressed format for textures with 8x5 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC8x6Unorm": |
  Represents an ASTC compressed format for textures with 8x6 block size and unsigned normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC8x6UnormSrgb": |
  Represents an ASTC compressed format for textures with 8x6 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC8x8Unorm": |
  Represents an ASTC compressed format for textures with 8x8 block size and unsigned normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC8x8UnormSrgb": |
  Represents an ASTC compressed format for textures with 8x8 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC10x5Unorm": |
  Represents an ASTC compressed format for textures with 10x5 block size and unsigned normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC10x5UnormSrgb": |
  Represents an ASTC compressed format for textures with 10x5 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC10x6Unorm": |
  Represents an ASTC compressed format for textures with 10x6 block size and unsigned normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC10x6UnormSrgb": |
  Represents an ASTC compressed format for textures with 10x6 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC10x8Unorm": |
  Represents an ASTC compressed format for textures with 10x8 block size and unsigned normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC10x8UnormSrgb": |
  Represents an ASTC compressed format for textures with 10x8 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC10x10Unorm": |
  Represents an ASTC compressed format for textures with 10x10 block size and unsigned normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC10x10UnormSrgb": |
  Represents an ASTC compressed format for textures with 10x10 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC12x10Unorm": |
  Represents an ASTC compressed format for textures with 12x10 block size and unsigned normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC12x10UnormSrgb": |
  Represents an ASTC compressed format for textures with 12x10 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC12x12Unorm": |
  Represents an ASTC compressed format for textures with 12x12 block size and unsigned normalized values. This format is used for texture compression in WebGPU.
"GPUTextureFormat#ASTC12x12UnormSrgb": |
  Represents an ASTC compressed format for textures with 12x12 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.
"GPUTextureSampleType": |
  Represents the sample type for textures in WebGPU. This enum defines the possible formats that a texture can have, which determines how the texture data is sampled and interpreted.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gputexturesampletype).
"GPUTextureSampleType#BindingNotUsed": |
  Indicates that the binding is not used. This value is typically used when a texture binding is not required for a particular operation.
"GPUTextureSampleType#Float": |
  Specifies that the texture samples are in floating-point format. This is commonly used for high dynamic range (HDR) rendering and other effects that require precise color representation.
"GPUTextureSampleType#UnfilterableFloat": |
  Specifies that the texture samples are in an unfilterable floating-point format. This format is used when the texture data should not be filtered (e.g., for depth textures or other specialized uses).
"GPUTextureSampleType#Depth": |
  Specifies that the texture samples are in depth format. Depth textures are used for depth buffering and shadow mapping, where the depth information is stored in the texture.
"GPUTextureSampleType#Sint": |
  Specifies that the texture samples are in signed integer format. This format is used for textures that store signed integer data, such as normal maps or other specialized textures.
"GPUTextureSampleType#Uint": |
  Specifies that the texture samples are in unsigned integer format. This format is used for textures that store unsigned integer data, such as stencil buffers or other specialized textures.
"GPUTextureViewDimension": |
  Represents the dimensionality of a texture view in WebGPU. This enum defines how a texture is viewed, which affects the corresponding WGSL types and sampling behavior.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gputextureviewdimension).
"GPUVertexFormat": |
  The `GPUVertexFormat` enum defines the possible formats for vertex attributes in WebGPU. Each format specifies the data type, number of components, and byte size of the vertex attribute. This enumeration is crucial for configuring vertex buffers and ensuring compatibility with shader programs.
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexStepMode": |
  The `GPUVertexStepMode` enum defines the step mode that configures how an address for vertex buffer data is computed, based on the current vertex or instance index.
  
  This enumeration is used to specify whether the vertex buffer data should be stepped per vertex or per instance. It is crucial for configuring vertex input in GPU rendering pipelines.
  
  For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexstepmode).
"GPUVertexStepMode#VertexBufferNotUsed": |
  Indicates that the vertex buffer is not used. This mode is typically used when no vertex data needs to be fetched from a buffer.
"GPUVertexStepMode#Vertex": |
  The address is advanced by `arrayStride` for each vertex, and reset between instances.
  
  This mode is used when the vertex data should be stepped per vertex. It is useful in scenarios where each vertex in a mesh has its own set of attributes.
"GPUVertexStepMode#Instance": |
  The address is advanced by `arrayStride` for each instance.
  
  This mode is used when the vertex data should be stepped per instance. It is useful in scenarios where multiple instances of a mesh share the same vertex data but have different transformations or attributes.
"GPUBufferBindingType#BindingNotUsed": |
  Indicates that the buffer binding is not used. This value signifies that no data will be bound to this slot in the bind group.
"GPUBufferBindingType#Uniform": |
  Indicates that the buffer binding is used for uniform data. Uniform buffers are typically used to pass constant data to shaders, such as transformation matrices or global parameters.
"GPUBufferBindingType#Storage": |
  Indicates that the buffer binding is used for storage data. Storage buffers are used to read from and write to in shaders, allowing for more dynamic data manipulation.
"GPUBufferBindingType#ReadOnlyStorage": |
  Indicates that the buffer binding is used for read-only storage data. Read-only storage buffers allow shaders to read from them but not write to them, providing a way to pass large datasets efficiently.
"GPUCompareFunction#Less": |
  The `Less` comparison function allows a provided value to pass the test if it is less than the sampled value. This is commonly used in depth testing to determine if a fragment should be discarded based on its depth.
"GPUBlendFactor#Zero": |
  Specifies a blend factor where all RGBA components are set to (0, 0, 0, 0). This effectively disables the blending for the specified component.
"GPUBlendFactor#One": |
  Specifies a blend factor where all RGBA components are set to (1, 1, 1, 1). This fully enables the blending for the specified component.
"GPUBlendFactor#Src": |
  Specifies a blend factor where the RGBA components are taken from the source color. The values are (R<sub>src</sub>, G<sub>src</sub>, B<sub>src</sub>, A<sub>src</sub>).
"GPUBlendFactor#OneMinusSrc": |
  Specifies a blend factor where the RGBA components are the inverse of the source color. The values are (1 - R<sub>src</sub>, 1 - G<sub>src</sub>, 1 - B<sub>src</sub>, 1 - A<sub>src</sub>).
"GPUBlendFactor#SrcAlpha": |
  Specifies a blend factor where the RGBA components are taken from the source alpha. The values are (A<sub>src</sub>, A<sub>src</sub>, A<sub>src</sub>, A<sub>src</sub>).
"GPUBlendFactor#OneMinusSrcAlpha": |
  Specifies a blend factor where the RGBA components are the inverse of the source alpha. The values are (1 - A<sub>src</sub>, 1 - A<sub>src</sub>, 1 - A<sub>src</sub>, 1 - A<sub>src</sub>).
"GPUBlendFactor#Dst": |
  Specifies a blend factor where the RGBA components are taken from the destination color. The values are (R<sub>dst</sub>, G<sub>dst</sub>, B<sub>dst</sub>, A<sub>dst</sub>).
"GPUBlendFactor#OneMinusDst": |
  Specifies a blend factor where the RGBA components are the inverse of the destination color. The values are (1 - R<sub>dst</sub>, 1 - G<sub>dst</sub>, 1 - B<sub>dst</sub>, 1 - A<sub>dst</sub>).
"GPUBlendFactor#DstAlpha": |
  Specifies a blend factor where the RGBA components are taken from the destination alpha. The values are (A<sub>dst</sub>, A<sub>dst</sub>, A<sub>dst</sub>, A<sub>dst</sub>).
"GPUBlendFactor#OneMinusDstAlpha": |
  Specifies a blend factor where the RGBA components are the inverse of the destination alpha. The values are (1 - A<sub>dst</sub>, 1 - A<sub>dst</sub>, 1 - A<sub>dst</sub>, 1 - A<sub>dst</sub>).
"GPUBlendFactor#SrcAlphaSaturated": |
  Specifies a blend factor where the RGBA components are the minimum of the source alpha and the inverse of the destination alpha. The values are (min(A<sub>src</sub>, 1 - A<sub>dst</sub>), min(A<sub>src</sub>, 1 - A<sub>dst</sub>), min(A<sub>src</sub>, 1 - A<sub>dst</sub>), 1).
"GPUBlendFactor#Constant": |
  Specifies a blend factor where the RGBA components are taken from a constant color. The values are (R<sub>const</sub>, G<sub>const</sub>, B<sub>const</sub>, A<sub>const</sub>).
"GPUBlendFactor#OneMinusConstant": |
  Specifies a blend factor where the RGBA components are the inverse of a constant color. The values are (1 - R<sub>const</sub>, 1 - G<sub>const</sub>, 1 - B<sub>const</sub>, 1 - A<sub>const</sub>).
"GPUBlendFactor#Src1": |
  Specifies a blend factor where the RGBA components are taken from an additional source color (src1). The values are (R<sub>src1</sub>, G<sub>src1</sub>, B<sub>src1</sub>, A<sub>src1</sub>). This feature requires [dual-source blending](https://www.w3.org/TR/webgpu/#dom-gpufeaturename-dual-source-blending).
"GPUBlendFactor#OneMinusSrc1": |
  Specifies a blend factor where the RGBA components are the inverse of an additional source color (src1). The values are (1 - R<sub>src1</sub>, 1 - G<sub>src1</sub>, 1 - B<sub>src1</sub>, 1 - A<sub>src1</sub>). This feature requires [dual-source blending](https://www.w3.org/TR/webgpu/#dom-gpufeaturename-dual-source-blending).
"GPUBlendFactor#Src1Alpha": |
  Specifies a blend factor where the RGBA components are taken from an additional source alpha (src1). The values are (A<sub>src1</sub>, A<sub>src1</sub>, A<sub>src1</sub>, A<sub>src1</sub>). This feature requires [dual-source blending](https://www.w3.org/TR/webgpu/#dom-gpufeaturename-dual-source-blending).
"GPUBlendFactor#OneMinusSrc1Alpha": |
  Specifies a blend factor where the RGBA components are the inverse of an additional source alpha (src1). The values are (1 - A<sub>src1</sub>, 1 - A<sub>src1</sub>, 1 - A<sub>src1</sub>, 1 - A<sub>src1</sub>). This feature requires [dual-source blending](https://www.w3.org/TR/webgpu/#dom-gpufeaturename-dual-source-blending).
"GPUDeviceLostReason#Unknown": |
  Indicates that the reason for the GPU device being lost is unknown. This can occur due to unforeseen errors or issues not covered by other reasons.
"GPUDeviceLostReason#Destroyed": |
  Indicates that the GPU device was explicitly destroyed, typically through a call to `GPUDevice.destroy()`. This is a normal operation and should be handled gracefully.
"GPUDeviceLostReason#InstanceDropped": |
  Indicates that the GPU device was lost because the instance (e.g., the browser tab or worker) was dropped. This can happen if the user navigates away from a page or closes a tab.
"GPUDeviceLostReason#FailedCreation": |
  Indicates that the GPU device failed to be created. This can occur due to hardware limitations, driver issues, or other initialization problems.
"GPUCompilationMessageType#Error": |
  `Error` indicates that a compilation error has occurred. This type of message is used when the shader code contains syntax errors or other issues that prevent successful compilation.
"GPUCompilationMessageType#Warning": |
  `Warning` indicates a warning message. This type of message is used to inform developers about potential issues in the shader code that do not prevent compilation but may affect performance or correctness.
"GPUCompilationMessageType#Info": |
  `Info` indicates an informational message. This type of message provides general information about the compilation process, such as optimization details or other non-critical messages.
"GPUTextureAspect#All": |
  Specifies that all available aspects of the texture format will be accessible. For color formats, this includes the color aspect. For combined depth-stencil formats, both the depth and stencil aspects are accessible. Depth-or-stencil formats with a single aspect will only make that specific aspect accessible.
  
  **Set of aspects:** [color](https://www.w3.org/TR/webgpu/#aspect-color), [depth](https://www.w3.org/TR/webgpu/#aspect-depth), [stencil](https://www.w3.org/TR/webgpu/#aspect-stencil)
"GPUTextureAspect#StencilOnly": |
  Specifies that only the stencil aspect of a depth-or-stencil format will be accessible. This is useful for operations that need to work exclusively with the stencil buffer.
  
  **Set of aspects:** [stencil](https://www.w3.org/TR/webgpu/#aspect-stencil)
"GPUTextureAspect#DepthOnly": |
  Specifies that only the depth aspect of a depth-or-stencil format will be accessible. This is useful for operations that need to work exclusively with the depth buffer.
  
  **Set of aspects:** [depth](https://www.w3.org/TR/webgpu/#aspect-depth)
"GPUBlendOperation#Add": |
  Represents the blend operation that adds the source and destination colors. This operation is useful for combining light sources or adding textures.
"GPUBlendOperation#Subtract": |
  Represents the blend operation that subtracts the destination color from the source color. This operation can be used for creating effects like shadows or decals.
"GPUBlendOperation#ReverseSubtract": |
  Represents the blend operation that subtracts the source color from the destination color. This operation can be used for creating effects like inverse shadows or highlights.
"GPUBlendOperation#Min": |
  Represents the blend operation that takes the minimum value between the source and destination colors component-wise. This operation can be used for creating effects like darkening or masking.
"GPUBlendOperation#Max": |
  Represents the blend operation that takes the maximum value between the source and destination colors component-wise. This operation can be used for creating effects like brightening or highlighting.
"GPUBufferMapState#Unmapped": |
  Indicates that the buffer is not currently mapped for use by `getMappedRange()`. This state means that the buffer data cannot be accessed directly through JavaScript or Kotlin. The buffer must be mapped using the `mapAsync()` method before it can be read or written.
  
  [See the W3C specification for more details](https://www.w3.org/TR/webgpu/#enumdef-gpubuffermapstate).
"GPUBufferMapState#Pending": |
  Indicates that a mapping of the buffer has been requested but is still pending. The mapping process may succeed or fail validation during the `mapAsync()` call. During this state, the buffer data is not yet accessible.
  
  [See the W3C specification for more details](https://www.w3.org/TR/webgpu/#enumdef-gpubuffermapstate).
"GPUBufferMapState#Mapped": |
  Indicates that the buffer is currently mapped and can be accessed using `getMappedRange()`. This state allows direct read or write access to the buffer data through an `ArrayBuffer` view.
  
  [See the W3C specification for more details](https://www.w3.org/TR/webgpu/#enumdef-gpubuffermapstate).
"GPUFeatureName#DepthClipControl": |
  The `DepthClipControl` feature allows the use of depth clip control in WebGPU. This feature enables more precise control over depth clipping, which can be useful for advanced rendering techniques.
  
  [See W3C specification: Depth Clip Control](https://www.w3.org/TR/webgpu/#depth-clip-control)
"GPUFeatureName#Depth32FloatStencil8": |
  The `Depth32FloatStencil8` feature indicates support for a depth buffer with 32-bit floating-point precision and an 8-bit stencil buffer. This is useful for high-precision depth testing and stencil operations.
  
  [See W3C specification: Depth32FloatStencil8](https://www.w3.org/TR/webgpu/#depth32float-stencil8)
"GPUFeatureName#TimestampQuery": |
  The `TimestampQuery` feature allows the use of timestamp queries in WebGPU. This can be used to measure the time taken by specific GPU operations, which is useful for performance profiling and optimization.
  
  [See W3C specification: Timestamp Query](https://www.w3.org/TR/webgpu/#timestamp-query)
"GPUFeatureName#TextureCompressionBC": |
  The `TextureCompressionBC` feature indicates support for BC (Block Compression) texture formats. This can significantly reduce the memory footprint of textures, which is beneficial for performance and storage.
  
  [See W3C specification: Texture Compression BC](https://www.w3.org/TR/webgpu/#texture-compression-bc)
"GPUFeatureName#TextureCompressionBCSliced3D": |
  The `TextureCompressionBCSliced3D` feature indicates support for BC texture compression in sliced 3D textures. This is useful for compressing 3D textures, which can improve performance and reduce memory usage.
  
  [See W3C specification: Texture Compression BC Sliced 3D](https://www.w3.org/TR/webgpu/#texture-compression-bc-sliced-3d)
"GPUFeatureName#TextureCompressionETC2": |
  The `TextureCompressionETC2` feature indicates support for ETC2 (Ericsson Texture Compression) texture formats. This can reduce the memory footprint of textures, which is beneficial for performance and storage.
  
  [See W3C specification: Texture Compression ETC2](https://www.w3.org/TR/webgpu/#texture-compression-etc2)
"GPUFeatureName#TextureCompressionASTC": |
  The `TextureCompressionASTC` feature indicates support for ASTC (Adaptive Scalable Texture Compression) texture formats. This can significantly reduce the memory footprint of textures, which is beneficial for performance and storage.
  
  [See W3C specification: Texture Compression ASTC](https://www.w3.org/TR/webgpu/#texture-compression-astc)
"GPUFeatureName#TextureCompressionASTCSliced3D": |
  The `TextureCompressionASTCSliced3D` feature indicates support for ASTC texture compression in sliced 3D textures. This is useful for compressing 3D textures, which can improve performance and reduce memory usage.
  
  [See W3C specification: Texture Compression ASTC Sliced 3D](https://www.w3.org/TR/webgpu/#texture-compression-astc-sliced-3d)
"GPUFeatureName#IndirectFirstInstance": |
  The `IndirectFirstInstance` feature allows the use of indirect drawing commands with the first instance parameter. This can be used to draw multiple instances of a mesh with different starting points, which is useful for complex scenes.
  
  [See W3C specification: Indirect First Instance](https://www.w3.org/TR/webgpu/#indirect-first-instance)
"GPUFeatureName#ShaderF16": |
  The `ShaderF16` feature indicates support for 16-bit floating-point precision in shaders. This can reduce the memory footprint of shader data, which is beneficial for performance and storage.
  
  [See W3C specification: Shader F16](https://www.w3.org/TR/webgpu/#shader-f16)
"GPUFeatureName#RG11B10UfloatRenderable": |
  The `RG11B10UfloatRenderable` feature indicates support for rendering to textures with the RG11B10Ufloat format. This is useful for high-dynamic-range (HDR) rendering.
  
  [See W3C specification: RG11B10Ufloat Renderable](https://www.w3.org/TR/webgpu/#rg11b10ufloat-renderable)
"GPUFeatureName#BGRA8UnormStorage": |
  The `BGRA8UnormStorage` feature indicates support for storing textures in the BGRA8Unorm format. This is useful for compatibility with certain graphics APIs and formats.
  
  [See W3C specification: BGRA8Unorm Storage](https://www.w3.org/TR/webgpu/#bgra8unorm-storage)
"GPUFeatureName#Float32Filterable": |
  The `Float32Filterable` feature indicates support for filtering textures with 32-bit floating-point precision. This is useful for high-quality texture sampling in shaders.
  
  [See W3C specification: Float32 Filterable](https://www.w3.org/TR/webgpu/#float32-filterable)
"GPUFeatureName#Float32Blendable": |
  The `Float32Blendable` feature indicates support for blending textures with 32-bit floating-point precision. This is useful for high-quality blending operations in shaders.
  
  [See W3C specification: Float32 Blendable](https://www.w3.org/TR/webgpu/#float32-blendable)
"GPUFeatureName#ClipDistances": |
  The `ClipDistances` feature allows the use of clip distances in WebGPU. This can be used to perform custom clipping operations in shaders, which is useful for advanced rendering techniques.
  
  [See W3C specification: Clip Distances](https://www.w3.org/TR/webgpu/#clip-distances)
"GPUFeatureName#DualSourceBlending": |
  The `DualSourceBlending` feature indicates support for dual-source blending. This allows for more complex blending operations, which can be useful for advanced rendering techniques.
  
  [See W3C specification: Dual Source Blending](https://www.w3.org/TR/webgpu/#dual-source-blending)
"GPUFilterMode#Nearest": |
  Specifies that the nearest texture sample should be returned. This mode is useful for pixelated or blocky textures, as it does not interpolate between texels.
  
  [W3C Specification](https://www.w3.org/TR/webgpu/#enumdef-gpufiltermode-nearest)
"GPUFilterMode#Linear": |
  Specifies that a linear interpolation should be performed between the nearest texture samples. This mode is useful for smooth textures, as it interpolates between texels.
  
  [W3C Specification](https://www.w3.org/TR/webgpu/#enumdef-gpufiltermode-linear)
"GPUIndexFormat#Uint16": |
  Represents the `uint16` index format. This enum value specifies that indices in an index buffer are stored as 16-bit unsigned integers.
  
  **See also:**
  - [W3C GPUIndexFormat Specification](https://www.w3.org/TR/webgpu/#enumdef-gpuindexformat)
"GPUIndexFormat#Uint32": |
  Represents the `uint32` index format. This enum value specifies that indices in an index buffer are stored as 32-bit unsigned integers.
  
  **See also:**
  - [W3C GPUIndexFormat Specification](https://www.w3.org/TR/webgpu/#enumdef-gpuindexformat)
"GPUMipmapFilterMode#Nearest": |
  Specifies that the nearest mipmap level should be used for filtering. This mode is faster but can result in more visible artifacts, especially when viewing textures from a distance.
  
  [W3C Specification](https://www.w3.org/TR/webgpu/#enumdef-gpumipmapfiltermode)
"GPUMipmapFilterMode#Linear": |
  Specifies that linear interpolation should be used between the two nearest mipmap levels for filtering. This mode provides smoother visuals but is computationally more expensive than [Nearest].
  
  [W3C Specification](https://www.w3.org/TR/webgpu/#enumdef-gpumipmapfiltermode)
"GPUPowerPreference#LowPower": |
  Represents the `low-power` preference for GPU power management. This value indicates that the application prefers to prioritize power efficiency over performance.
  
  **See also:**
  - [WebGPU Specification: GPUPowerPreference](https://www.w3.org/TR/webgpu/#enumdef-gpupowerpreference)
"GPUPowerPreference#HighPerformance": |
  Represents the `high-performance` preference for GPU power management. This value indicates that the application prefers to prioritize performance over power efficiency.
  
  **See also:**
  - [WebGPU Specification: GPUPowerPreference](https://www.w3.org/TR/webgpu/#enumdef-gpupowerpreference)
"GPUQueryType#Occlusion": |
  Represents the occlusion query type. This enum value is used to perform occlusion queries, which determine whether objects are visible from a particular viewpoint.
  
  **See also:**
  - [W3C WebGPU Specification: GPUQueryType](https://www.w3.org/TR/webgpu/#enumdef-gpuquerytype)
"GPUQueryType#Timestamp": |
  Represents the timestamp query type. This enum value is used to perform timestamp queries, which capture the time at a specific point in the rendering pipeline.
  
  **See also:**
  - [W3C WebGPU Specification: GPUQueryType](https://www.w3.org/TR/webgpu/#enumdef-gpuquerytype)
"GPUStoreOp#Store": |
  Stores the resulting value of the render pass for this attachment. This operation ensures that the final rendered output is retained and can be used in subsequent operations.
  
  [W3C Specification](https://www.w3.org/TR/webgpu/#dom-gpustoreop-store)
"GPUStoreOp#Discard": |
  Discards the resulting value of the render pass for this attachment. This operation does not retain the final rendered output, and implementations are not required to perform a clear at the end of the render pass.
  
  [W3C Specification](https://www.w3.org/TR/webgpu/#dom-gpustoreop-discard)
"GPUTextureViewDimension#OneD": |
  Represents a texture view dimension where the texture is viewed as a 1-dimensional image.
  
  This dimension corresponds to the following WGSL types:
  - `texture_1d`
  - `texture_storage_1d`
  
  [See the official WebGPU specification for more details](https://www.w3.org/TR/webgpu/#enumdef-gputextureviewdimension).
"GPUTextureViewDimension#TwoD": |
  Represents a texture view dimension where the texture is viewed as a single 2-dimensional image.
  
  This dimension corresponds to the following WGSL types:
  - `texture_2d`
  - `texture_storage_2d`
  - `texture_multisampled_2d`
  - `texture_depth_2d`
  - `texture_depth_multisampled_2d`
  
  [See the official WebGPU specification for more details](https://www.w3.org/TR/webgpu/#enumdef-gputextureviewdimension).
"GPUTextureViewDimension#TwoDArray": |
  Represents a texture view dimension where the texture is viewed as an array of 2-dimensional images.
  
  This dimension corresponds to the following WGSL types:
  - `texture_2d_array`
  - `texture_storage_2d_array`
  - `texture_depth_2d_array`
  
  [See the official WebGPU specification for more details](https://www.w3.org/TR/webgpu/#enumdef-gputextureviewdimension).
"GPUTextureViewDimension#Cube": |
  Represents a texture view dimension where the texture is viewed as a cubemap.
  
  The view has 6 array layers, each corresponding to a face of the cube in the order `[+X, -X, +Y, -Y, +Z, -Z]`. Sampling is done seamlessly across the faces of the cubemap.
  
  This dimension corresponds to the following WGSL types:
  - `texture_cube`
  - `texture_depth_cube`
  
  [See the official WebGPU specification for more details](https://www.w3.org/TR/webgpu/#enumdef-gputextureviewdimension).
"GPUTextureViewDimension#CubeArray": |
  Represents a texture view dimension where the texture is viewed as a packed array of `n` cubemaps, each with 6 array layers.
  
  This dimension corresponds to the following WGSL types:
  - `texture_cube_array`
  - `texture_depth_cube_array`
  
  [See the official WebGPU specification for more details](https://www.w3.org/TR/webgpu/#enumdef-gputextureviewdimension).
"GPUTextureViewDimension#ThreeD": |
  Represents a texture view dimension where the texture is viewed as a 3-dimensional image.
  
  This dimension corresponds to the following WGSL types:
  - `texture_3d`
  - `texture_storage_3d`
  
  [See the official WebGPU specification for more details](https://www.w3.org/TR/webgpu/#enumdef-gputextureviewdimension).
"GPUVertexFormat#Uint8": |
  Represents a single unsigned 8-bit integer component. This format is useful for vertex attributes that require compact storage and minimal precision.
  
  **Data Type:** Unsigned int
  **Components:** 1
  **Byte Size:** 1 byte
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Uint8x2": |
  Represents two unsigned 8-bit integer components. This format is useful for vertex attributes that require compact storage and minimal precision, such as texture coordinates.
  
  **Data Type:** Unsigned int
  **Components:** 2
  **Byte Size:** 2 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Uint8x4": |
  Represents four unsigned 8-bit integer components. This format is useful for vertex attributes that require compact storage and minimal precision, such as color values.
  
  **Data Type:** Unsigned int
  **Components:** 4
  **Byte Size:** 4 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Sint8": |
  Represents a single signed 8-bit integer component. This format is useful for vertex attributes that require compact storage and minimal precision.
  
  **Data Type:** Signed int
  **Components:** 1
  **Byte Size:** 1 byte
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Sint8x2": |
  Represents two signed 8-bit integer components. This format is useful for vertex attributes that require compact storage and minimal precision, such as texture coordinates.
  
  **Data Type:** Signed int
  **Components:** 2
  **Byte Size:** 2 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Sint8x4": |
  Represents four signed 8-bit integer components. This format is useful for vertex attributes that require compact storage and minimal precision, such as color values.
  
  **Data Type:** Signed int
  **Components:** 4
  **Byte Size:** 4 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Unorm8": |
  Represents a single unsigned normalized 8-bit integer component. This format is useful for vertex attributes that require compact storage and minimal precision, such as texture coordinates.
  
  **Data Type:** Unsigned normalized
  **Components:** 1
  **Byte Size:** 1 byte
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Unorm8x2": |
  Represents two unsigned normalized 8-bit integer components. This format is useful for vertex attributes that require compact storage and minimal precision, such as texture coordinates.
  
  **Data Type:** Unsigned normalized
  **Components:** 2
  **Byte Size:** 2 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Unorm8x4": |
  Represents four unsigned normalized 8-bit integer components. This format is useful for vertex attributes that require compact storage and minimal precision, such as color values.
  
  **Data Type:** Unsigned normalized
  **Components:** 4
  **Byte Size:** 4 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Snorm8": |
  Represents a single signed normalized 8-bit integer component. This format is useful for vertex attributes that require compact storage and minimal precision, such as texture coordinates.
  
  **Data Type:** Signed normalized
  **Components:** 1
  **Byte Size:** 1 byte
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Snorm8x2": |
  Represents two signed normalized 8-bit integer components. This format is useful for vertex attributes that require compact storage and minimal precision, such as texture coordinates.
  
  **Data Type:** Signed normalized
  **Components:** 2
  **Byte Size:** 2 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Snorm8x4": |
  Represents four signed normalized 8-bit integer components. This format is useful for vertex attributes that require compact storage and minimal precision, such as color values.
  
  **Data Type:** Signed normalized
  **Components:** 4
  **Byte Size:** 4 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Uint16": |
  Represents a single unsigned 16-bit integer component. This format is useful for vertex attributes that require moderate precision and storage.
  
  **Data Type:** Unsigned int
  **Components:** 1
  **Byte Size:** 2 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Uint16x2": |
  Represents two unsigned 16-bit integer components. This format is useful for vertex attributes that require moderate precision and storage, such as texture coordinates.
  
  **Data Type:** Unsigned int
  **Components:** 2
  **Byte Size:** 4 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Uint16x4": |
  Represents four unsigned 16-bit integer components. This format is useful for vertex attributes that require moderate precision and storage, such as color values.
  
  **Data Type:** Unsigned int
  **Components:** 4
  **Byte Size:** 8 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Sint16": |
  Represents a single signed 16-bit integer component. This format is useful for vertex attributes that require moderate precision and storage.
  
  **Data Type:** Signed int
  **Components:** 1
  **Byte Size:** 2 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Sint16x2": |
  Represents two signed 16-bit integer components. This format is useful for vertex attributes that require moderate precision and storage, such as texture coordinates.
  
  **Data Type:** Signed int
  **Components:** 2
  **Byte Size:** 4 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Sint16x4": |
  Represents four signed 16-bit integer components. This format is useful for vertex attributes that require moderate precision and storage, such as color values.
  
  **Data Type:** Signed int
  **Components:** 4
  **Byte Size:** 8 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Unorm16": |
  Represents a single unsigned normalized 16-bit integer component. This format is useful for vertex attributes that require moderate precision and storage, such as texture coordinates.
  
  **Data Type:** Unsigned normalized
  **Components:** 1
  **Byte Size:** 2 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Unorm16x2": |
  Represents two unsigned normalized 16-bit integer components. This format is useful for vertex attributes that require moderate precision and storage, such as texture coordinates.
  
  **Data Type:** Unsigned normalized
  **Components:** 2
  **Byte Size:** 4 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Unorm16x4": |
  Represents four unsigned normalized 16-bit integer components. This format is useful for vertex attributes that require moderate precision and storage, such as color values.
  
  **Data Type:** Unsigned normalized
  **Components:** 4
  **Byte Size:** 8 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Snorm16": |
  Represents a single signed normalized 16-bit integer component. This format is useful for vertex attributes that require moderate precision and storage, such as texture coordinates.
  
  **Data Type:** Signed normalized
  **Components:** 1
  **Byte Size:** 2 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Snorm16x2": |
  Represents two signed normalized 16-bit integer components. This format is useful for vertex attributes that require moderate precision and storage, such as texture coordinates.
  
  **Data Type:** Signed normalized
  **Components:** 2
  **Byte Size:** 4 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Snorm16x4": |
  Represents four signed normalized 16-bit integer components. This format is useful for vertex attributes that require moderate precision and storage, such as color values.
  
  **Data Type:** Signed normalized
  **Components:** 4
  **Byte Size:** 8 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Float16": |
  Represents a single 16-bit floating-point component. This format is useful for vertex attributes that require moderate precision and storage, such as texture coordinates.
  
  **Data Type:** Float
  **Components:** 1
  **Byte Size:** 2 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Float16x2": |
  Represents two 16-bit floating-point components. This format is useful for vertex attributes that require moderate precision and storage, such as texture coordinates.
  
  **Data Type:** Float
  **Components:** 2
  **Byte Size:** 4 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Float16x4": |
  Represents four 16-bit floating-point components. This format is useful for vertex attributes that require moderate precision and storage, such as color values.
  
  **Data Type:** Float
  **Components:** 4
  **Byte Size:** 8 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Float32": |
  Represents a single 32-bit floating-point component. This format is useful for vertex attributes that require high precision and storage, such as texture coordinates.
  
  **Data Type:** Float
  **Components:** 1
  **Byte Size:** 4 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Float32x2": |
  Represents two 32-bit floating-point components. This format is useful for vertex attributes that require high precision and storage, such as texture coordinates.
  
  **Data Type:** Float
  **Components:** 2
  **Byte Size:** 8 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Float32x3": |
  Represents three 32-bit floating-point components. This format is useful for vertex attributes that require high precision and storage, such as texture coordinates.
  
  **Data Type:** Float
  **Components:** 3
  **Byte Size:** 12 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Float32x4": |
  Represents four 32-bit floating-point components. This format is useful for vertex attributes that require high precision and storage, such as color values.
  
  **Data Type:** Float
  **Components:** 4
  **Byte Size:** 16 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Uint32": |
  Represents a single 32-bit unsigned integer component. This format is useful for vertex attributes that require high precision and storage, such as indices.
  
  **Data Type:** Unsigned int
  **Components:** 1
  **Byte Size:** 4 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Uint32x2": |
  Represents two 32-bit unsigned integer components. This format is useful for vertex attributes that require high precision and storage, such as texture coordinates.
  
  **Data Type:** Unsigned int
  **Components:** 2
  **Byte Size:** 8 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Uint32x3": |
  Represents three 32-bit unsigned integer components. This format is useful for vertex attributes that require high precision and storage, such as texture coordinates.
  
  **Data Type:** Unsigned int
  **Components:** 3
  **Byte Size:** 12 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Uint32x4": |
  Represents four 32-bit unsigned integer components. This format is useful for vertex attributes that require high precision and storage, such as color values.
  
  **Data Type:** Unsigned int
  **Components:** 4
  **Byte Size:** 16 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Sint32": |
  Represents a single 32-bit signed integer component. This format is useful for vertex attributes that require high precision and storage, such as indices.
  
  **Data Type:** Signed int
  **Components:** 1
  **Byte Size:** 4 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Sint32x2": |
  Represents two 32-bit signed integer components. This format is useful for vertex attributes that require high precision and storage, such as texture coordinates.
  
  **Data Type:** Signed int
  **Components:** 2
  **Byte Size:** 8 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Sint32x3": |
  Represents three 32-bit signed integer components. This format is useful for vertex attributes that require high precision and storage, such as texture coordinates.
  
  **Data Type:** Signed int
  **Components:** 3
  **Byte Size:** 12 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Sint32x4": |
  Represents four 32-bit signed integer components. This format is useful for vertex attributes that require high precision and storage, such as color values.
  
  **Data Type:** Signed int
  **Components:** 4
  **Byte Size:** 16 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Unorm1010102": |
  Represents a 10-10-10-2 unsigned normalized component. This format is useful for vertex attributes that require specific precision and storage, such as color values.
  
  **Data Type:** Unsigned normalized
  **Components:** 4
  **Byte Size:** 4 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUVertexFormat#Unorm8x4BGRA": |
  Represents a 8-bit unsigned normalized component in BGRA order. This format is useful for vertex attributes that require specific precision and storage, such as color values.
  
  **Data Type:** Unsigned normalized
  **Components:** 4
  **Byte Size:** 4 bytes
  
  @see [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).
"GPUUncapturedErrorCallback": |
   A functional interface representing a callback that handles uncaptured GPU errors.
   
   This callback is designed to process errors surfaced from WebGPU operations that are not explicitly handled by user code, such as errors triggered by the `uncapturederror` event.
   
   The purpose of this callback is to enable developers to log, debug, or otherwise respond to errors in a structured manner, improving the development experience and debugging process.
   
   Error details are provided via the [GPUError] parameter, which contains information about the specific error, including a human-readable message.
   
   **Usage Context:**
   - Typically set as part of error handling mechanisms in WebGPU-based applications.
   - Provides an opportunity to capture and respond to errors globally with [GPUDeviceDescriptor], outside of scoped error-handling like `popErrorScope`.
"GPUUncapturedErrorCallback#onUncapturedError(error)": |
   Handles uncaptured GPU errors by providing a callback mechanism to process errors surfaced
   from WebGPU operations that are not explicitly handled in user code.
   
   The callback is triggered for errors such as those raised by the `uncapturederror` event.
   Developers can use this method to log, debug, or respond to errors in a structured way.
   
   @param error The GPU error instance containing details about the encountered error,
                including a human-readable message for debugging and logging purposes.