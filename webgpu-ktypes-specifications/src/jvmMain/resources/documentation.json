{
    "GPUBindingResource": "Represents a binding resource in the WebGPU API. This sealed interface can be one of several types:\n- [GPUSampler]\n- [GPUTextureView]\n- [GPUBufferBinding]\n- [GPUExternalTexture]\n\nThis interface is used to specify the type of resource that can be bound in a bind group. For more details, refer to the\n[WebGPU specification on GPUBindingResource](https://www.w3.org/TR/webgpu/#typedefdef-gpubindingresource).",
    "GPUBufferBinding": "The `GPUBufferBinding` interface describes a buffer and an optional range to bind as a resource. This is used in the context of WebGPU to specify how buffers should be bound for shader access.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpubufferbinding).",
    "GPUBufferBinding#buffer": "The `buffer` property specifies the `GPUBuffer` to bind. This buffer will be exposed to shaders as a resource.\n\n**Type**: [GPUBuffer](https://www.w3.org/TR/webgpu/#gpubuffer)",
    "GPUBufferBinding#offset": "The `offset` property specifies the offset, in bytes, from the beginning of the `buffer` to the start of the range exposed to the shader by the buffer binding. This value defaults to 0 if not specified.\n\n**Type**: [GPUSize64](https://www.w3.org/TR/webgpu/#typedefdef-gpusize64)",
    "GPUBufferBinding#size": "The `size` property specifies the size, in bytes, of the buffer binding. If not provided, it specifies the range starting at `offset` and ending at the end of the `buffer`.\n\n**Type**: [GPUSize64](https://www.w3.org/TR/webgpu/#typedefdef-gpusize64)",
    "GPUColor": "Represents a color in the RGBA format, which can be either a sequence of four `Double` values or a [GPUColorDict]. This interface provides access to the red, green, blue, and alpha channel values.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#gpucolor).",
    "GPUColor#r": "The red channel value of the color. This value is a `Double` representing the intensity of the red component in the RGBA color model.\n\n**Type**: Double",
    "GPUColor#g": "The green channel value of the color. This value is a `Double` representing the intensity of the green component in the RGBA color model.\n\n**Type**: Double",
    "GPUColor#b": "The blue channel value of the color. This value is a `Double` representing the intensity of the blue component in the RGBA color model.\n\n**Type**: Double",
    "GPUColor#a": "The alpha channel value of the color. This value is a `Double` representing the opacity of the color, where 0.0 means fully transparent and 1.0 means fully opaque.\n\n**Type**: Double",
    "GPUOrigin2D": "Represents a 2D origin point in GPU coordinates. This interface can be used to specify the starting point for various GPU operations, such as texture sampling or buffer updates.\n\nThe `GPUOrigin2D` type is defined as either a sequence of two values or a dictionary with `x` and `y` properties. This allows for flexible initialization and usage in different contexts.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#gpuorigin2d).",
    "GPUOrigin2D#x": "The x-coordinate of the origin point. This value is of type `GPUIntegerCoordinate`.\n\n- **Type**: `GPUIntegerCoordinate`\n- **Default Value**: 0\n\nWhen using a sequence to represent `GPUOrigin2D`, this property refers to the first item in the sequence. If the sequence does not contain an item, the default value of 0 is used.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpuorigin2ddict-x).",
    "GPUOrigin2D#y": "The y-coordinate of the origin point. This value is of type `GPUIntegerCoordinate`.\n\n- **Type**: `GPUIntegerCoordinate`\n- **Default Value**: 0\n\nWhen using a sequence to represent `GPUOrigin2D`, this property refers to the second item in the sequence. If the sequence does not contain an item, the default value of 0 is used.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpuorigin2ddict-y).",
    "GPUOrigin3D": "Represents a 3D origin point in GPU coordinates. This interface can be used to specify the starting point for various GPU operations, such as texture sampling or buffer updates.\n\nThe `GPUOrigin3D` type can be either a sequence of three [GPUIntegerCoordinate] values or an instance of [GPUOrigin3DDict]. When accessed, the properties `x`, `y`, and `z` will refer to the corresponding values in the sequence or dictionary.\n\nFor more details, see the [WebGPU specification](https://www.w3.org/TR/webgpu/#gpuorigin3d).",
    "GPUOrigin3D#x": "The x-coordinate of the 3D origin point. This value is either the first item in a sequence of [GPUIntegerCoordinate] values or the `x` property of a [GPUOrigin3DDict].\n\n**Type:** [GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate)\n\n**Default Value:** 0",
    "GPUOrigin3D#y": "The y-coordinate of the 3D origin point. This value is either the second item in a sequence of [GPUIntegerCoordinate] values or the `y` property of a [GPUOrigin3DDict].\n\n**Type:** [GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate)\n\n**Default Value:** 0",
    "GPUOrigin3D#z": "The z-coordinate of the 3D origin point. This value is either the third item in a sequence of [GPUIntegerCoordinate] values or the `z` property of a [GPUOrigin3DDict].\n\n**Type:** [GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate)\n\n**Default Value:** 0",
    "GPUObjectBase": "The `GPUObjectBase` interface is a mixin that provides a common base for all WebGPU objects. It includes properties such as a label, which can be used to identify the object in debugging and error messages.\n\nThis interface is fundamental to the WebGPU API as it ensures that all WebGPU objects share a consistent set of properties and behaviors. The `label` property allows developers to assign meaningful names to their WebGPU objects, making it easier to debug and manage them.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#gpuobjectbase).",
    "GPUObjectBase#label": "A developer-provided label which is used in an implementation-defined way. It can be utilized by the browser, OS, or other tools to help identify the underlying internal object to the developer.\n\nThis property is particularly useful for debugging purposes as it allows developers to assign meaningful names to their WebGPU objects. These labels can then be displayed in error messages, console warnings, and various debugging utilities.\n\n**Type**: `String`\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpuobjectbase-label).",
    "GPUCompilationMessage": "The `GPUCompilationMessage` interface represents an informational, warning, or error message generated by the [GPUShaderModule] compiler. These messages are designed to be human-readable and assist developers in diagnosing issues with their shader code. Each message can correspond to a specific point in the shader code, a substring of the shader code, or may not correspond to any specific point at all.\n\nSee also: [W3C Specification](https://www.w3.org/TR/webgpu/#dom-gpucompilationmessage)",
    "GPUCompilationMessage#message": "A human-readable string that describes the compilation message. This attribute provides detailed information about the issue, warning, or informational note generated during shader compilation.\n\nSee also: [W3C Specification](https://www.w3.org/TR/webgpu/#dom-gpucompilationmessage-message)",
    "GPUCompilationMessage#type": "The type of the compilation message, which can be one of the following values from the `GPUCompilationMessageType` enum: \"error\", \"warning\", or \"info\". This attribute helps in categorizing the severity and nature of the message.\n\nSee also: [W3C Specification](https://www.w3.org/TR/webgpu/#dom-gpucompilationmessage-type)",
    "GPUCompilationMessage#lineNum": "The line number within the shader code where the message originates. This attribute is an `ULong` value representing the zero-based index of the line.\n\nSee also: [W3C Specification](https://www.w3.org/TR/webgpu/#dom-gpucompilationmessage-linenum)",
    "GPUCompilationMessage#linePos": "The position within the line where the message originates. This attribute is an `ULong` value representing the zero-based index of the character position.\n\nSee also: [W3C Specification](https://www.w3.org/TR/webgpu/#dom-gpucompilationmessage-linepos)",
    "GPUCompilationMessage#offset": "The byte offset within the shader code where the message originates. This attribute is an `ULong` value representing the zero-based index of the byte.\n\nSee also: [W3C Specification](https://www.w3.org/TR/webgpu/#dom-gpucompilationmessage-offset)",
    "GPUCompilationMessage#length": "The length in bytes of the substring within the shader code that the message refers to. This attribute is an `ULong` value representing the number of bytes.\n\nSee also: [W3C Specification](https://www.w3.org/TR/webgpu/#dom-gpucompilationmessage-length)",
    "GPUCompilationInfo": "Represents the compilation information for a GPU shader module. This interface provides access to messages generated during the compilation process, which can be useful for debugging and optimization.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/).",
    "GPUCompilationInfo#messages": "A list of [GPUCompilationMessage] objects that contain detailed information about the compilation process. These messages can include warnings and errors that occurred during the compilation of a shader module.\n\n**Type**: `List<[GPUCompilationMessage]>`\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#gpucompilationinfo).",
    "GPUPipelineBase": "The `GPUPipelineBase` interface represents the base class for GPU pipelines in WebGPU. It provides a method to retrieve bind group layouts, which are essential for configuring resources used by shaders.\n\nThis interface is part of the WebGPU API and is designed to be implemented by specific pipeline types such as compute pipelines or render pipelines.",
    "GPUPipelineBase#getBindGroupLayout(index)": "Retrieves a `GPUBindGroupLayout` object at the specified index from the pipeline.\n\n**Parameters:**\n- `index`: A `UInt` representing the index of the bind group layout to retrieve. This value must be within the range of valid indices for the pipeline's bind group layouts.\n\n**Returns:**\n- A `GPUBindGroupLayout` object that describes the bindings for a specific set of resources used by the shader stages in the pipeline.\n\nThis method is crucial for setting up resource bindings that shaders will use during execution. The `GPUBindGroupLayout` objects define how resources are bound to the pipeline, including buffers, textures, and samplers.\n\n**See also:**\n- [WebGPU Specification: GPUPipelineBase](https://www.w3.org/TR/webgpu/#gpupipelinebase)",
    "GPUBindingCommandsMixin": "The `GPUBindingCommandsMixin` interface extends the functionality of GPU command objects by providing methods to set bind groups. This mixin assumes the presence of `GPUObjectBase` and `GPUCommandsMixin` members on the same object.\n\nIt includes device timeline properties for managing bind groups and dynamic offsets, which are essential for configuring the rendering pipeline in WebGPU.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#gpubindingcommandsmixin).",
    "GPUBindingCommandsMixin#setBindGroup(index, bindGroup, dynamicOffsetsData)": "Sets a bind group for a specific index in the rendering pipeline.\n\n@param index The index at which to set the bind group. This must be a valid `GPUIndex32` value.\n@param bindGroup The `GPUBindGroup` to set at the specified index. If `null`, the bind group at the specified index is unset.\n@param dynamicOffsetsData A list of unsigned integers representing dynamic offsets for the bind group. This parameter is optional and defaults to an empty list.\n\nThis method updates the internal state of the command encoder to include the specified bind group and dynamic offsets at the given index. The `bind_group` parameter allows for flexible binding configurations, enabling efficient resource management in the rendering pipeline.\n\nFor more information, see the [WebGPU specification on GPUBindingCommandsMixin](https://www.w3.org/TR/webgpu/#gpubindingcommandsmixin).",
    "GPURenderBundleEncoder": "The `GPURenderBundleEncoder` interface represents an encoder for creating render bundles in WebGPU. A render bundle is a collection of rendering commands that can be executed multiple times with different parameters, improving performance by reducing the overhead of command encoding.\n\nThis interface inherits from several mixins and interfaces:\n- [GPUObjectBase]: Provides basic object properties such as `label`.\n- [GPUCommandsMixin]: Mixin for common GPU commands.\n- [GPUDebugCommandsMixin]: Mixin for debug-related commands.\n- [GPUBindingCommandsMixin]: Mixin for binding-related commands.\n- [GPURenderCommandsMixin]: Mixin for render-related commands.\n- [AutoCloseable]: Ensures that resources are closed properly.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/).",
    "GPURenderBundleEncoder#finish(descriptor)": "Encodes the render commands into a `GPURenderBundle` and finalizes the encoder.\n\n**Parameters:**\n- `descriptor`: An optional `GPURenderBundleDescriptor` that specifies additional parameters for creating the render bundle. If not provided, default values are used.\n\n**Returns:**\n- A `GPURenderBundle` object containing the encoded render commands.\n\n**See also:**\n- [WebGPU Specification: finish](https://www.w3.org/TR/webgpu/#dom-gpurenderbundleencoder-finish)",
    "GPUDeviceLostInfo": "Represents information about why a [GPUDevice](https://www.w3.org/TR/webgpu/#gpudevice) was lost. This interface provides details that can help developers understand the cause of device loss and take appropriate actions.\n\n**See also:**\n- [WebGPU Specification: GPUDeviceLostInfo](https://www.w3.org/TR/webgpu/#gpudevicelostinfo)",
    "GPUDeviceLostInfo#reason": "The reason why the GPU device was lost. This is an instance of [GPUDeviceLostReason](https://www.w3.org/TR/webgpu/#enumdef-gpudevicelostreason), which enumerates possible causes for device loss.\n\n**See also:**\n- [WebGPU Specification: GPUDeviceLostInfo.reason](https://www.w3.org/TR/webgpu/#dom-gpudevicelostinfo-reason)",
    "GPUDeviceLostInfo#message": "A message providing additional information about why the GPU device was lost. This string is implementation-defined and should not be parsed by applications.\n\n**Important:**\nThe message may contain sensitive information and should be handled with care. It is intended for debugging purposes and should not be displayed to end-users without proper sanitization.\n\n**See also:**\n- [WebGPU Specification: GPUDeviceLostInfo.message](https://www.w3.org/TR/webgpu/#dom-gpudevicelostinfo-message)",
    "GPUValidationError": "A subtype of [GPUError] that indicates an operation did not satisfy all validation requirements. Validation errors are always indicative of an application error and are expected to fail the same way across all devices, assuming the same [[features]] and [[limits]] are in use.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#gpuvalidationerror).\n\nIn this example, if an operation on the `GPUDevice` fails due to a validation error, it will be caught by the `catch` block, and the error message will be printed.",
    "GPUOutOfMemoryError": "Represents a subtype of GPUError that indicates an out-of-memory condition. This error occurs when there is insufficient free memory to complete the requested operation.\n\nThe operation may succeed if attempted again with a lower memory requirement (e.g., using smaller texture dimensions), or if memory used by other resources is released first.\n\n**See Also:**\n- [GPUError](https://www.w3.org/TR/webgpu/#gpuerror)",
    "GPUInternalError": "A subtype of GPUError that indicates an operation failed for a system or implementation-specific reason, even when all validation requirements have been satisfied. This error may occur if the operation exceeds the capabilities of the implementation in ways not easily captured by the supported limits.\n\nFor example, the same operation might succeed on other devices or under different circumstances.\n\n**See also:**\n- GPUError\n- [Supported Limits](https://www.w3.org/TR/webgpu/#supported-limits)\n\n**Related Operations:**\n- [Generate an Internal Error](https://www.w3.org/TR/webgpu/#generate-an-internal-error)",
    "GPUObjectDescriptorBase": "Represents the base descriptor for GPU objects. This interface is used to provide a common structure for labeling GPU objects, which can be helpful for debugging and identification purposes.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpuobjectdescriptorbase).",
    "GPUObjectDescriptorBase#label": "A string that labels the GPU object. This label can be used for debugging purposes to identify the object.\n\n**Type**: [String](https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-string/)\n\n**Default Value**: An empty string (`\"\"`)\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpuobjectdescriptorbase-label).",
    "GPUTextureViewDescriptor": "The `GPUTextureViewDescriptor` interface defines a set of properties that describe how to create a view on a texture. This descriptor is used when creating a [GPUTextureView](https://www.w3.org/TR/webgpu/#gputextureview) object, which represents a specific way to access the data in a texture.\n\nA texture view allows for different formats, dimensions, and usages of the underlying texture data. This is particularly useful for scenarios where you need to access the same texture data in multiple ways without duplicating the actual texture data.",
    "GPUTextureViewDescriptor#format": "`format` specifies the format of the texture view. This must be either the `format` of the texture or one of the `viewFormats` specified during its creation.\n\nSee also: [WebGPU Specification - GPUTextureFormat](https://www.w3.org/TR/webgpu/#enumdef-gputextureformat).",
    "GPUTextureViewDescriptor#dimension": "`dimension` specifies the dimension to view the texture as. This property determines how the texture will be interpreted in terms of its dimensionality (e.g., 1D, 2D, or 3D).\n\nSee also: [WebGPU Specification - GPUTextureViewDimension](https://www.w3.org/TR/webgpu/#enumdef-gputextureviewdimension).",
    "GPUTextureViewDescriptor#usage": "`usage` specifies the allowed usages for the texture view. This must be a subset of the `usage` flags of the texture. If set to 0, it defaults to the full set of usage flags of the texture.\n\nSee also: [WebGPU Specification - GPUTextureUsageFlags](https://www.w3.org/TR/webgpu/#typedefdef-gputextureusageflags).",
    "GPUTextureViewDescriptor#aspect": "`aspect` specifies which aspects of the texture are accessible to the texture view. This property determines whether the view can access color, depth, stencil, or all aspects of the texture.\n\nSee also: [WebGPU Specification - GPUTextureAspect](https://www.w3.org/TR/webgpu/#enumdef-gputextureaspect).",
    "GPUTextureViewDescriptor#baseMipLevel": "`baseMipLevel` specifies the first (most detailed) mipmap level accessible to the texture view. This property defines the starting point for mipmap levels that can be accessed by the view.\n\nSee also: [WebGPU Specification - GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate).",
    "GPUTextureViewDescriptor#mipLevelCount": "`mipLevelCount` specifies how many mipmap levels, starting with `baseMipLevel`, are accessible to the texture view. This property defines the range of mipmap levels that can be accessed by the view.\n\nSee also: [WebGPU Specification - GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate).",
    "GPUTextureViewDescriptor#baseArrayLayer": "`baseArrayLayer` specifies the index of the first array layer accessible to the texture view. This property defines the starting point for array layers that can be accessed by the view.\n\nSee also: [WebGPU Specification - GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate).",
    "GPUBindGroupLayoutDescriptor": "Represents a descriptor for creating a GPUBindGroupLayout. This interface extends GPUObjectDescriptorBase and is used to define the layout of bind groups in WebGPU.\n\nA `GPUBindGroupLayoutDescriptor` specifies a list of entries that describe shader resource bindings. Each entry defines how resources are bound to shaders, including buffers, samplers, textures, and external textures.",
    "GPUBindGroupLayoutDescriptor#entries": "A required list of GPUBindGroupLayoutEntry objects that define the shader resource bindings for a bind group.\n\nEach entry in this list describes a single shader resource binding to be included in a `GPUBindGroupLayout`. The entries specify how resources are bound to shaders, including buffers, samplers, textures, and external textures.\n\n**Type**: List<GPUBindGroupLayoutEntry>\n\n**See also**:\n- GPUBindGroupLayoutEntry",
    "GPUBindGroupLayoutEntry": "Represents a binding layout entry for a bind group in WebGPU. This interface defines the structure of individual bindings within a bind group, specifying how resources such as buffers, samplers, and textures are bound to shader stages.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpubindgrouplayoutentry).",
    "GPUBindGroupLayoutEntry#binding": "The binding index within the bind group. This value uniquely identifies the binding within the bind group layout.\n\n**Type:** [GPUIndex32](https://www.w3.org/TR/webgpu/#typedefdef-gpuindex32)",
    "GPUBindGroupLayoutEntry#visibility": "Specifies the shader stages that can access this binding. This is a bitmask of [GPUShaderStageFlags](https://www.w3.org/TR/webgpu/#typedefdef-gpushaderstageflags) indicating the visibility of the binding.\n\n**Type:** [GPUShaderStageFlags](https://www.w3.org/TR/webgpu/#typedefdef-gpushaderstageflags)",
    "GPUBindGroupLayoutEntry#buffer": "Optional layout for a buffer binding. If specified, this defines the properties of the buffer that can be bound to this entry.\n\n**Type:** [GPUBufferBindingLayout](https://www.w3.org/TR/webgpu/#dictdef-gpubufferbindinglayout)? (nullable)",
    "GPUBindGroupLayoutEntry#sampler": "Optional layout for a sampler binding. If specified, this defines the properties of the sampler that can be bound to this entry.\n\n**Type:** [GPUSamplerBindingLayout](https://www.w3.org/TR/webgpu/#dictdef-gpusamplerbindinglayout)? (nullable)",
    "GPUBindGroupLayoutEntry#texture": "Optional layout for a texture binding. If specified, this defines the properties of the texture that can be bound to this entry.\n\n**Type:** [GPUTextureBindingLayout](https://www.w3.org/TR/webgpu/#dictdef-gputexturebindinglayout)? (nullable)",
    "GPUBufferBindingLayout": "Represents a layout for buffer bindings in WebGPU. This interface defines the properties required to specify how buffers should be bound to binding points in shaders.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#gpubufferbindinglayout-dictionary).",
    "GPUBufferBindingLayout#type": "Specifies the type required for buffers bound to this binding point. This property determines how the buffer will be used in the shader.\n\n**Type:** [GPUBufferBindingType](https://www.w3.org/TR/webgpu/#enumdef-gpubufferbindingtype)\n\n**Default Value:** \"uniform\"",
    "GPUBufferBindingLayout#hasDynamicOffset": "Indicates whether this binding requires a dynamic offset. A dynamic offset allows for more flexible buffer binding, enabling the use of different buffer sizes at runtime.\n\n**Type:** Boolean\n\n**Default Value:** false",
    "GPUBufferBindingLayout#minBindingSize": "Specifies the minimum size of a buffer binding used with this bind point. This value is used to validate that buffers bound to this layout meet the required size constraints.\n\n**Type:** GPUSize64\n\n**Default Value:** 0\n\n**Behavior:**\n- If `minBindingSize` is not `0`, pipeline creation validates that this value is greater than or equal to the minimum buffer binding size of the variable.\n- If `minBindingSize` is `0`, it is ignored during pipeline creation, and draw/dispatch commands validate that each binding in the [GPUBindGroup](https://www.w3.org/TR/webgpu/#gpubindgroup) satisfies the minimum buffer binding size of the variable.",
    "GPUTextureBindingLayout": "Represents the layout for a GPU texture binding. This interface defines the required properties for specifying how textures should be bound in a GPU pipeline.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gputexturebindinglayout).",
    "GPUTextureBindingLayout#sampleType": "Specifies the type required for texture views bound to this binding. This property determines how the texture data should be sampled.\n\n**Default Value**: \"float\"\n\n**Possible Values**:\n- `GPUTextureSampleType.FLOAT`\n- `GPUTextureSampleType.UNFILTERABLE_FLOAT`\n- `GPUTextureSampleType.DEPTH`\n- `GPUTextureSampleType.SINT`\n- `GPUTextureSampleType.UINT`\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gputexturesampletype).",
    "GPUTextureBindingLayout#viewDimension": "Specifies the required dimension for texture views bound to this binding. This property defines the dimensionality of the texture view.\n\n**Default Value**: \"2d\"\n\n**Possible Values**:\n- `GPUTextureViewDimension._1D`\n- `GPUTextureViewDimension._2D`\n- `GPUTextureViewDimension._2D_ARRAY`\n- `GPUTextureViewDimension._3D`\n- `GPUTextureViewDimension.CUBE`\n- `GPUTextureViewDimension.CUBE_ARRAY`\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gputextureviewdimension).",
    "GPUTextureBindingLayout#multisampled": "Indicates whether texture views bound to this binding must be multisampled. This property is used to specify if the texture should support multisampling.\n\n**Default Value**: `false`\n\n**Type**: `Boolean`\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gputexturebindinglayout).",
    "GPUStorageTextureBindingLayout": "Represents the layout configuration for a storage texture binding in WebGPU. This interface defines how textures are accessed and used within shaders, specifying the access mode, format, and view dimension.\n\nFor more details, refer to the [WebGPU specification on GPUStorageTextureBindingLayout](https://www.w3.org/TR/webgpu/#dictdef-gpustoragetexturebindinglayout).",
    "GPUStorageTextureBindingLayout#access": "Specifies the access mode for this binding, indicating whether the texture is readable, writable, or both. This property defaults to `GPUStorageTextureAccess.WriteOnly`.\n\n**Type:** [GPUStorageTextureAccess](https://www.w3.org/TR/webgpu/#enumdef-gpustoragetextureaccess)\n\n**Default Value:** `GPUStorageTextureAccess.WriteOnly`",
    "GPUStorageTextureBindingLayout#format": "Specifies the required format of texture views bound to this binding. This property is mandatory and defines how the texture data is interpreted.\n\n**Type:** [GPUTextureFormat](https://www.w3.org/TR/webgpu/#enumdef-gputextureformat)",
    "GPUStorageTextureBindingLayout#viewDimension": "Specifies the required dimension for texture views bound to this binding. This property defaults to `GPUTextureViewDimension.D2`.\n\n**Type:** [GPUTextureViewDimension](https://www.w3.org/TR/webgpu/#enumdef-gputextureviewdimension)\n\n**Default Value:** `GPUTextureViewDimension.D2`",
    "GPUBindGroupDescriptor": "The `GPUBindGroupDescriptor` interface represents a descriptor for creating bind groups in WebGPU. It extends the `GPUObjectDescriptorBase` and is used to specify the layout and entries of a bind group.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpubindgroupdescriptor).",
    "GPUBindGroupDescriptor#layout": "The `layout` property specifies the `GPUBindGroupLayout` that the entries of this bind group will conform to. This layout defines how resources are bound and accessed in shaders.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpubindgroupdescriptor-layout).",
    "GPUBindGroupDescriptor#entries": "The `entries` property is a list of `GPUBindGroupEntry` objects that describe the resources to expose to the shader for each binding described by the `layout`. Each entry specifies how a particular resource should be bound.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpubindgroupdescriptor-entries).",
    "GPUBindGroupEntry": "Represents a single resource to be bound in a [GPUBindGroup]. This interface is used to describe the binding of resources such as samplers, texture views, external textures, or buffer bindings within a bind group.\n\nFor more details, refer to the [WebGPU specification on GPUBindGroupEntry](https://www.w3.org/TR/webgpu/#dictdef-gpubindgroupentry).",
    "GPUBindGroupEntry#binding": "A unique identifier for a resource binding within the [GPUBindGroup]. This identifier corresponds to a `GPUBindGroupLayoutEntry.binding` and a `@binding` attribute in the [GPUShaderModule].\n\n**Type:** [GPUIndex32](TYPE_MAPPING.md)",
    "GPUBindGroupEntry#resource": "The resource to bind, which can be one of the following types:\n- [GPUSampler]\n- [GPUTextureView]\n- [GPUExternalTexture]\n- [GPUBufferBinding]\n\n**Type:** [GPUBindingResource](TYPE_MAPPING.md)",
    "GPUPipelineLayoutDescriptor": "The `GPUPipelineLayoutDescriptor` interface defines all the [GPUBindGroupLayout](https://www.w3.org/TR/webgpu/#dictdef-gpubindgrouplayout)s used by a pipeline. This descriptor is essential for configuring the layout of bind groups in a GPU pipeline, ensuring that shader modules can access resources correctly.\n\n**Inheritance**: This interface inherits from [GPUObjectDescriptorBase](https://www.w3.org/TR/webgpu/#dictdef-gpuobjectdescriptorbase).\n\nIn this example, `bindGroupLayout1` and `bindGroupLayout2` are instances of [GPUBindGroupLayout]. The `bindGroupLayouts` list defines the layout of bind groups that the pipeline will use.",
    "GPUPipelineLayoutDescriptor#bindGroupLayouts": "A list of optional [GPUBindGroupLayout](https://www.w3.org/TR/webgpu/#dictdef-gpubindgrouplayout)s that the pipeline will use. Each element in this list corresponds to a `@group` attribute in the [GPUShaderModule], with the `N`th element corresponding to `@group(N)`.\n\n**Type**: `List<GPUBindGroupLayout?>`\n\n**Details**:\n- This list defines the layout of bind groups that the pipeline will use.\n- Each [GPUBindGroupLayout] in this list must match the corresponding `@group` attribute in the shader module.\n\nIn this example, `bindGroupLayout1` and `bindGroupLayout2` are instances of [GPUBindGroupLayout]. The `bindGroupLayouts` list defines the layout of bind groups that the pipeline will use.",
    "GPUShaderModuleCompilationHint": "Represents a hint for compiling a GPUShaderModule. This interface provides information about the entry point and layout that may be used with the shader module in future pipeline creation calls.\n\nFor more details, refer to the WebGPU specification on Shader Module Compilation Information: https://www.w3.org/TR/webgpu/#shader-module-compilation-information.",
    "GPUShaderModuleCompilationHint#entryPoint": "The entry point of the shader module. This is a required field and must be specified.\n\nType: String (https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-string/).",
    "GPUShaderModuleCompilationHint#layout": "A GPUPipelineLayout that the shader module may be used with in future pipeline creation calls. If set to null, the default pipeline layout for the entry point associated with this hint will be used.\n\nType: GPUPipelineLayout or GPUAutoLayoutMode.",
    "GPUPipelineDescriptorBase": "Represents the base descriptor for a GPU pipeline. This interface extends [GPUObjectDescriptorBase] and is used to define the layout of a GPU pipeline.\n\nThe `layout` property specifies either a [GPUPipelineLayout] or an automatic layout mode (`\"auto\"`). When `\"auto\"` is specified, the pipeline layout is generated automatically.",
    "GPUPipelineDescriptorBase#layout": "Specifies the layout for this pipeline. This can be either a [GPUPipelineLayout] object or the string `\"auto\"` to generate the pipeline layout automatically.\n\n**Type**: [GPUPipelineLayout] or `String`\n\n**Default**: None\n\n**Behavior**:\n- If a [GPUPipelineLayout] is provided, it defines the specific layout for the pipeline.\n- If `\"auto\"` is specified, the pipeline layout is generated automatically. However, this means that the pipeline cannot share [GPUBindGroup]s with any other pipelines.\n\n**See also**: [GPUAutoLayoutMode], [GPUBindGroup]",
    "GPUComputePipelineDescriptor": "Represents a descriptor for creating a compute pipeline in WebGPU. This interface extends [GPUPipelineDescriptorBase] and is used to define the configuration for a compute pipeline, which executes compute shaders.\n\nA compute pipeline is responsible for performing general-purpose computations on the GPU. It does not render graphics but can be used for tasks such as data processing, simulations, and other parallel computations.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpucomputepipelinedescriptor).",
    "GPUComputePipelineDescriptor#compute": "Specifies the compute shader stage for the pipeline. This member is required and must be set to a valid [GPUProgrammableStage] object that describes the compute shader entry point.\n\nThe compute shader is responsible for executing the compute operations defined in the shader code. It does not produce visual output but can perform parallel computations on data.\n\n**Type:** [GPUProgrammableStage]",
    "GPURenderPipelineDescriptor": "The `GPURenderPipelineDescriptor` interface extends `GPUPipelineDescriptorBase` and defines the configuration for a render pipeline in WebGPU. It specifies the vertex, primitive, depth-stencil, multisample, and fragment states required to create a render pipeline. For more details, refer to the [W3C specification](https://www.w3.org/TR/webgpu/#dictdef-gpurenderpipelinedescriptor).",
    "GPURenderPipelineDescriptor#vertex": "`vertex` of type `GPUVertexState`. Describes the vertex shader entry point of the pipeline and its input buffer layouts. This is a required field. For more details, refer to the [W3C specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpipelinedescriptor-vertex).",
    "GPURenderPipelineDescriptor#primitive": "`primitive` of type `GPUPrimitiveState`, defaulting to `{}` if not provided. Describes the primitive-related properties of the pipeline, such as topology and strip index format. For more details, refer to the [W3C specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpipelinedescriptor-primitive).",
    "GPURenderPipelineDescriptor#depthStencil": "`depthStencil` of type `GPUDepthStencilState?`. Describes the optional depth-stencil properties, including testing, operations, and bias. This field is nullable. For more details, refer to the [W3C specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpipelinedescriptor-depthstencil).",
    "GPURenderPipelineDescriptor#multisample": "`multisample` of type `GPUMultisampleState`, defaulting to `{}` if not provided. Describes the multi-sampling properties of the pipeline, such as count and mask. For more details, refer to the [W3C specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpipelinedescriptor-multisample).",
    "GPURenderPipelineDescriptor#fragment": "`fragment` of type `GPUFragmentState?`. Describes the fragment shader entry point of the pipeline and its output colors. If not provided, the [no color output mode](https://www.w3.org/TR/webgpu/#no-color-output) is enabled. This field is nullable. For more details, refer to the [W3C specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpipelinedescriptor-fragment).",
    "GPUMultisampleState": "Represents the multisampling state used by a [GPURenderPipeline](https://www.w3.org/TR/webgpu/#gpurenderpipeline) to interact with render pass attachments that support multisampling.\n\nThis interface defines how many samples per pixel are used, which samples are written to, and whether alpha-to-coverage is enabled. The multisample state is crucial for rendering high-quality images by reducing aliasing artifacts.\n\n**See also:**\n- [GPUMultisampleState dictionary in the WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpumultisamplestate)",
    "GPUMultisampleState#count": "Specifies the number of samples per pixel. This value determines the level of multisampling used during rendering.\n\n**Type:** [GPUSize32](https://www.w3.org/TR/webgpu/#typedefdef-gpusize32)\n\n**Default Value:** 1\n\n**Constraints:**\n- Must be either 1 or 4.\n- If `alphaToCoverageEnabled` is `true`, `count` must be greater than 1.\n\n**See also:**\n- [count member in the WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpumultisamplestate-count)",
    "GPUMultisampleState#mask": "Determines which samples are written to during rendering. This mask allows for selective sampling, which can be useful for optimizing performance or achieving specific visual effects.\n\n**Type:** [GPUSampleMask](https://www.w3.org/TR/webgpu/#typedefdef-gpusamplemask)\n\n**Default Value:** 0xFFFFFFFF\n\n**See also:**\n- [mask member in the WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpumultisamplestate-mask)",
    "GPUMultisampleState#alphaToCoverageEnabled": "When set to `true`, enables alpha-to-coverage, which uses the fragment's alpha channel to generate a sample coverage mask. This can improve the quality of antialiased edges.\n\n**Type:** Boolean\n\n**Default Value:** false\n\n**Constraints:**\n- If `alphaToCoverageEnabled` is `true`, `count` must be greater than 1.\n\n**See also:**\n- [alphaToCoverageEnabled member in the WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpumultisamplestate-alphatocoverageenabled)",
    "GPUFragmentState": "Represents a fragment state in WebGPU, which is a type of programmable stage that defines how fragments are processed during rendering. This interface extends [GPUProgrammableStage] and includes specific configurations for color targets.\n\nThe `GPUFragmentState` interface is used to configure the fragment shader stage of a GPU pipeline, specifying how the colors are written to the render target. This is crucial for defining the visual output of a rendering operation.\n\n**See also:**\n- [WebGPU Specification: GPUProgrammableStage](https://www.w3.org/TR/webgpu/#gpuprogrammablestage)",
    "GPUFragmentState#targets": "A list of [GPUColorTargetState] objects that define the formats and behaviors of the color targets this pipeline writes to. Each `GPUColorTargetState` in the list specifies how a particular color target should be handled during rendering.\n\n**Type:** List<[GPUColorTargetState]?>\n\n**See also:**\n- [WebGPU Specification: GPUFragmentState](https://www.w3.org/TR/webgpu/#dictdef-gpufragmentstate)",
    "GPUColorTargetState": "Represents the state of a color target in a GPU render pipeline. This interface defines the format, blending behavior, and write mask for a color attachment in a render pass.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpucolortargetstate).",
    "GPUColorTargetState#format": "The format of this color target. The pipeline will only be compatible with render pass encoders which use a texture view of this format in the corresponding color attachment.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpucolortargetstate-format).",
    "GPUColorTargetState#blend": "The blending behavior for this color target. If left undefined, disables blending for this color target.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpucolortargetstate-blend).",
    "GPUColorTargetState#writeMask": "Bitmask controlling which channels are written to when drawing to this color target. Defaults to `0xF` (all channels).\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpucolortargetstate-writemask).",
    "GPUBlendState": "Represents the blend state used in rendering operations, defining how colors and alpha values are blended.\n\nThis interface is part of the WebGPU API and corresponds to the `GPUBlendState` dictionary defined in the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpublendstate).\n\nThe `GPUBlendState` interface includes two properties: `color` and `alpha`, both of type `GPUBlendComponent`. These properties specify the blending behavior for color channels and alpha channels, respectively.",
    "GPUBlendComponent": "Represents a blend component used in blending operations for color or alpha components of a fragment. This interface defines how the source and destination colors are combined during rendering.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpublendcomponent).",
    "GPUBlendComponent#operation": "Defines the [GPUBlendOperation] used to calculate the values written to the target attachment components.\n\nThis property specifies the blending operation to be performed. The default value is `add`.\n\n**Type:** [GPUBlendOperation]\n\n**Default Value:** \"add\"\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpublendcomponent-operation).",
    "GPUBlendComponent#srcFactor": "Defines the [GPUBlendFactor] operation to be performed on values from the fragment shader.\n\nThis property specifies the blending factor for the source color. The default value is `one`.\n\n**Type:** [GPUBlendFactor]\n\n**Default Value:** \"one\"\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpublendcomponent-srcfactor).",
    "GPUBlendComponent#dstFactor": "Defines the [GPUBlendFactor] operation to be performed on values from the target attachment.\n\nThis property specifies the blending factor for the destination color. The default value is `zero`.\n\n**Type:** [GPUBlendFactor]\n\n**Default Value:** \"zero\"\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpublendcomponent-dstfactor).",
    "GPUStencilFaceState": "Represents a set of stencil face state parameters that define how stencil tests and operations are performed. This interface is used to configure the behavior of the stencil buffer for front or back-facing triangles in a render pipeline.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpustencilfacestate).",
    "GPUStencilFaceState#compare": "Specifies the comparison function used for stencil tests. This determines how the current stencil value is compared to the reference value.\n\n**Default Value:** `GPUCompareFunction.Always`\n\n**See Also:**\n- [W3C WebGPU specification: GPUStencilFaceState.compare](https://www.w3.org/TR/webgpu/#dom-gpustencilfacestate-compare)",
    "GPUStencilFaceState#failOp": "Specifies the operation to perform when the stencil test fails. This defines what action to take if the comparison function does not pass.\n\n**Default Value:** `GPUStencilOperation.Keep`\n\n**See Also:**\n- [W3C WebGPU specification: GPUStencilFaceState.failOp](https://www.w3.org/TR/webgpu/#dom-gpustencilfacestate-failop)",
    "GPUStencilFaceState#depthFailOp": "Specifies the operation to perform when the stencil test passes but the depth test fails. This defines what action to take if the comparison function passes but the depth test does not.\n\n**Default Value:** `GPUStencilOperation.Keep`\n\n**See Also:**\n- [W3C WebGPU specification: GPUStencilFaceState.depthFailOp](https://www.w3.org/TR/webgpu/#dom-gpustencilfacestate-depthfailop)",
    "GPUStencilFaceState#passOp": "Specifies the operation to perform when both the stencil test and the depth test pass. This defines what action to take if both tests are successful.\n\n**Default Value:** `GPUStencilOperation.Keep`\n\n**See Also:**\n- [W3C WebGPU specification: GPUStencilFaceState.passOp](https://www.w3.org/TR/webgpu/#dom-gpustencilfacestate-passop)",
    "GPUVertexState": "Represents a vertex state in the WebGPU API, defining how vertex data is laid out and processed. This interface extends [GPUProgrammableStage], allowing it to be used as part of a render pipeline.\n\nA `GPUVertexState` object specifies the layout of vertex attribute data in vertex buffers. Each buffer's layout is defined by a list of `GPUVertexBufferLayout` objects, which describe the structure and stride of the vertex data.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#vertex-state).",
    "GPUVertexState#buffers": "A list of `GPUVertexBufferLayout` objects that define the layout of vertex attribute data in each vertex buffer used by this pipeline.\n\nEach `GPUVertexBufferLayout` specifies how the vertex data is structured, including the stride between elements and the attributes that describe the members of the structure. This allows the GPU to correctly interpret the vertex data during rendering.\n\n**Type**: List<[GPUVertexBufferLayout]>\n\n**Default Value**: An empty list\n\nFor more information, see the [W3C WebGPU specification on GPUVertexBufferLayout](https://www.w3.org/TR/webgpu/#dictdef-gpuvertexbufferlayout).",
    "GPUVertexBufferLayout": "Represents the layout of a vertex buffer in WebGPU. This interface defines how vertices are structured and accessed, including the stride between elements, the step mode (whether data is per-vertex or per-instance), and the attributes that describe the vertex data.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpuvertexbufferlayout).",
    "GPUVertexBufferLayout#arrayStride": "The stride, in bytes, between elements of this array. This value specifies how much memory is allocated for each vertex or instance in the buffer.\n\n**Type:** [GPUSize64](https://www.w3.org/TR/webgpu/#typedefdef-gpusize64)",
    "GPUVertexBufferLayout#stepMode": "Specifies whether each element of this array represents per-vertex data or per-instance data. The default value is `GPUVertexStepMode.VERTEX`.\n\n**Type:** [GPUVertexStepMode](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexstepmode)",
    "GPUVertexBufferLayout#attributes": "An array defining the layout of the vertex attributes within each element. This sequence describes how the vertex data is structured and accessed.\n\n**Type:** List<[GPUVertexAttribute](https://www.w3.org/TR/webgpu/#dictdef-gpuvertexattribute)>",
    "GPUVertexAttribute": "Represents a vertex attribute in the WebGPU API. This interface defines the format, offset, and shader location of a vertex attribute.\n\nA `GPUVertexAttribute` is used to describe how data from a vertex buffer should be interpreted by the GPU. It specifies the format of the data (e.g., float32, uint32), the byte offset within the vertex buffer where the data starts, and the shader location that corresponds to this attribute.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpuvertexattribute).",
    "GPUVertexAttribute#format": "The format of the vertex attribute. This specifies how the data should be interpreted by the GPU.\n\n**Type:** [GPUVertexFormat]\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpuvertexattribute-format).",
    "GPUVertexAttribute#offset": "The offset, in bytes, from the beginning of the vertex buffer element to the data for this attribute.\n\n**Type:** [GPUSize64]\n\nThis value must be a multiple of the minimum of 4 and the byte size of the format specified by `format`. It defines where within the vertex buffer the data for this attribute begins.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpuvertexattribute-offset).",
    "GPUVertexAttribute#shaderLocation": "The numeric location associated with this attribute. This corresponds to a `@location` attribute declared in the vertex module of the shader.\n\n**Type:** [GPUIndex32]\n\nThis value must be less than the maximum number of vertex attributes supported by the device, as specified by `device.limits.maxVertexAttributes`.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpuvertexattribute-shaderlocation).",
    "GPUCommandBufferDescriptor": "The `GPUCommandBufferDescriptor` interface represents a descriptor for creating command buffers in WebGPU. This interface inherits from [GPUObjectDescriptorBase], providing a base set of properties and methods that are common to all GPU object descriptors.\n\nA command buffer is a sequence of commands that can be submitted to the GPU for execution. The `GPUCommandBufferDescriptor` specifies the configuration options for creating these command buffers, such as label and usage flags.\n\nThis interface is used when calling [GPUDevice.createCommandBuffer] to create a new command buffer with the specified configuration.\n\n**See also:**\n- [WebGPU Specification: GPUCommandBufferDescriptor](https://www.w3.org/TR/webgpu/#dictdef-gpucommandbufferdescriptor)",
    "GPUCommandEncoderDescriptor": "The `GPUCommandEncoderDescriptor` interface represents a descriptor used to create a [GPUCommandEncoder](https://www.w3.org/TR/webgpu/#gpucommandencoder) object. This descriptor inherits from the base descriptor interface [GPUObjectDescriptorBase](https://www.w3.org/TR/webgpu/#dictdef-gpuobjectdescriptorbase).\n\nThe `GPUCommandEncoderDescriptor` is used to specify configuration options for the command encoder, such as label and device.\n\n**See Also:**\n- [GPUObjectDescriptorBase](https://www.w3.org/TR/webgpu/#dictdef-gpuobjectdescriptorbase)",
    "GPUComputePassTimestampWrites": "Represents a dictionary that specifies the query set and indices where timestamps will be written during a compute pass. This interface is used to measure the duration of compute passes by recording timestamps at the beginning and end of the pass.\n\nFor more details, refer to the [WebGPU specification on GPUComputePassTimestampWrites](https://www.w3.org/TR/webgpu/#dictdef-gpucomputepasstimestampwrites).",
    "GPUComputePassTimestampWrites#querySet": "The `GPUQuerySet` of type \"timestamp\" that the query results will be written to. This set contains the queries where the timestamps will be recorded.\n\n**Type**: [GPUQuerySet](https://www.w3.org/TR/webgpu/#gpuqueryset)",
    "GPUComputePassTimestampWrites#beginningOfPassWriteIndex": "If defined, indicates the query index in `querySet` into which the timestamp at the beginning of the compute pass will be written. This value is of type [GPUSize32](https://www.w3.org/TR/webgpu/#typedefdef-gpusize32).\n\n**Type**: GPUSize32?",
    "GPUComputePassTimestampWrites#endOfPassWriteIndex": "If defined, indicates the query index in `querySet` into which the timestamp at the end of the compute pass will be written. This value is of type [GPUSize32](https://www.w3.org/TR/webgpu/#typedefdef-gpusize32).\n\n**Type**: GPUSize32?",
    "GPUComputePassDescriptor": "Represents a descriptor for configuring a compute pass in WebGPU. This interface extends [GPUObjectDescriptorBase] and is used to specify the details of a compute pass, including timestamp writes.\n\nFor more information, see the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpucomputepassdescriptor).",
    "GPUComputePassDescriptor#timestampWrites": "Defines which timestamp values will be written for this pass and where to write them.\n\nThis property is of type [GPUComputePassTimestampWrites].\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpucomputepassdescriptor-timestampwrites).",
    "GPURenderPassTimestampWrites": "Represents a dictionary that specifies the query set and indices where timestamps will be written during a render pass. This interface is used to capture timing information at the beginning and end of a render pass.\n\nFor more details, refer to the [WebGPU specification on GPURenderPassTimestampWrites](https://www.w3.org/TR/webgpu/#dom-gpurenderpasstimestampwrites).",
    "GPURenderPassTimestampWrites#querySet": "The GPUQuerySet of type `timestamp` that the query results will be written to.\n\nThis property is required and specifies the query set where the timestamps will be recorded.",
    "GPURenderPassTimestampWrites#beginningOfPassWriteIndex": "An optional index in the [querySet] that indicates where the timestamp at the beginning of the render pass will be written.\n\nIf defined, this property specifies the exact query index within the `querySet` where the start timestamp of the render pass will be recorded.",
    "GPURenderPassTimestampWrites#endOfPassWriteIndex": "An optional index in the [querySet] that indicates where the timestamp at the end of the render pass will be written.\n\nIf defined, this property specifies the exact query index within the `querySet` where the end timestamp of the render pass will be recorded.",
    "GPURenderPassDescriptor": "The `GPURenderPassDescriptor` interface defines the configuration for a render pass in WebGPU. It specifies the color attachments, depth/stencil attachment, occlusion query set, timestamp writes, and maximum draw count for the render pass.\n\nThis descriptor is used to configure the rendering process by specifying how different types of data will be handled during the render pass. The `colorAttachments` property defines which color buffers will receive the output from the render pass. The `depthStencilAttachment` specifies the depth/stencil buffer that will be used for depth testing and stencil operations. The `occlusionQuerySet` allows for occlusion queries to be performed, and the `timestampWrites` can be used to write timestamps during the render pass.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpurenderpassdescriptor).",
    "GPURenderPassDescriptor#colorAttachments": "The `colorAttachments` property is a list of `GPURenderPassColorAttachment` objects that define the color attachments for the render pass. Each attachment specifies how the output from the render pass will be written to a particular color buffer.\n\nDue to usage compatibility, no color attachment may alias another attachment or any resource used inside the render pass.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpassdescriptor-colorattachments).",
    "GPURenderPassDescriptor#depthStencilAttachment": "The `depthStencilAttachment` property specifies a `GPURenderPassDepthStencilAttachment` object that defines the depth/stencil attachment for the render pass. This attachment is used for depth testing and stencil operations during the rendering process.\n\nDue to usage compatibility, no writable depth/stencil attachment may alias another attachment or any resource used inside the render pass.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpassdescriptor-depthstencilattachment).",
    "GPURenderPassDescriptor#occlusionQuerySet": "The `occlusionQuerySet` property specifies a `GPUQuerySet` object that defines where the occlusion query results will be stored for this render pass. Occlusion queries are used to determine whether certain pixels were rendered during the pass.",
    "GPURenderPassDescriptor#timestampWrites": "The `timestampWrites` property allows you to specify a list of `GPUQuerySet` objects that define where timestamp query results will be stored for this render pass. Timestamps are used to measure the time taken by different parts of the rendering process.",
    "GPURenderPassDescriptor#maxDrawCount": "The `maxDrawCount` property specifies the maximum number of draw calls that can be made during the render pass. This is useful for optimizing performance and managing resources efficiently.\n\nSetting an appropriate value for `maxDrawCount` helps in preventing resource exhaustion and ensures smooth rendering.",
    "GPURenderBundleDescriptor": "Represents a descriptor for creating a [GPURenderBundle]. This interface inherits from [GPUObjectDescriptorBase], which provides common properties and methods for GPU objects.\n\nThe `GPURenderBundleDescriptor` is used to specify the configuration options when creating a render bundle. A render bundle encapsulates a sequence of rendering commands that can be executed multiple times with different parameters, improving performance by reducing the overhead of command encoding.",
    "GPURenderBundleEncoderDescriptor": "Represents a descriptor for creating a GPURenderBundleEncoder. This interface extends the GPURenderPassLayout and is used to specify whether the depth or stencil components of a render pass are read-only.\n\n@see [WebGPU Specification - GPURenderBundleEncoderDescriptor](https://www.w3.org/TR/webgpu/#dictdef-gpurenderbundleencoderdescriptor)",
    "GPURenderBundleEncoderDescriptor#depthReadOnly": "Indicates whether the render bundle modifies the depth component of the GPURenderPassDepthStencilAttachment in any render pass it is executed in.\n\nIf set to true, the depth component is read-only. This can be useful for optimizing performance by avoiding unnecessary writes to the depth buffer.\n\n@return A Boolean value indicating whether the depth component is read-only.\n@default false",
    "GPURenderBundleEncoderDescriptor#stencilReadOnly": "Indicates whether the render bundle modifies the stencil component of the GPURenderPassDepthStencilAttachment in any render pass it is executed in.\n\nIf set to true, the stencil component is read-only. This can be useful for optimizing performance by avoiding unnecessary writes to the stencil buffer.\n\n@return A Boolean value indicating whether the stencil component is read-only.\n@default false",
    "GPUQuerySetDescriptor": "Represents a descriptor for creating a [GPUQuerySet](https://www.w3.org/TR/webgpu/#gpuqueryset) object. This interface extends [GPUObjectDescriptorBase], providing the necessary configuration parameters to define the type and count of queries managed by the query set.\n\n**See also:**\n- [WebGPU Specification: GPUQuerySetDescriptor](https://www.w3.org/TR/webgpu/#dictdef-gpuquerysetdescriptor)",
    "GPUQuerySetDescriptor#type": "Specifies the type of queries managed by the [GPUQuerySet]. This property is required and must be set to one of the values defined in the [GPUQueryType](https://www.w3.org/TR/webgpu/#enumdef-gpuquerytype) enum.\n\n**See also:**\n- [WebGPU Specification: type](https://www.w3.org/TR/webgpu/#dom-gpuquerysetdescriptor-type)",
    "GPUQuerySetDescriptor#count": "Specifies the number of queries managed by the [GPUQuerySet]. This property is required and must be set to a valid [GPUSize32](https://www.w3.org/TR/webgpu/#typedefdef-gpusize32) value.\n\n**See also:**\n- [WebGPU Specification: count](https://www.w3.org/TR/webgpu/#dom-gpuquerysetdescriptor-count)",
    "GPUTextureViewDescriptor#arrayLayerCount": "`arrayLayerCount` specifies how many array layers, starting with `baseArrayLayer`, are accessible to the texture view. This property defines the range of array layers that can be accessed by the view.\n\nSee also: [WebGPU Specification - GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate).",
    "GPUSamplerBindingLayout": "Represents a binding layout for samplers in WebGPU. This interface defines the type of sampler that can be bound to a specific binding.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpusamplerbindinglayout).",
    "GPUSamplerBindingLayout#type": "Specifies the type of sampler that can be bound to this binding layout. This is an enumeration value that indicates whether the sampler is used for filtering, non-filtering, or comparison operations.\n\n**Type**: [GPUSamplerBindingType]\n\n**Default Value**: \"filtering\"\n\nThis property determines how the sampler will be utilized in the shader. For example, a filtering sampler might be used for texture sampling with mipmapping, while a non-filtering sampler might be used for shadow mapping.",
    "GPUBlendState#color": "Defines the blending behavior of the corresponding render target for color channels.\n\nThis property is of type `GPUBlendComponent` and specifies how the color channels are blended during rendering. For more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpublendstate-color).",
    "GPUBlendState#alpha": "Defines the blending behavior of the corresponding render target for the alpha channel.\n\nThis property is of type `GPUBlendComponent` and specifies how the alpha channel is blended during rendering. For more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpublendstate-alpha).",
    "GPURenderPassLayout": "Represents the layout of a render pass, specifying the formats and sample counts for color and depth/stencil attachments.\n\nThis interface is used to define the configuration of a render pass, which includes the formats of the color attachments and the optional depth/stencil attachment. It also specifies the number of samples per pixel in the attachments.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#gpurenderpasslayout).",
    "GPURenderPassLayout#colorFormats": "A list of the [GPUTextureFormat](https://www.w3.org/TR/webgpu/#enumdef-gputextureformat)s of the color attachments for this pass or bundle.\n\nThis property specifies the formats of the color attachments that will be used in the render pass. Each format corresponds to a texture view that will be rendered to during the pass.",
    "GPURenderPassLayout#depthStencilFormat": "The [GPUTextureFormat](https://www.w3.org/TR/webgpu/#enumdef-gputextureformat) of the depth/stencil attachment for this pass or bundle.\n\nThis property specifies the format of the depth/stencil attachment that will be used in the render pass. It is optional and can be `null` if no depth/stencil attachment is required.",
    "GPURenderPassLayout#sampleCount": "Number of samples per pixel in the attachments for this pass or bundle.\n\nThis property specifies the number of samples per pixel for multisampling. The default value is `1`, which means no multisampling.",
    "GPUExtent3D": "Represents a 3-dimensional extent, which defines the size of a texture or other GPU resources. This interface can be used to specify dimensions in three axes: width, height, and depth or array layers.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#gpuextent3d).\n\n@see [GPUExtent3DDict](https://www.w3.org/TR/webgpu/#dictdef-gpuextent3ddict)",
    "GPUExtent3D#width": "The width of the extent.\n\nThis property corresponds to the `width` field in the [GPUExtent3DDict](https://www.w3.org/TR/webgpu/#dictdef-gpuextent3ddict).\n\n@return The width as a [GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate).",
    "GPUExtent3D#height": "The height of the extent.\n\nThis property corresponds to the `height` field in the [GPUExtent3DDict](https://www.w3.org/TR/webgpu/#dictdef-gpuextent3ddict), which defaults to 1 if not specified.\n\n@return The height as a [GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate).",
    "GPUExtent3D#depthOrArrayLayers": "The depth of the extent or the number of array layers it contains.\n\nThis property corresponds to the `depthOrArrayLayers` field in the [GPUExtent3DDict](https://www.w3.org/TR/webgpu/#dictdef-gpuextent3ddict), which defaults to 1 if not specified. If used with a [GPUTexture](https://www.w3.org/TR/webgpu/#gputexture) with a dimension of `\"3d\"`, it defines the depth of the texture. If used with a `GPUTexture` with a dimension of `\"2d\"`, it defines the number of array layers in the texture.\n\n@return The depth or number of array layers as a [GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate)."
}