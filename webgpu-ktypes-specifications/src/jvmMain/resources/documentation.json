{
    "GPUBindingResource": "Represents a binding resource in the WebGPU API. This sealed interface can be one of several types:\n- [GPUSampler]\n- [GPUTextureView]\n- [GPUBufferBinding]\n- [GPUExternalTexture]\n\nThis interface is used to specify the type of resource that can be bound in a bind group. For more details, refer to the\n[WebGPU specification on GPUBindingResource](https://www.w3.org/TR/webgpu/#typedefdef-gpubindingresource).",
    "GPUBufferBinding": "The `GPUBufferBinding` interface describes a buffer and an optional range to bind as a resource. This is used in the context of WebGPU to specify how buffers should be bound for shader access.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpubufferbinding).",
    "GPUBufferBinding#buffer": "The `buffer` property specifies the `GPUBuffer` to bind. This buffer will be exposed to shaders as a resource.\n\n**Type**: [GPUBuffer](https://www.w3.org/TR/webgpu/#gpubuffer)",
    "GPUBufferBinding#offset": "The `offset` property specifies the offset, in bytes, from the beginning of the `buffer` to the start of the range exposed to the shader by the buffer binding. This value defaults to 0 if not specified.\n\n**Type**: [GPUSize64](https://www.w3.org/TR/webgpu/#typedefdef-gpusize64)",
    "GPUBufferBinding#size": "The `size` property specifies the size, in bytes, of the buffer binding. If not provided, it specifies the range starting at `offset` and ending at the end of the `buffer`.\n\n**Type**: [GPUSize64](https://www.w3.org/TR/webgpu/#typedefdef-gpusize64)",
    "GPUColor": "Represents a color in the RGBA format, which can be either a sequence of four `Double` values or a [GPUColorDict]. This interface provides access to the red, green, blue, and alpha channel values.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#gpucolor).",
    "GPUColor#r": "The red channel value of the color. This value is a `Double` representing the intensity of the red component in the RGBA color model.\n\n**Type**: Double",
    "GPUColor#g": "The green channel value of the color. This value is a `Double` representing the intensity of the green component in the RGBA color model.\n\n**Type**: Double",
    "GPUColor#b": "The blue channel value of the color. This value is a `Double` representing the intensity of the blue component in the RGBA color model.\n\n**Type**: Double",
    "GPUColor#a": "The alpha channel value of the color. This value is a `Double` representing the opacity of the color, where 0.0 means fully transparent and 1.0 means fully opaque.\n\n**Type**: Double",
    "GPUOrigin2D": "Represents a 2D origin point in GPU coordinates. This interface can be used to specify the starting point for various GPU operations, such as texture sampling or buffer updates.\n\nThe `GPUOrigin2D` type is defined as either a sequence of two values or a dictionary with `x` and `y` properties. This allows for flexible initialization and usage in different contexts.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#gpuorigin2d).",
    "GPUOrigin2D#x": "The x-coordinate of the origin point. This value is of type `GPUIntegerCoordinate`.\n\n- **Type**: `GPUIntegerCoordinate`\n- **Default Value**: 0\n\nWhen using a sequence to represent `GPUOrigin2D`, this property refers to the first item in the sequence. If the sequence does not contain an item, the default value of 0 is used.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpuorigin2ddict-x).",
    "GPUOrigin2D#y": "The y-coordinate of the origin point. This value is of type `GPUIntegerCoordinate`.\n\n- **Type**: `GPUIntegerCoordinate`\n- **Default Value**: 0\n\nWhen using a sequence to represent `GPUOrigin2D`, this property refers to the second item in the sequence. If the sequence does not contain an item, the default value of 0 is used.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpuorigin2ddict-y).",
    "GPUOrigin3D": "Represents a 3D origin point in GPU coordinates. This interface can be used to specify the starting point for various GPU operations, such as texture sampling or buffer updates.\n\nThe `GPUOrigin3D` type can be either a sequence of three [GPUIntegerCoordinate] values or an instance of [GPUOrigin3DDict]. When accessed, the properties `x`, `y`, and `z` will refer to the corresponding values in the sequence or dictionary.\n\nFor more details, see the [WebGPU specification](https://www.w3.org/TR/webgpu/#gpuorigin3d).",
    "GPUOrigin3D#x": "The x-coordinate of the 3D origin point. This value is either the first item in a sequence of [GPUIntegerCoordinate] values or the `x` property of a [GPUOrigin3DDict].\n\n**Type:** [GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate)\n\n**Default Value:** 0",
    "GPUOrigin3D#y": "The y-coordinate of the 3D origin point. This value is either the second item in a sequence of [GPUIntegerCoordinate] values or the `y` property of a [GPUOrigin3DDict].\n\n**Type:** [GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate)\n\n**Default Value:** 0",
    "GPUOrigin3D#z": "The z-coordinate of the 3D origin point. This value is either the third item in a sequence of [GPUIntegerCoordinate] values or the `z` property of a [GPUOrigin3DDict].\n\n**Type:** [GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate)\n\n**Default Value:** 0",
    "GPUObjectBase": "The `GPUObjectBase` interface is a mixin that provides a common base for all WebGPU objects. It includes properties such as a label, which can be used to identify the object in debugging and error messages.\n\nThis interface is fundamental to the WebGPU API as it ensures that all WebGPU objects share a consistent set of properties and behaviors. The `label` property allows developers to assign meaningful names to their WebGPU objects, making it easier to debug and manage them.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#gpuobjectbase).",
    "GPUObjectBase#label": "A developer-provided label which is used in an implementation-defined way. It can be utilized by the browser, OS, or other tools to help identify the underlying internal object to the developer.\n\nThis property is particularly useful for debugging purposes as it allows developers to assign meaningful names to their WebGPU objects. These labels can then be displayed in error messages, console warnings, and various debugging utilities.\n\n**Type**: `String`\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpuobjectbase-label).",
    "GPUCompilationMessage": "The `GPUCompilationMessage` interface represents an informational, warning, or error message generated by the [GPUShaderModule] compiler. These messages are designed to be human-readable and assist developers in diagnosing issues with their shader code. Each message can correspond to a specific point in the shader code, a substring of the shader code, or may not correspond to any specific point at all.\n\nSee also: [W3C Specification](https://www.w3.org/TR/webgpu/#dom-gpucompilationmessage)",
    "GPUCompilationMessage#message": "A human-readable string that describes the compilation message. This attribute provides detailed information about the issue, warning, or informational note generated during shader compilation.\n\nSee also: [W3C Specification](https://www.w3.org/TR/webgpu/#dom-gpucompilationmessage-message)",
    "GPUCompilationMessage#type": "The type of the compilation message, which can be one of the following values from the `GPUCompilationMessageType` enum: \"error\", \"warning\", or \"info\". This attribute helps in categorizing the severity and nature of the message.\n\nSee also: [W3C Specification](https://www.w3.org/TR/webgpu/#dom-gpucompilationmessage-type)",
    "GPUCompilationMessage#lineNum": "The line number within the shader code where the message originates. This attribute is an `ULong` value representing the zero-based index of the line.\n\nSee also: [W3C Specification](https://www.w3.org/TR/webgpu/#dom-gpucompilationmessage-linenum)",
    "GPUCompilationMessage#linePos": "The position within the line where the message originates. This attribute is an `ULong` value representing the zero-based index of the character position.\n\nSee also: [W3C Specification](https://www.w3.org/TR/webgpu/#dom-gpucompilationmessage-linepos)",
    "GPUCompilationMessage#offset": "The byte offset within the shader code where the message originates. This attribute is an `ULong` value representing the zero-based index of the byte.\n\nSee also: [W3C Specification](https://www.w3.org/TR/webgpu/#dom-gpucompilationmessage-offset)",
    "GPUCompilationMessage#length": "The length in bytes of the substring within the shader code that the message refers to. This attribute is an `ULong` value representing the number of bytes.\n\nSee also: [W3C Specification](https://www.w3.org/TR/webgpu/#dom-gpucompilationmessage-length)",
    "GPUCompilationInfo": "Represents the compilation information for a GPU shader module. This interface provides access to messages generated during the compilation process, which can be useful for debugging and optimization.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/).",
    "GPUCompilationInfo#messages": "A list of [GPUCompilationMessage] objects that contain detailed information about the compilation process. These messages can include warnings and errors that occurred during the compilation of a shader module.\n\n**Type**: `List<[GPUCompilationMessage]>`\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#gpucompilationinfo).",
    "GPUPipelineBase": "The `GPUPipelineBase` interface represents the base class for GPU pipelines in WebGPU. It provides a method to retrieve bind group layouts, which are essential for configuring resources used by shaders.\n\nThis interface is part of the WebGPU API and is designed to be implemented by specific pipeline types such as compute pipelines or render pipelines.",
    "GPUPipelineBase#getBindGroupLayout(index)": "Retrieves a `GPUBindGroupLayout` object at the specified index from the pipeline.\n\n**Parameters:**\n- `index`: A `UInt` representing the index of the bind group layout to retrieve. This value must be within the range of valid indices for the pipeline's bind group layouts.\n\n**Returns:**\n- A `GPUBindGroupLayout` object that describes the bindings for a specific set of resources used by the shader stages in the pipeline.\n\nThis method is crucial for setting up resource bindings that shaders will use during execution. The `GPUBindGroupLayout` objects define how resources are bound to the pipeline, including buffers, textures, and samplers.\n\n**See also:**\n- [WebGPU Specification: GPUPipelineBase](https://www.w3.org/TR/webgpu/#gpupipelinebase)",
    "GPUBindingCommandsMixin": "The `GPUBindingCommandsMixin` interface extends the functionality of GPU command objects by providing methods to set bind groups. This mixin assumes the presence of `GPUObjectBase` and `GPUCommandsMixin` members on the same object.\n\nIt includes device timeline properties for managing bind groups and dynamic offsets, which are essential for configuring the rendering pipeline in WebGPU.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#gpubindingcommandsmixin).",
    "GPUBindingCommandsMixin#setBindGroup(index, bindGroup, dynamicOffsetsData)": "Sets a bind group for a specific index in the rendering pipeline.\n\n@param index The index at which to set the bind group. This must be a valid `GPUIndex32` value.\n@param bindGroup The `GPUBindGroup` to set at the specified index. If `null`, the bind group at the specified index is unset.\n@param dynamicOffsetsData A list of unsigned integers representing dynamic offsets for the bind group. This parameter is optional and defaults to an empty list.\n\nThis method updates the internal state of the command encoder to include the specified bind group and dynamic offsets at the given index. The `bind_group` parameter allows for flexible binding configurations, enabling efficient resource management in the rendering pipeline.\n\nFor more information, see the [WebGPU specification on GPUBindingCommandsMixin](https://www.w3.org/TR/webgpu/#gpubindingcommandsmixin).",
    "GPURenderBundleEncoder": "The `GPURenderBundleEncoder` interface represents an encoder for creating render bundles in WebGPU. A render bundle is a collection of rendering commands that can be executed multiple times with different parameters, improving performance by reducing the overhead of command encoding.\n\nThis interface inherits from several mixins and interfaces:\n- [GPUObjectBase]: Provides basic object properties such as `label`.\n- [GPUCommandsMixin]: Mixin for common GPU commands.\n- [GPUDebugCommandsMixin]: Mixin for debug-related commands.\n- [GPUBindingCommandsMixin]: Mixin for binding-related commands.\n- [GPURenderCommandsMixin]: Mixin for render-related commands.\n- [AutoCloseable]: Ensures that resources are closed properly.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/).",
    "GPURenderBundleEncoder#finish(descriptor)": "Encodes the render commands into a `GPURenderBundle` and finalizes the encoder.\n\n**Parameters:**\n- `descriptor`: An optional `GPURenderBundleDescriptor` that specifies additional parameters for creating the render bundle. If not provided, default values are used.\n\n**Returns:**\n- A `GPURenderBundle` object containing the encoded render commands.\n\n**See also:**\n- [WebGPU Specification: finish](https://www.w3.org/TR/webgpu/#dom-gpurenderbundleencoder-finish)",
    "GPUDeviceLostInfo": "Represents information about why a [GPUDevice](https://www.w3.org/TR/webgpu/#gpudevice) was lost. This interface provides details that can help developers understand the cause of device loss and take appropriate actions.\n\n**See also:**\n- [WebGPU Specification: GPUDeviceLostInfo](https://www.w3.org/TR/webgpu/#gpudevicelostinfo)",
    "GPUDeviceLostInfo#reason": "The reason why the GPU device was lost. This is an instance of [GPUDeviceLostReason](https://www.w3.org/TR/webgpu/#enumdef-gpudevicelostreason), which enumerates possible causes for device loss.\n\n**See also:**\n- [WebGPU Specification: GPUDeviceLostInfo.reason](https://www.w3.org/TR/webgpu/#dom-gpudevicelostinfo-reason)",
    "GPUDeviceLostInfo#message": "A message providing additional information about why the GPU device was lost. This string is implementation-defined and should not be parsed by applications.\n\n**Important:**\nThe message may contain sensitive information and should be handled with care. It is intended for debugging purposes and should not be displayed to end-users without proper sanitization.\n\n**See also:**\n- [WebGPU Specification: GPUDeviceLostInfo.message](https://www.w3.org/TR/webgpu/#dom-gpudevicelostinfo-message)",
    "GPUValidationError": "A subtype of [GPUError] that indicates an operation did not satisfy all validation requirements. Validation errors are always indicative of an application error and are expected to fail the same way across all devices, assuming the same [[features]] and [[limits]] are in use.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#gpuvalidationerror).\n\nIn this example, if an operation on the `GPUDevice` fails due to a validation error, it will be caught by the `catch` block, and the error message will be printed.",
    "GPUOutOfMemoryError": "Represents a subtype of GPUError that indicates an out-of-memory condition. This error occurs when there is insufficient free memory to complete the requested operation.\n\nThe operation may succeed if attempted again with a lower memory requirement (e.g., using smaller texture dimensions), or if memory used by other resources is released first.\n\n**See Also:**\n- [GPUError](https://www.w3.org/TR/webgpu/#gpuerror)",
    "GPUInternalError": "A subtype of GPUError that indicates an operation failed for a system or implementation-specific reason, even when all validation requirements have been satisfied. This error may occur if the operation exceeds the capabilities of the implementation in ways not easily captured by the supported limits.\n\nFor example, the same operation might succeed on other devices or under different circumstances.\n\n**See also:**\n- GPUError\n- [Supported Limits](https://www.w3.org/TR/webgpu/#supported-limits)\n\n**Related Operations:**\n- [Generate an Internal Error](https://www.w3.org/TR/webgpu/#generate-an-internal-error)",
    "GPUObjectDescriptorBase": "Represents the base descriptor for GPU objects. This interface is used to provide a common structure for labeling GPU objects, which can be helpful for debugging and identification purposes.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpuobjectdescriptorbase).",
    "GPUObjectDescriptorBase#label": "A string that labels the GPU object. This label can be used for debugging purposes to identify the object.\n\n**Type**: [String](https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-string/)\n\n**Default Value**: An empty string (`\"\"`)\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpuobjectdescriptorbase-label).",
    "GPUTextureViewDescriptor": "The `GPUTextureViewDescriptor` interface defines a set of properties that describe how to create a view on a texture. This descriptor is used when creating a [GPUTextureView](https://www.w3.org/TR/webgpu/#gputextureview) object, which represents a specific way to access the data in a texture.\n\nA texture view allows for different formats, dimensions, and usages of the underlying texture data. This is particularly useful for scenarios where you need to access the same texture data in multiple ways without duplicating the actual texture data.",
    "GPUTextureViewDescriptor#format": "`format` specifies the format of the texture view. This must be either the `format` of the texture or one of the `viewFormats` specified during its creation.\n\nSee also: [WebGPU Specification - GPUTextureFormat](https://www.w3.org/TR/webgpu/#enumdef-gputextureformat).",
    "GPUTextureViewDescriptor#dimension": "`dimension` specifies the dimension to view the texture as. This property determines how the texture will be interpreted in terms of its dimensionality (e.g., 1D, 2D, or 3D).\n\nSee also: [WebGPU Specification - GPUTextureViewDimension](https://www.w3.org/TR/webgpu/#enumdef-gputextureviewdimension).",
    "GPUTextureViewDescriptor#usage": "`usage` specifies the allowed usages for the texture view. This must be a subset of the `usage` flags of the texture. If set to 0, it defaults to the full set of usage flags of the texture.\n\nSee also: [WebGPU Specification - GPUTextureUsageFlags](https://www.w3.org/TR/webgpu/#typedefdef-gputextureusageflags).",
    "GPUTextureViewDescriptor#aspect": "`aspect` specifies which aspects of the texture are accessible to the texture view. This property determines whether the view can access color, depth, stencil, or all aspects of the texture.\n\nSee also: [WebGPU Specification - GPUTextureAspect](https://www.w3.org/TR/webgpu/#enumdef-gputextureaspect).",
    "GPUTextureViewDescriptor#baseMipLevel": "`baseMipLevel` specifies the first (most detailed) mipmap level accessible to the texture view. This property defines the starting point for mipmap levels that can be accessed by the view.\n\nSee also: [WebGPU Specification - GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate).",
    "GPUTextureViewDescriptor#mipLevelCount": "`mipLevelCount` specifies how many mipmap levels, starting with `baseMipLevel`, are accessible to the texture view. This property defines the range of mipmap levels that can be accessed by the view.\n\nSee also: [WebGPU Specification - GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate).",
    "GPUTextureViewDescriptor#baseArrayLayer": "`baseArrayLayer` specifies the index of the first array layer accessible to the texture view. This property defines the starting point for array layers that can be accessed by the view.\n\nSee also: [WebGPU Specification - GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate).",
    "GPUBindGroupLayoutDescriptor": "Represents a descriptor for creating a GPUBindGroupLayout. This interface extends GPUObjectDescriptorBase and is used to define the layout of bind groups in WebGPU.\n\nA `GPUBindGroupLayoutDescriptor` specifies a list of entries that describe shader resource bindings. Each entry defines how resources are bound to shaders, including buffers, samplers, textures, and external textures.",
    "GPUBindGroupLayoutDescriptor#entries": "A required list of GPUBindGroupLayoutEntry objects that define the shader resource bindings for a bind group.\n\nEach entry in this list describes a single shader resource binding to be included in a `GPUBindGroupLayout`. The entries specify how resources are bound to shaders, including buffers, samplers, textures, and external textures.\n\n**Type**: List<GPUBindGroupLayoutEntry>\n\n**See also**:\n- GPUBindGroupLayoutEntry",
    "GPUBindGroupLayoutEntry": "Represents a binding layout entry for a GPU bind group. This interface defines the structure of individual bindings within a [GPUBindGroupLayout](https://www.w3.org/TR/webgpu/#gpubindgrouplayout).\n\nA `GPUBindGroupLayoutEntry` specifies how resources are bound to shader stages, including buffers, samplers, textures, and storage textures. Only one type of binding (buffer, sampler, texture, storageTexture) can be defined for any given entry.\n\n**See also:**\n- [WebGPU Specification: GPUBindGroupLayoutEntry](https://www.w3.org/TR/webgpu/#dictdef-gpubindgrouplayoutentry)",
    "GPUBindGroupLayoutEntry#binding": "A unique identifier for a resource binding within the [GPUBindGroupLayout](https://www.w3.org/TR/webgpu/#gpubindgrouplayout). This ID corresponds to a `GPUBindGroupEntry.binding` and a `@binding` attribute in the [GPUShaderModule](https://www.w3.org/TR/webgpu/#gpushadermodule).\n\n**Type:** [GPUIndex32](https://www.w3.org/TR/webgpu/#typedefdef-gpuindex32)",
    "GPUBindGroupLayoutEntry#visibility": "A bitset of the members of [GPUShaderStage](https://www.w3.org/TR/webgpu/#namespacedef-gpushaderstage). Each set bit indicates that a `GPUBindGroupLayoutEntry`'s resource will be accessible from the associated shader stage.\n\n**Type:** [GPUShaderStageFlags](https://www.w3.org/TR/webgpu/#typedefdef-gpushaderstageflags)",
    "GPUBindGroupLayoutEntry#buffer": "When provided, indicates that the binding resource type for this `GPUBindGroupLayoutEntry` is [GPUBufferBinding](https://www.w3.org/TR/webgpu/#dictdef-gpubufferbinding).\n\n**Type:** [GPUBufferBindingLayout?](https://www.w3.org/TR/webgpu/#dictdef-gpubufferbindinglayout)",
    "GPUBindGroupLayoutEntry#sampler": "When provided, indicates that the binding resource type for this `GPUBindGroupLayoutEntry` is [GPUSampler](https://www.w3.org/TR/webgpu/#gpusampler).\n\n**Type:** [GPUSamplerBindingLayout?](https://www.w3.org/TR/webgpu/#dictdef-gpusamplerbindinglayout)",
    "GPUBindGroupLayoutEntry#texture": "When provided, indicates that the binding resource type for this `GPUBindGroupLayoutEntry` is [GPUTextureView](https://www.w3.org/TR/webgpu/#gputextureview).\n\n**Type:** [GPUTextureBindingLayout?](https://www.w3.org/TR/webgpu/#dictdef-gputexturebindinglayout)",
    "GPUBufferBindingLayout": "Represents a layout for buffer bindings in WebGPU. This interface defines the properties required to specify how buffers should be bound to binding points in shaders.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#gpubufferbindinglayout-dictionary).",
    "GPUBufferBindingLayout#type": "Specifies the type required for buffers bound to this binding point. This property determines how the buffer will be used in the shader.\n\n**Type:** [GPUBufferBindingType](https://www.w3.org/TR/webgpu/#enumdef-gpubufferbindingtype)\n\n**Default Value:** \"uniform\"",
    "GPUBufferBindingLayout#hasDynamicOffset": "Indicates whether this binding requires a dynamic offset. A dynamic offset allows for more flexible buffer binding, enabling the use of different buffer sizes at runtime.\n\n**Type:** Boolean\n\n**Default Value:** false",
    "GPUBufferBindingLayout#minBindingSize": "Specifies the minimum size of a buffer binding used with this bind point. This value is used to validate that buffers bound to this layout meet the required size constraints.\n\n**Type:** GPUSize64\n\n**Default Value:** 0\n\n**Behavior:**\n- If `minBindingSize` is not `0`, pipeline creation validates that this value is greater than or equal to the minimum buffer binding size of the variable.\n- If `minBindingSize` is `0`, it is ignored during pipeline creation, and draw/dispatch commands validate that each binding in the [GPUBindGroup](https://www.w3.org/TR/webgpu/#gpubindgroup) satisfies the minimum buffer binding size of the variable.",
    "GPUTextureBindingLayout": "Represents the layout for a GPU texture binding. This interface defines the required properties for specifying how textures should be bound in a GPU pipeline.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gputexturebindinglayout).",
    "GPUTextureBindingLayout#sampleType": "Specifies the type required for texture views bound to this binding. This property determines how the texture data should be sampled.\n\n**Default Value**: \"float\"\n\n**Possible Values**:\n- `GPUTextureSampleType.FLOAT`\n- `GPUTextureSampleType.UNFILTERABLE_FLOAT`\n- `GPUTextureSampleType.DEPTH`\n- `GPUTextureSampleType.SINT`\n- `GPUTextureSampleType.UINT`\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gputexturesampletype).",
    "GPUTextureBindingLayout#viewDimension": "Specifies the required dimension for texture views bound to this binding. This property defines the dimensionality of the texture view.\n\n**Default Value**: \"2d\"\n\n**Possible Values**:\n- `GPUTextureViewDimension._1D`\n- `GPUTextureViewDimension._2D`\n- `GPUTextureViewDimension._2D_ARRAY`\n- `GPUTextureViewDimension._3D`\n- `GPUTextureViewDimension.CUBE`\n- `GPUTextureViewDimension.CUBE_ARRAY`\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gputextureviewdimension).",
    "GPUTextureBindingLayout#multisampled": "Indicates whether texture views bound to this binding must be multisampled. This property is used to specify if the texture should support multisampling.\n\n**Default Value**: `false`\n\n**Type**: `Boolean`\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gputexturebindinglayout).",
    "GPUStorageTextureBindingLayout": "Represents the layout configuration for a storage texture binding in WebGPU. This interface defines how textures are accessed and used within shaders, specifying the access mode, format, and view dimension.\n\nFor more details, refer to the [WebGPU specification on GPUStorageTextureBindingLayout](https://www.w3.org/TR/webgpu/#dictdef-gpustoragetexturebindinglayout).",
    "GPUStorageTextureBindingLayout#access": "Specifies the access mode for this binding, indicating whether the texture is readable, writable, or both. This property defaults to `GPUStorageTextureAccess.WriteOnly`.\n\n**Type:** [GPUStorageTextureAccess](https://www.w3.org/TR/webgpu/#enumdef-gpustoragetextureaccess)\n\n**Default Value:** `GPUStorageTextureAccess.WriteOnly`",
    "GPUStorageTextureBindingLayout#format": "Specifies the required format of texture views bound to this binding. This property is mandatory and defines how the texture data is interpreted.\n\n**Type:** [GPUTextureFormat](https://www.w3.org/TR/webgpu/#enumdef-gputextureformat)",
    "GPUStorageTextureBindingLayout#viewDimension": "Specifies the required dimension for texture views bound to this binding. This property defaults to `GPUTextureViewDimension.D2`.\n\n**Type:** [GPUTextureViewDimension](https://www.w3.org/TR/webgpu/#enumdef-gputextureviewdimension)\n\n**Default Value:** `GPUTextureViewDimension.D2`",
    "GPUBindGroupDescriptor": "The `GPUBindGroupDescriptor` interface represents a descriptor for creating bind groups in WebGPU. It extends the `GPUObjectDescriptorBase` and is used to specify the layout and entries of a bind group.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpubindgroupdescriptor).",
    "GPUBindGroupDescriptor#layout": "The `layout` property specifies the `GPUBindGroupLayout` that the entries of this bind group will conform to. This layout defines how resources are bound and accessed in shaders.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpubindgroupdescriptor-layout).",
    "GPUBindGroupDescriptor#entries": "The `entries` property is a list of `GPUBindGroupEntry` objects that describe the resources to expose to the shader for each binding described by the `layout`. Each entry specifies how a particular resource should be bound.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpubindgroupdescriptor-entries).",
    "GPUBindGroupEntry": "Represents a single resource to be bound in a [GPUBindGroup]. This interface is used to describe the binding of resources such as samplers, texture views, external textures, or buffer bindings within a bind group.\n\nFor more details, refer to the [WebGPU specification on GPUBindGroupEntry](https://www.w3.org/TR/webgpu/#dictdef-gpubindgroupentry).",
    "GPUBindGroupEntry#binding": "A unique identifier for a resource binding within the [GPUBindGroup]. This identifier corresponds to a `GPUBindGroupLayoutEntry.binding` and a `@binding` attribute in the [GPUShaderModule].\n\n**Type:** [GPUIndex32](TYPE_MAPPING.md)",
    "GPUBindGroupEntry#resource": "The resource to bind, which can be one of the following types:\n- [GPUSampler]\n- [GPUTextureView]\n- [GPUExternalTexture]\n- [GPUBufferBinding]\n\n**Type:** [GPUBindingResource](TYPE_MAPPING.md)",
    "GPUPipelineLayoutDescriptor": "The `GPUPipelineLayoutDescriptor` interface defines all the [GPUBindGroupLayout](https://www.w3.org/TR/webgpu/#dictdef-gpubindgrouplayout)s used by a pipeline. This descriptor is essential for configuring the layout of bind groups in a GPU pipeline, ensuring that shader modules can access resources correctly.\n\n**Inheritance**: This interface inherits from [GPUObjectDescriptorBase](https://www.w3.org/TR/webgpu/#dictdef-gpuobjectdescriptorbase).\n\nIn this example, `bindGroupLayout1` and `bindGroupLayout2` are instances of [GPUBindGroupLayout]. The `bindGroupLayouts` list defines the layout of bind groups that the pipeline will use.",
    "GPUPipelineLayoutDescriptor#bindGroupLayouts": "A list of optional [GPUBindGroupLayout](https://www.w3.org/TR/webgpu/#dictdef-gpubindgrouplayout)s that the pipeline will use. Each element in this list corresponds to a `@group` attribute in the [GPUShaderModule], with the `N`th element corresponding to `@group(N)`.\n\n**Type**: `List<GPUBindGroupLayout?>`\n\n**Details**:\n- This list defines the layout of bind groups that the pipeline will use.\n- Each [GPUBindGroupLayout] in this list must match the corresponding `@group` attribute in the shader module.\n\nIn this example, `bindGroupLayout1` and `bindGroupLayout2` are instances of [GPUBindGroupLayout]. The `bindGroupLayouts` list defines the layout of bind groups that the pipeline will use.",
    "GPUShaderModuleCompilationHint": "Represents a hint for compiling a GPUShaderModule. This interface provides information about the entry point and layout that may be used with the shader module in future pipeline creation calls.\n\nFor more details, refer to the WebGPU specification on Shader Module Compilation Information: https://www.w3.org/TR/webgpu/#shader-module-compilation-information.",
    "GPUShaderModuleCompilationHint#entryPoint": "The entry point of the shader module. This is a required field and must be specified.\n\nType: String (https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-string/).",
    "GPUShaderModuleCompilationHint#layout": "A GPUPipelineLayout that the shader module may be used with in future pipeline creation calls. If set to null, the default pipeline layout for the entry point associated with this hint will be used.\n\nType: GPUPipelineLayout or GPUAutoLayoutMode.",
    "GPUPipelineDescriptorBase": "Represents the base descriptor for a GPU pipeline. This interface extends [GPUObjectDescriptorBase] and is used to define the layout of a GPU pipeline.\n\nThe `layout` property specifies either a [GPUPipelineLayout] or an automatic layout mode (`\"auto\"`). When `\"auto\"` is specified, the pipeline layout is generated automatically.",
    "GPUPipelineDescriptorBase#layout": "Specifies the layout for this pipeline. This can be either a [GPUPipelineLayout] object or the string `\"auto\"` to generate the pipeline layout automatically.\n\n**Type**: [GPUPipelineLayout] or `String`\n\n**Default**: None\n\n**Behavior**:\n- If a [GPUPipelineLayout] is provided, it defines the specific layout for the pipeline.\n- If `\"auto\"` is specified, the pipeline layout is generated automatically. However, this means that the pipeline cannot share [GPUBindGroup]s with any other pipelines.\n\n**See also**: [GPUAutoLayoutMode], [GPUBindGroup]",
    "GPUComputePipelineDescriptor": "Represents a descriptor for creating a compute pipeline in WebGPU. This interface extends [GPUPipelineDescriptorBase] and is used to define the configuration for a compute pipeline, which executes compute shaders.\n\nA compute pipeline is responsible for performing general-purpose computations on the GPU. It does not render graphics but can be used for tasks such as data processing, simulations, and other parallel computations.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpucomputepipelinedescriptor).",
    "GPUComputePipelineDescriptor#compute": "Specifies the compute shader stage for the pipeline. This member is required and must be set to a valid [GPUProgrammableStage] object that describes the compute shader entry point.\n\nThe compute shader is responsible for executing the compute operations defined in the shader code. It does not produce visual output but can perform parallel computations on data.\n\n**Type:** [GPUProgrammableStage]",
    "GPURenderPipelineDescriptor": "The `GPURenderPipelineDescriptor` interface extends `GPUPipelineDescriptorBase` and defines the configuration for a render pipeline in WebGPU. It specifies the vertex, primitive, depth-stencil, multisample, and fragment states required to create a render pipeline. For more details, refer to the [W3C specification](https://www.w3.org/TR/webgpu/#dictdef-gpurenderpipelinedescriptor).",
    "GPURenderPipelineDescriptor#vertex": "`vertex` of type `GPUVertexState`. Describes the vertex shader entry point of the pipeline and its input buffer layouts. This is a required field. For more details, refer to the [W3C specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpipelinedescriptor-vertex).",
    "GPURenderPipelineDescriptor#primitive": "`primitive` of type `GPUPrimitiveState`, defaulting to `{}` if not provided. Describes the primitive-related properties of the pipeline, such as topology and strip index format. For more details, refer to the [W3C specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpipelinedescriptor-primitive).",
    "GPURenderPipelineDescriptor#depthStencil": "`depthStencil` of type `GPUDepthStencilState?`. Describes the optional depth-stencil properties, including testing, operations, and bias. This field is nullable. For more details, refer to the [W3C specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpipelinedescriptor-depthstencil).",
    "GPURenderPipelineDescriptor#multisample": "`multisample` of type `GPUMultisampleState`, defaulting to `{}` if not provided. Describes the multi-sampling properties of the pipeline, such as count and mask. For more details, refer to the [W3C specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpipelinedescriptor-multisample).",
    "GPURenderPipelineDescriptor#fragment": "`fragment` of type `GPUFragmentState?`. Describes the fragment shader entry point of the pipeline and its output colors. If not provided, the [no color output mode](https://www.w3.org/TR/webgpu/#no-color-output) is enabled. This field is nullable. For more details, refer to the [W3C specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpipelinedescriptor-fragment).",
    "GPUMultisampleState": "Represents the multisampling state used by a [GPURenderPipeline](https://www.w3.org/TR/webgpu/#gpurenderpipeline) to interact with render pass attachments that support multisampling.\n\nThis interface defines how many samples per pixel are used, which samples are written to, and whether alpha-to-coverage is enabled. The multisample state is crucial for rendering high-quality images by reducing aliasing artifacts.\n\n**See also:**\n- [GPUMultisampleState dictionary in the WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpumultisamplestate)",
    "GPUMultisampleState#count": "Specifies the number of samples per pixel. This value determines the level of multisampling used during rendering.\n\n**Type:** [GPUSize32](https://www.w3.org/TR/webgpu/#typedefdef-gpusize32)\n\n**Default Value:** 1\n\n**Constraints:**\n- Must be either 1 or 4.\n- If `alphaToCoverageEnabled` is `true`, `count` must be greater than 1.\n\n**See also:**\n- [count member in the WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpumultisamplestate-count)",
    "GPUMultisampleState#mask": "Determines which samples are written to during rendering. This mask allows for selective sampling, which can be useful for optimizing performance or achieving specific visual effects.\n\n**Type:** [GPUSampleMask](https://www.w3.org/TR/webgpu/#typedefdef-gpusamplemask)\n\n**Default Value:** 0xFFFFFFFF\n\n**See also:**\n- [mask member in the WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpumultisamplestate-mask)",
    "GPUMultisampleState#alphaToCoverageEnabled": "When set to `true`, enables alpha-to-coverage, which uses the fragment's alpha channel to generate a sample coverage mask. This can improve the quality of antialiased edges.\n\n**Type:** Boolean\n\n**Default Value:** false\n\n**Constraints:**\n- If `alphaToCoverageEnabled` is `true`, `count` must be greater than 1.\n\n**See also:**\n- [alphaToCoverageEnabled member in the WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpumultisamplestate-alphatocoverageenabled)",
    "GPUFragmentState": "Represents a fragment state in WebGPU, which is a type of programmable stage that defines how fragments are processed during rendering. This interface extends [GPUProgrammableStage] and includes specific configurations for color targets.\n\nThe `GPUFragmentState` interface is used to configure the fragment shader stage of a GPU pipeline, specifying how the colors are written to the render target. This is crucial for defining the visual output of a rendering operation.\n\n**See also:**\n- [WebGPU Specification: GPUProgrammableStage](https://www.w3.org/TR/webgpu/#gpuprogrammablestage)",
    "GPUFragmentState#targets": "A list of [GPUColorTargetState] objects that define the formats and behaviors of the color targets this pipeline writes to. Each `GPUColorTargetState` in the list specifies how a particular color target should be handled during rendering.\n\n**Type:** List<[GPUColorTargetState]?>\n\n**See also:**\n- [WebGPU Specification: GPUFragmentState](https://www.w3.org/TR/webgpu/#dictdef-gpufragmentstate)",
    "GPUColorTargetState": "Represents the state of a color target in a GPU render pipeline. This interface defines the format, blending behavior, and write mask for a color attachment in a render pass.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpucolortargetstate).",
    "GPUColorTargetState#format": "The format of this color target. The pipeline will only be compatible with render pass encoders which use a texture view of this format in the corresponding color attachment.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpucolortargetstate-format).",
    "GPUColorTargetState#blend": "The blending behavior for this color target. If left undefined, disables blending for this color target.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpucolortargetstate-blend).",
    "GPUColorTargetState#writeMask": "Bitmask controlling which channels are written to when drawing to this color target. Defaults to `0xF` (all channels).\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpucolortargetstate-writemask).",
    "GPUBlendState": "Represents the blend state used in rendering operations, defining how colors and alpha values are blended.\n\nThis interface is part of the WebGPU API and corresponds to the `GPUBlendState` dictionary defined in the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpublendstate).\n\nThe `GPUBlendState` interface includes two properties: `color` and `alpha`, both of type `GPUBlendComponent`. These properties specify the blending behavior for color channels and alpha channels, respectively.",
    "GPUBlendComponent": "Represents a blend component used in blending operations for color or alpha components of a fragment. This interface defines how the source and destination colors are combined during rendering.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpublendcomponent).",
    "GPUBlendComponent#operation": "Defines the [GPUBlendOperation] used to calculate the values written to the target attachment components.\n\nThis property specifies the blending operation to be performed. The default value is `add`.\n\n**Type:** [GPUBlendOperation]\n\n**Default Value:** \"add\"\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpublendcomponent-operation).",
    "GPUBlendComponent#srcFactor": "Defines the [GPUBlendFactor] operation to be performed on values from the fragment shader.\n\nThis property specifies the blending factor for the source color. The default value is `one`.\n\n**Type:** [GPUBlendFactor]\n\n**Default Value:** \"one\"\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpublendcomponent-srcfactor).",
    "GPUBlendComponent#dstFactor": "Defines the [GPUBlendFactor] operation to be performed on values from the target attachment.\n\nThis property specifies the blending factor for the destination color. The default value is `zero`.\n\n**Type:** [GPUBlendFactor]\n\n**Default Value:** \"zero\"\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpublendcomponent-dstfactor).",
    "GPUStencilFaceState": "Represents a set of stencil face state parameters that define how stencil tests and operations are performed. This interface is used to configure the behavior of the stencil buffer for front or back-facing triangles in a render pipeline.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpustencilfacestate).",
    "GPUStencilFaceState#compare": "Specifies the comparison function used for stencil tests. This determines how the current stencil value is compared to the reference value.\n\n**Default Value:** `GPUCompareFunction.Always`\n\n**See Also:**\n- [W3C WebGPU specification: GPUStencilFaceState.compare](https://www.w3.org/TR/webgpu/#dom-gpustencilfacestate-compare)",
    "GPUStencilFaceState#failOp": "Specifies the operation to perform when the stencil test fails. This defines what action to take if the comparison function does not pass.\n\n**Default Value:** `GPUStencilOperation.Keep`\n\n**See Also:**\n- [W3C WebGPU specification: GPUStencilFaceState.failOp](https://www.w3.org/TR/webgpu/#dom-gpustencilfacestate-failop)",
    "GPUStencilFaceState#depthFailOp": "Specifies the operation to perform when the stencil test passes but the depth test fails. This defines what action to take if the comparison function passes but the depth test does not.\n\n**Default Value:** `GPUStencilOperation.Keep`\n\n**See Also:**\n- [W3C WebGPU specification: GPUStencilFaceState.depthFailOp](https://www.w3.org/TR/webgpu/#dom-gpustencilfacestate-depthfailop)",
    "GPUStencilFaceState#passOp": "Specifies the operation to perform when both the stencil test and the depth test pass. This defines what action to take if both tests are successful.\n\n**Default Value:** `GPUStencilOperation.Keep`\n\n**See Also:**\n- [W3C WebGPU specification: GPUStencilFaceState.passOp](https://www.w3.org/TR/webgpu/#dom-gpustencilfacestate-passop)",
    "GPUVertexState": "Represents a vertex state in the WebGPU API, defining how vertex data is laid out and processed. This interface extends [GPUProgrammableStage], allowing it to be used as part of a render pipeline.\n\nA `GPUVertexState` object specifies the layout of vertex attribute data in vertex buffers. Each buffer's layout is defined by a list of `GPUVertexBufferLayout` objects, which describe the structure and stride of the vertex data.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#vertex-state).",
    "GPUVertexState#buffers": "A list of `GPUVertexBufferLayout` objects that define the layout of vertex attribute data in each vertex buffer used by this pipeline.\n\nEach `GPUVertexBufferLayout` specifies how the vertex data is structured, including the stride between elements and the attributes that describe the members of the structure. This allows the GPU to correctly interpret the vertex data during rendering.\n\n**Type**: List<[GPUVertexBufferLayout]>\n\n**Default Value**: An empty list\n\nFor more information, see the [W3C WebGPU specification on GPUVertexBufferLayout](https://www.w3.org/TR/webgpu/#dictdef-gpuvertexbufferlayout).",
    "GPUVertexBufferLayout": "Represents the layout of a vertex buffer in WebGPU. This interface defines how vertices are structured and accessed, including the stride between elements, the step mode (whether data is per-vertex or per-instance), and the attributes that describe the vertex data.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpuvertexbufferlayout).",
    "GPUVertexBufferLayout#arrayStride": "The stride, in bytes, between elements of this array. This value specifies how much memory is allocated for each vertex or instance in the buffer.\n\n**Type:** [GPUSize64](https://www.w3.org/TR/webgpu/#typedefdef-gpusize64)",
    "GPUVertexBufferLayout#stepMode": "Specifies whether each element of this array represents per-vertex data or per-instance data. The default value is `GPUVertexStepMode.VERTEX`.\n\n**Type:** [GPUVertexStepMode](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexstepmode)",
    "GPUVertexBufferLayout#attributes": "An array defining the layout of the vertex attributes within each element. This sequence describes how the vertex data is structured and accessed.\n\n**Type:** List<[GPUVertexAttribute](https://www.w3.org/TR/webgpu/#dictdef-gpuvertexattribute)>",
    "GPUVertexAttribute": "Represents a vertex attribute in the WebGPU API. This interface defines the format, offset, and shader location of a vertex attribute.\n\nA `GPUVertexAttribute` is used to describe how data from a vertex buffer should be interpreted by the GPU. It specifies the format of the data (e.g., float32, uint32), the byte offset within the vertex buffer where the data starts, and the shader location that corresponds to this attribute.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpuvertexattribute).",
    "GPUVertexAttribute#format": "The format of the vertex attribute. This specifies how the data should be interpreted by the GPU.\n\n**Type:** [GPUVertexFormat]\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpuvertexattribute-format).",
    "GPUVertexAttribute#offset": "The offset, in bytes, from the beginning of the vertex buffer element to the data for this attribute.\n\n**Type:** [GPUSize64]\n\nThis value must be a multiple of the minimum of 4 and the byte size of the format specified by `format`. It defines where within the vertex buffer the data for this attribute begins.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpuvertexattribute-offset).",
    "GPUVertexAttribute#shaderLocation": "The numeric location associated with this attribute. This corresponds to a `@location` attribute declared in the vertex module of the shader.\n\n**Type:** [GPUIndex32]\n\nThis value must be less than the maximum number of vertex attributes supported by the device, as specified by `device.limits.maxVertexAttributes`.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpuvertexattribute-shaderlocation).",
    "GPUCommandBufferDescriptor": "The `GPUCommandBufferDescriptor` interface represents a descriptor for creating command buffers in WebGPU. This interface inherits from [GPUObjectDescriptorBase], providing a base set of properties and methods that are common to all GPU object descriptors.\n\nA command buffer is a sequence of commands that can be submitted to the GPU for execution. The `GPUCommandBufferDescriptor` specifies the configuration options for creating these command buffers, such as label and usage flags.\n\nThis interface is used when calling [GPUDevice.createCommandBuffer] to create a new command buffer with the specified configuration.\n\n**See also:**\n- [WebGPU Specification: GPUCommandBufferDescriptor](https://www.w3.org/TR/webgpu/#dictdef-gpucommandbufferdescriptor)",
    "GPUCommandEncoderDescriptor": "The `GPUCommandEncoderDescriptor` interface represents a descriptor used to create a [GPUCommandEncoder](https://www.w3.org/TR/webgpu/#gpucommandencoder) object. This descriptor inherits from the base descriptor interface [GPUObjectDescriptorBase](https://www.w3.org/TR/webgpu/#dictdef-gpuobjectdescriptorbase).\n\nThe `GPUCommandEncoderDescriptor` is used to specify configuration options for the command encoder, such as label and device.\n\n**See Also:**\n- [GPUObjectDescriptorBase](https://www.w3.org/TR/webgpu/#dictdef-gpuobjectdescriptorbase)",
    "GPUComputePassTimestampWrites": "Represents a dictionary that specifies the query set and indices where timestamps will be written during a compute pass. This interface is used to measure the duration of compute passes by recording timestamps at the beginning and end of the pass.\n\nFor more details, refer to the [WebGPU specification on GPUComputePassTimestampWrites](https://www.w3.org/TR/webgpu/#dictdef-gpucomputepasstimestampwrites).",
    "GPUComputePassTimestampWrites#querySet": "The `GPUQuerySet` of type \"timestamp\" that the query results will be written to. This set contains the queries where the timestamps will be recorded.\n\n**Type**: [GPUQuerySet](https://www.w3.org/TR/webgpu/#gpuqueryset)",
    "GPUComputePassTimestampWrites#beginningOfPassWriteIndex": "If defined, indicates the query index in `querySet` into which the timestamp at the beginning of the compute pass will be written. This value is of type [GPUSize32](https://www.w3.org/TR/webgpu/#typedefdef-gpusize32).\n\n**Type**: GPUSize32?",
    "GPUComputePassTimestampWrites#endOfPassWriteIndex": "If defined, indicates the query index in `querySet` into which the timestamp at the end of the compute pass will be written. This value is of type [GPUSize32](https://www.w3.org/TR/webgpu/#typedefdef-gpusize32).\n\n**Type**: GPUSize32?",
    "GPUComputePassDescriptor": "Represents a descriptor for configuring a compute pass in WebGPU. This interface extends [GPUObjectDescriptorBase] and is used to specify the details of a compute pass, including timestamp writes.\n\nFor more information, see the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpucomputepassdescriptor).",
    "GPUComputePassDescriptor#timestampWrites": "Defines which timestamp values will be written for this pass and where to write them.\n\nThis property is of type [GPUComputePassTimestampWrites].\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpucomputepassdescriptor-timestampwrites).",
    "GPURenderPassTimestampWrites": "Represents a dictionary that specifies the query set and indices where timestamps will be written during a render pass. This interface is used to capture timing information at the beginning and end of a render pass.\n\nFor more details, refer to the [WebGPU specification on GPURenderPassTimestampWrites](https://www.w3.org/TR/webgpu/#dom-gpurenderpasstimestampwrites).",
    "GPURenderPassTimestampWrites#querySet": "The GPUQuerySet of type `timestamp` that the query results will be written to.\n\nThis property is required and specifies the query set where the timestamps will be recorded.",
    "GPURenderPassTimestampWrites#beginningOfPassWriteIndex": "An optional index in the [querySet] that indicates where the timestamp at the beginning of the render pass will be written.\n\nIf defined, this property specifies the exact query index within the `querySet` where the start timestamp of the render pass will be recorded.",
    "GPURenderPassTimestampWrites#endOfPassWriteIndex": "An optional index in the [querySet] that indicates where the timestamp at the end of the render pass will be written.\n\nIf defined, this property specifies the exact query index within the `querySet` where the end timestamp of the render pass will be recorded.",
    "GPURenderPassDescriptor": "The `GPURenderPassDescriptor` interface defines the configuration for a render pass in WebGPU. It specifies the color attachments, depth/stencil attachment, occlusion query set, timestamp writes, and maximum draw count for the render pass.\n\nThis descriptor is used to configure the rendering process by specifying how different types of data will be handled during the render pass. The `colorAttachments` property defines which color buffers will receive the output from the render pass. The `depthStencilAttachment` specifies the depth/stencil buffer that will be used for depth testing and stencil operations. The `occlusionQuerySet` allows for occlusion queries to be performed, and the `timestampWrites` can be used to write timestamps during the render pass.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpurenderpassdescriptor).",
    "GPURenderPassDescriptor#colorAttachments": "The `colorAttachments` property is a list of `GPURenderPassColorAttachment` objects that define the color attachments for the render pass. Each attachment specifies how the output from the render pass will be written to a particular color buffer.\n\nDue to usage compatibility, no color attachment may alias another attachment or any resource used inside the render pass.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpassdescriptor-colorattachments).",
    "GPURenderPassDescriptor#depthStencilAttachment": "The `depthStencilAttachment` property specifies a `GPURenderPassDepthStencilAttachment` object that defines the depth/stencil attachment for the render pass. This attachment is used for depth testing and stencil operations during the rendering process.\n\nDue to usage compatibility, no writable depth/stencil attachment may alias another attachment or any resource used inside the render pass.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpassdescriptor-depthstencilattachment).",
    "GPURenderPassDescriptor#occlusionQuerySet": "The `occlusionQuerySet` property specifies a `GPUQuerySet` object that defines where the occlusion query results will be stored for this render pass. Occlusion queries are used to determine whether certain pixels were rendered during the pass.",
    "GPURenderPassDescriptor#timestampWrites": "The `timestampWrites` property allows you to specify a list of `GPUQuerySet` objects that define where timestamp query results will be stored for this render pass. Timestamps are used to measure the time taken by different parts of the rendering process.",
    "GPURenderPassDescriptor#maxDrawCount": "The `maxDrawCount` property specifies the maximum number of draw calls that can be made during the render pass. This is useful for optimizing performance and managing resources efficiently.\n\nSetting an appropriate value for `maxDrawCount` helps in preventing resource exhaustion and ensures smooth rendering.",
    "GPURenderBundleDescriptor": "Represents a descriptor for creating a [GPURenderBundle]. This interface inherits from [GPUObjectDescriptorBase], which provides common properties and methods for GPU objects.\n\nThe `GPURenderBundleDescriptor` is used to specify the configuration options when creating a render bundle. A render bundle encapsulates a sequence of rendering commands that can be executed multiple times with different parameters, improving performance by reducing the overhead of command encoding.",
    "GPURenderBundleEncoderDescriptor": "Represents a descriptor for creating a GPURenderBundleEncoder. This interface extends the GPURenderPassLayout and is used to specify whether the depth or stencil components of a render pass are read-only.\n\n@see [WebGPU Specification - GPURenderBundleEncoderDescriptor](https://www.w3.org/TR/webgpu/#dictdef-gpurenderbundleencoderdescriptor)",
    "GPURenderBundleEncoderDescriptor#depthReadOnly": "Indicates whether the render bundle modifies the depth component of the GPURenderPassDepthStencilAttachment in any render pass it is executed in.\n\nIf set to true, the depth component is read-only. This can be useful for optimizing performance by avoiding unnecessary writes to the depth buffer.\n\n@return A Boolean value indicating whether the depth component is read-only.\n@default false",
    "GPURenderBundleEncoderDescriptor#stencilReadOnly": "Indicates whether the render bundle modifies the stencil component of the GPURenderPassDepthStencilAttachment in any render pass it is executed in.\n\nIf set to true, the stencil component is read-only. This can be useful for optimizing performance by avoiding unnecessary writes to the stencil buffer.\n\n@return A Boolean value indicating whether the stencil component is read-only.\n@default false",
    "GPUQuerySetDescriptor": "Represents a descriptor for creating a [GPUQuerySet](https://www.w3.org/TR/webgpu/#gpuqueryset) object. This interface extends [GPUObjectDescriptorBase], providing the necessary configuration parameters to define the type and count of queries managed by the query set.\n\n**See also:**\n- [WebGPU Specification: GPUQuerySetDescriptor](https://www.w3.org/TR/webgpu/#dictdef-gpuquerysetdescriptor)",
    "GPUQuerySetDescriptor#type": "Specifies the type of queries managed by the [GPUQuerySet]. This property is required and must be set to one of the values defined in the [GPUQueryType](https://www.w3.org/TR/webgpu/#enumdef-gpuquerytype) enum.\n\n**See also:**\n- [WebGPU Specification: type](https://www.w3.org/TR/webgpu/#dom-gpuquerysetdescriptor-type)",
    "GPUQuerySetDescriptor#count": "Specifies the number of queries managed by the [GPUQuerySet]. This property is required and must be set to a valid [GPUSize32](https://www.w3.org/TR/webgpu/#typedefdef-gpusize32) value.\n\n**See also:**\n- [WebGPU Specification: count](https://www.w3.org/TR/webgpu/#dom-gpuquerysetdescriptor-count)",
    "GPUTextureViewDescriptor#arrayLayerCount": "`arrayLayerCount` specifies how many array layers, starting with `baseArrayLayer`, are accessible to the texture view. This property defines the range of array layers that can be accessed by the view.\n\nSee also: [WebGPU Specification - GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate).",
    "GPUSamplerBindingLayout": "Represents a binding layout for samplers in WebGPU. This interface defines the type of sampler that can be bound to a specific binding.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpusamplerbindinglayout).",
    "GPUSamplerBindingLayout#type": "Specifies the type of sampler that can be bound to this binding layout. This is an enumeration value that indicates whether the sampler is used for filtering, non-filtering, or comparison operations.\n\n**Type**: [GPUSamplerBindingType]\n\n**Default Value**: \"filtering\"\n\nThis property determines how the sampler will be utilized in the shader. For example, a filtering sampler might be used for texture sampling with mipmapping, while a non-filtering sampler might be used for shadow mapping.",
    "GPUBlendState#color": "Defines the blending behavior of the corresponding render target for color channels.\n\nThis property is of type `GPUBlendComponent` and specifies how the color channels are blended during rendering. For more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpublendstate-color).",
    "GPUBlendState#alpha": "Defines the blending behavior of the corresponding render target for the alpha channel.\n\nThis property is of type `GPUBlendComponent` and specifies how the alpha channel is blended during rendering. For more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpublendstate-alpha).",
    "GPURenderPassLayout": "Represents the layout of a render pass, specifying the formats and sample counts for color and depth/stencil attachments.\n\nThis interface is used to define the configuration of a render pass, which includes the formats of the color attachments and the optional depth/stencil attachment. It also specifies the number of samples per pixel in the attachments.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#gpurenderpasslayout).",
    "GPURenderPassLayout#colorFormats": "A list of the [GPUTextureFormat](https://www.w3.org/TR/webgpu/#enumdef-gputextureformat)s of the color attachments for this pass or bundle.\n\nThis property specifies the formats of the color attachments that will be used in the render pass. Each format corresponds to a texture view that will be rendered to during the pass.",
    "GPURenderPassLayout#depthStencilFormat": "The [GPUTextureFormat](https://www.w3.org/TR/webgpu/#enumdef-gputextureformat) of the depth/stencil attachment for this pass or bundle.\n\nThis property specifies the format of the depth/stencil attachment that will be used in the render pass. It is optional and can be `null` if no depth/stencil attachment is required.",
    "GPURenderPassLayout#sampleCount": "Number of samples per pixel in the attachments for this pass or bundle.\n\nThis property specifies the number of samples per pixel for multisampling. The default value is `1`, which means no multisampling.",
    "GPUExtent3D": "Represents a 3-dimensional extent, which defines the size of a texture or other GPU resources. This interface can be used to specify dimensions in three axes: width, height, and depth or array layers.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#gpuextent3d).\n\n@see [GPUExtent3DDict](https://www.w3.org/TR/webgpu/#dictdef-gpuextent3ddict)",
    "GPUExtent3D#width": "The width of the extent.\n\nThis property corresponds to the `width` field in the [GPUExtent3DDict](https://www.w3.org/TR/webgpu/#dictdef-gpuextent3ddict).\n\n@return The width as a [GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate).",
    "GPUExtent3D#height": "The height of the extent.\n\nThis property corresponds to the `height` field in the [GPUExtent3DDict](https://www.w3.org/TR/webgpu/#dictdef-gpuextent3ddict), which defaults to 1 if not specified.\n\n@return The height as a [GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate).",
    "GPUExtent3D#depthOrArrayLayers": "The depth of the extent or the number of array layers it contains.\n\nThis property corresponds to the `depthOrArrayLayers` field in the [GPUExtent3DDict](https://www.w3.org/TR/webgpu/#dictdef-gpuextent3ddict), which defaults to 1 if not specified. If used with a [GPUTexture](https://www.w3.org/TR/webgpu/#gputexture) with a dimension of `\"3d\"`, it defines the depth of the texture. If used with a `GPUTexture` with a dimension of `\"2d\"`, it defines the number of array layers in the texture.\n\n@return The depth or number of array layers as a [GPUIntegerCoordinate](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinate).",
    "GPUSampler": "/**\n * The `GPUSampler` interface encodes transformations and filtering information that can be used in a shader to interpret texture resource data.\n * \n * This interface is created via the [GPUDevice.createSampler()] method.\n * \n * For more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#gpusampler).\n */\ninterface GPUSampler : GPUBindingResource, GPUObjectBase, AutoCloseable",
    "GPUTextureView": "A `GPUTextureView` represents a view onto some subset of the texture subresources defined by a particular [GPUTexture]. This interface allows for efficient access and manipulation of specific portions of a texture, enabling optimized rendering and data processing.\n\nThe `GPUTextureView` is part of the WebGPU API and is designed to be used in conjunction with other GPU resources such as [GPUBindGroup] and [GPURenderPipeline]. It provides a way to bind specific texture views to shaders, enabling advanced rendering techniques.\n\nThis interface inherits from `GPUBindingResource` and `GPUObjectBase`, which means it can be used as a binding resource in various GPU operations. Additionally, it implements the `AutoCloseable` interface, allowing for proper resource management and cleanup.\n\n**See also:**\n- [WebGPU Specification: GPUTextureView](https://www.w3.org/TR/webgpu/#gputextureview)",
    "GPUSupportedLimits": "The `GPUSupportedLimits` interface provides access to the supported limits of a GPU adapter or device.\nThese limits define the maximum capabilities and constraints for various resources and operations,\nsuch as texture dimensions, bind groups, buffers, and shader stages. This information is crucial\nfor optimizing performance and ensuring compatibility with the underlying hardware.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#gpusupportedlimits).",
    "GPUSupportedLimits#maxTextureDimension1D": "The maximum size for a 1D texture dimension. This value represents the largest allowable width\nfor a 1D texture in texels.\n\n**Type:** `UInt`",
    "GPUSupportedLimits#maxTextureDimension2D": "The maximum size for a 2D texture dimension. This value represents the largest allowable width or height\nfor a 2D texture in texels.\n\n**Type:** `UInt`",
    "GPUSupportedLimits#maxTextureDimension3D": "The maximum size for a 3D texture dimension. This value represents the largest allowable depth\nfor a 3D texture in texels.\n\n**Type:** `UInt`",
    "GPUSupportedLimits#maxTextureArrayLayers": "The maximum number of layers in a texture array. This value represents the largest allowable number\nof layers for a texture array.\n\n**Type:** `UInt`",
    "GPUSupportedLimits#maxBindGroups": "The maximum number of bind groups that can be used in a single pipeline. This value represents the largest allowable\nnumber of bind groups for a pipeline.\n\n**Type:** `UInt`",
    "GPUSupportedLimits#maxBindGroupsPlusVertexBuffers": "The maximum number of bind groups plus vertex buffers that can be used in a single pipeline. This value represents the largest allowable\ncombined count of bind groups and vertex buffers for a pipeline.\n\n**Type:** `UInt`",
    "GPUSupportedLimits#maxBindingsPerBindGroup": "The maximum number of bindings per bind group. This value represents the largest allowable number of bindings for a single bind group.\n\n**Type:** `UInt`",
    "GPUSupportedLimits#maxDynamicUniformBuffersPerPipelineLayout": "The maximum number of dynamic uniform buffers per pipeline layout. This value represents the largest allowable number of dynamic uniform buffers for a single pipeline layout.\n\n**Type:** `UInt`",
    "GPUAdapterInfo": "The `GPUAdapterInfo` interface exposes various identifying information about an adapter. None of the members in `GPUAdapterInfo` are guaranteed to be populated with any particular value; if no value is provided, the attribute will return the empty string \" \". It is at the user agent’s discretion which values to reveal, and it is likely that on some devices none of the values will be populated. As such, applications **must** be able to handle any possible `GPUAdapterInfo` values, including the absence of those values.\n\nThe `GPUAdapterInfo` for an adapter is exposed via [GPUAdapter.info](https://www.w3.org/TR/webgpu/#dom-gpuadapter-info) and [GPUDevice.adapterInfo](https://www.w3.org/TR/webgpu/#dom-gpudevice-adapterinfo). This info is immutable: for a given adapter, each `GPUAdapterInfo` attribute will return the same value every time it’s accessed.\n\n**Note:** Though the `GPUAdapterInfo` attributes are immutable *once accessed*, an implementation may delay the decision on what to expose for each attribute until the first time it is accessed.",
    "GPUAdapterInfo#vendor": "The `vendor` property returns a string identifying the vendor of the GPU adapter. This value may be an empty string if the user agent chooses not to reveal this information.",
    "GPUAdapterInfo#architecture": "The `architecture` property returns a string identifying the architecture of the GPU adapter. This value may be an empty string if the user agent chooses not to reveal this information.",
    "GPUAdapterInfo#device": "The `device` property returns a string identifying the device name of the GPU adapter. This value may be an empty string if the user agent chooses not to reveal this information.",
    "GPUAdapterInfo#description": "The `description` property returns a string providing a description of the GPU adapter. This value may be an empty string if the user agent chooses not to reveal this information.",
    "GPUAdapterInfo#subgroupMinSize": "The `subgroupMinSize` property returns the minimum size of a subgroup for the GPU adapter. This value is represented as an unsigned integer (`UInt`).",
    "GPUAdapterInfo#subgroupMaxSize": "The `subgroupMaxSize` property returns the maximum size of a subgroup for the GPU adapter. This value is represented as an unsigned integer (`UInt`).",
    "GPUAdapterInfo#isFallbackAdapter": "The `isFallbackAdapter` property returns a boolean indicating whether the adapter is a fallback adapter. A fallback adapter is used when the preferred adapter is not available.",
    "GPUAdapter": "The `GPUAdapter` interface encapsulates a GPU adapter and describes its capabilities, including supported features and limits. This interface is essential for interacting with the underlying GPU hardware and obtaining a `GPUDevice` to perform rendering operations.\n\nTo obtain a `GPUAdapter`, use the `requestAdapter()` method provided by the `GPU` object. The `GPUAdapter` provides read-only access to its features, limits, and information about the adapter.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#gpuadapter).",
    "GPUAdapter#features": "Represents the set of features supported by the GPU adapter. This property is read-only and provides information about the capabilities of the underlying hardware.\n\nThe `features` attribute contains a `GPUSupportedFeatures` object, which includes boolean flags indicating whether specific features are supported.",
    "GPUAdapter#limits": "Represents the limits imposed by the GPU adapter. This property is read-only and provides information about the constraints of the underlying hardware.\n\nThe `limits` attribute contains a `GPUSupportedLimits` object, which includes various limit values such as maximum texture dimensions, maximum bind groups, etc.",
    "GPUAdapter#info": "Provides information about the physical adapter underlying this `GPUAdapter`. This property is read-only and returns a `GPUAdapterInfo` object.\n\nThe `info` attribute contains details such as the name of the adapter, vendor ID, device ID, etc. These values are constant over time for a given `GPUAdapter`.",
    "GPUAdapter#requestDevice(descriptor)": "Asynchronously requests a `GPUDevice` from the adapter. This method returns a `Result<GPUDevice>`, which resolves to a `GPUDevice` instance if successful.\n\nThe `descriptor` parameter is optional and allows specifying configuration options for the device, such as enabling specific features or setting default queue properties.",
    "GPUDevice": "The `GPUDevice` interface encapsulates a GPU device and exposes the functionality of that device. It is the top-level interface through which WebGPU interfaces are created.\n\nTo obtain a `GPUDevice`, use the `requestDevice()` method on a `GPUAdapter`.\n\n**See also:**\n- [WebGPU Specification: GPUDevice](https://www.w3.org/TR/webgpu/#gpudevice)",
    "GPUDevice#features": "Represents the supported features of the GPU device.\n\n**Type:** [GPUSupportedFeatures]\n\n**See also:**\n- [WebGPU Specification: GPUSupportedFeatures](https://www.w3.org/TR/webgpu/#gpusupportedfeatures)",
    "GPUDevice#limits": "Represents the supported limits of the GPU device.\n\n**Type:** [GPUSupportedLimits]\n\n**See also:**\n- [WebGPU Specification: GPUSupportedLimits](https://www.w3.org/TR/webgpu/#gpusupportedlimits)",
    "GPUDevice#adapterInfo": "Provides information about the GPU adapter associated with this device.\n\n**Type:** [GPUAdapterInfo]\n\n**See also:**\n- [WebGPU Specification: GPUAdapterInfo](https://www.w3.org/TR/webgpu/#gpuadapterinfo)",
    "GPUDevice#queue": "Represents the command queue associated with this device.\n\n**Type:** [GPUQueue]\n\n**See also:**\n- [WebGPU Specification: GPUQueue](https://www.w3.org/TR/webgpu/#gpuqueue)",
    "GPUDevice#createBuffer(descriptor)": "Creates a new buffer object based on the provided descriptor.\n\n**Parameters:**\n- `descriptor`: A [GPUBufferDescriptor] that specifies the properties of the buffer to be created.\n\n**Returns:** A new [GPUBuffer] object.\n\n**See also:**\n- [WebGPU Specification: createBuffer](https://www.w3.org/TR/webgpu/#dom-gpudevice-createbuffer)",
    "GPUDevice#createTexture(descriptor)": "Creates a new texture object based on the provided descriptor.\n\n**Parameters:**\n- `descriptor`: A [GPUTextureDescriptor] that specifies the properties of the texture to be created.\n\n**Returns:** A new [GPUTexture] object.\n\n**See also:**\n- [WebGPU Specification: createTexture](https://www.w3.org/TR/webgpu/#dom-gpudevice-createtexture)",
    "GPUDevice#createSampler(descriptor)": "Creates a new sampler object based on the provided descriptor.\n\n**Parameters:**\n- `descriptor`: An optional [GPUSamplerDescriptor] that specifies the properties of the sampler to be created. If not provided, default values are used.\n\n**Returns:** A new [GPUSampler] object.\n\n**See also:**\n- [WebGPU Specification: createSampler](https://www.w3.org/TR/webgpu/#dom-gpudevice-createsampler)",
    "GPUBuffer": "The `GPUBuffer` interface represents a block of memory that can be used in GPU operations. Data is stored in linear layout, meaning each byte of the allocation can be addressed by its offset from the start of the buffer, subject to alignment restrictions depending on the operation. Some buffers can be mapped, making the block of memory accessible via an `ArrayBuffer` called its mapping.\n\nBuffers are created via [GPUDevice.createBuffer()](https://www.w3.org/TR/webgpu/#dom-gpudevice-createbuffer). Buffers may be [mappedAtCreation](https://www.w3.org/TR/webgpu/#dom-gpubufferdescriptor-mappedatcreation).\n\nRefer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#gpubuffer) for more details.",
    "GPUBuffer#size": "The `size` property returns the size of the buffer in bytes. This value is read-only and represents the total allocated memory for this buffer.\n\n**Type:** [GPUSize64Out](https://www.w3.org/TR/webgpu/#typedefdef-gpusize64out)",
    "GPUBuffer#usage": "The `usage` property specifies how the buffer can be used. This value is read-only and represents a combination of flags indicating the allowed operations on this buffer.\n\n**Type:** [GPUBufferUsageFlags](https://www.w3.org/TR/webgpu/#typedefdef-gpuflagsconstant)",
    "GPUBuffer#mapState": "The `mapState` property indicates the current mapping state of the buffer. This value is read-only and can be one of the following: `unmapped`, `pending`, or `mapped`.\n\n**Type:** [GPUBufferMapState](https://www.w3.org/TR/webgpu/#enumdef-gpubuffermapstate)",
    "GPUBuffer#mapAsync(mode, offset, size)": "The `mapAsync` function asynchronously maps the buffer into an `ArrayBuffer`. This operation is non-blocking and returns a [Result](https://kotlinlang.org/api/latest/kotlinx-coroutines/kotlinx-coroutines-core/kotlinx.coroutines/-result/) indicating success or failure.\n\n**Parameters:**\n- `mode`: The mapping mode, which can be either [GPUMapModeRead] or [GPUMapModeWrite].\n- `offset`: (Optional) The offset within the buffer to start mapping. Defaults to 0.\n- `size`: (Optional) The size of the range to map. If null, maps from the offset to the end of the buffer.\n\n**Returns:** A [Result](https://kotlinlang.org/api/latest/kotlinx-coroutines/kotlinx-coroutines-core/kotlinx.coroutines/-result/) indicating success or failure.",
    "GPUBuffer#getMappedRange(offset, size)": "The `getMappedRange` function returns an `ArrayBuffer` representing the mapped range of the buffer. This method can only be called when the buffer is in the `mapped` state.\n\n**Parameters:**\n- `offset`: (Optional) The offset within the buffer to start mapping. Defaults to 0.\n- `size`: (Optional) The size of the range to map. If null, maps from the offset to the end of the buffer.\n\n**Returns:** An [ArrayBuffer](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/ArrayBuffer) containing the mapped data.",
    "GPUBuffer#unmap()": "The `unmap` function unmaps the buffer, making it no longer accessible via an `ArrayBuffer`. This method can only be called when the buffer is in the `mapped` state.",
    "GPUBindGroupLayout": "The `GPUBindGroupLayout` interface defines the structure that specifies how resources are bound in a [GPUBindGroup] and made accessible to shader stages. This layout is crucial for organizing and managing bindings efficiently within the WebGPU pipeline.\n\n**Inheritance:**\n- Implements `AutoCloseable`\n- Inherits from [GPUObjectBase]\n\n**Notes:**\n- The `GPUBindGroupLayout` is immutable once created.\n- It must be properly closed to free up resources when no longer needed.\n\n**See Also:**\n- [WebGPU Specification: GPUBindGroupLayout](https://www.w3.org/TR/webgpu/#gpubindgrouplayout)",
    "GPUBindGroup": "A `GPUBindGroup` defines a set of resources to be bound together in a group and specifies how these resources are used in shader stages. This interface is essential for managing the binding of buffers, textures, samplers, and other resources that shaders need during rendering.\n\nThe `GPUBindGroup` interface extends [GPUObjectBase], which provides common functionality for GPU objects such as reference counting and lifecycle management. It also implements `AutoCloseable`, allowing for proper resource cleanup when the bind group is no longer needed.\n\nFor more details, refer to the [WebGPU specification section on GPUBindGroup](https://www.w3.org/TR/webgpu/#gpubindgroup).\n\n**See Also:**\n- [GPUObjectBase]",
    "GPUPipelineLayout": "A [GPUPipelineLayout](https://www.w3.org/TR/webgpu/#gpupipelinelayout) defines the mapping between resources of all [GPUBindGroup](https://www.w3.org/TR/webgpu/#gpubindgroup) objects set up during command encoding in [setBindGroup()](https://www.w3.org/TR/webgpu/#dom-gpubindingcommandsmixin-setbindgroup), and the shaders of the pipeline set by [GPURenderCommandsMixin.setPipeline] or [GPUComputePassEncoder.setPipeline].\n\nThis interface extends [GPUObjectBase] and implements [AutoCloseable], allowing for proper resource management.\n\n**See Also:**\n- [GPUObjectBase]\n- [AutoCloseable](https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-auto-closeable/)",
    "GPUShaderModule": "The `GPUShaderModule` interface represents a reference to an internal shader module object in the WebGPU API. This interface is used to manage and interact with shader modules, which contain the compiled code for shaders.\n\nA shader module is created from shader source code or precompiled binary data and can be used to create pipeline objects that define how rendering operations are performed.\n\nFor more details, refer to the [WebGPU specification on GPUShaderModule](https://www.w3.org/TR/webgpu/#shader-module).\n\n**Inheritance:**\n- `GPUObjectBase`\n- `AutoCloseable`",
    "GPUShaderModule#getCompilationInfo()": "Retrieves the compilation information for the shader module. This method returns a `Result` object that contains either the `GPUCompilationInfo` or an error indicating why the compilation failed.\n\n**Returns:**\n- A `Result<GPUCompilationInfo>` containing the compilation information if successful, or an error otherwise.",
    "GPUComputePipeline": "A [GPUComputePipeline](https://www.w3.org/TR/webgpu/#gpucomputepipeline) is a specialized type of pipeline that controls the compute shader stage. It is used within a [GPUComputePassEncoder](https://www.w3.org/TR/webgpu/#gpucomputepassencoder) to execute compute shaders, which are essential for general-purpose computations on the GPU.\n\nThis interface extends [GPUObjectBase], [GPUPipelineBase], and implements [AutoCloseable](https://kotlinlang.org/api/latest/jvm/stdlib/kotlin.io/-auto-closeable/). It provides methods to manage the lifecycle of compute pipelines, ensuring that resources are properly released when they are no longer needed.\n\n**Important Notes:**\n- Ensure that the `pipelineDescriptor` is correctly configured with the necessary shader module and other parameters.\n- Properly manage the lifecycle of the pipeline by closing it when it is no longer needed to avoid memory leaks.\n\n**See Also:**\n- [GPUComputePassEncoder](https://www.w3.org/TR/webgpu/#gpucomputepassencoder)\n- [GPUPipelineBase]",
    "GPUCommandBuffer": "The `GPUCommandBuffer` interface represents a command buffer in the WebGPU API. It is used to encapsulate a list of GPU commands that can be executed on the [Queue timeline](https://www.w3.org/TR/webgpu/#queue-timeline).\n\nThis interface inherits from [`GPUObjectBase`](https://www.w3.org/TR/webgpu/#gpuobjectbase) and implements `AutoCloseable`, allowing for proper resource management.\n\n### Device Timeline Properties\n\n- **[[command_list]]**: A read-only list of [GPU commands](https://www.w3.org/TR/webgpu/#gpu-command) to be executed when this command buffer is submitted. This property is essential for managing the sequence of operations that will be performed on the GPU.\n\n- **[[renderState]]**: The current state used by any render pass commands being executed. Initially, this property is `null`, but it can be set to a valid [RenderState](https://www.w3.org/TR/webgpu/#renderstate) during the execution of render passes.\n\nIn this example, a `GPUCommandBuffer` is created using the `device.createCommandBuffer()` method. Commands are added to the command buffer within a render pass, and finally, the command buffer is submitted to the queue for execution.\n\n### Notes\n\n- The `GPUCommandBuffer` interface is designed to be used in conjunction with other WebGPU interfaces such as [`GPUDevice`](https://www.w3.org/TR/webgpu/#gpudevice) and [`GPUQueue`](https://www.w3.org/TR/webgpu/#gpuqueue).\n- Proper management of command buffers is crucial for efficient GPU resource utilization. Always ensure that command buffers are properly closed after use to avoid memory leaks.",
    "GPUCommandEncoder": "The `GPUCommandEncoder` interface represents a command encoder that allows the creation of command buffers for rendering and compute operations. It is part of the WebGPU API, which provides low-level access to GPU capabilities.\n\nThis interface includes methods for beginning render and compute passes, copying data between buffers and textures, clearing buffers, resolving query sets, and finishing command encoding.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#command-encoder).\n\n**Included Interfaces:**\n- `GPUObjectBase`: Provides base functionality for GPU objects.\n- `GPUCommandsMixin`: Mixin interface for common GPU commands.\n- `GPUDebugCommandsMixin`: Mixin interface for debug-related GPU commands.\n\n**See Also:**\n- [GPURenderPassEncoder](https://www.w3.org/TR/webgpu/#gpurenderpassencoder)\n- [GPUComputePassEncoder](https://www.w3.org/TR/webgpu/#gpucomputepassencoder)",
    "GPUCommandEncoder#beginRenderPass(descriptor)": "Begins a render pass using the specified descriptor. This method returns a `GPURenderPassEncoder` that can be used to record rendering commands.\n\n**Parameters:**\n- `descriptor`: A `GPURenderPassDescriptor` object that specifies the configuration for the render pass.\n\n**Returns:**\n- A `GPURenderPassEncoder` instance that can be used to record rendering commands within the render pass.\n\n**See Also:**\n- [GPURenderPassDescriptor](https://www.w3.org/TR/webgpu/#dictdef-gpurenderpassdescriptor)",
    "GPUCommandEncoder#beginComputePass(descriptor)": "Begins a compute pass using the specified descriptor. This method returns a `GPUComputePassEncoder` that can be used to record compute commands.\n\n**Parameters:**\n- `descriptor`: An optional `GPUComputePassDescriptor` object that specifies the configuration for the compute pass. If not provided, default values are used.\n\n**Returns:**\n- A `GPUComputePassEncoder` instance that can be used to record compute commands within the compute pass.\n\n**See Also:**\n- [GPUComputePassDescriptor](https://www.w3.org/TR/webgpu/#dictdef-gpucomputepassdescriptor)",
    "GPUCommandEncoder#copyBufferToBuffer(source, sourceOffset, destination, destinationOffset, size)": "Copies data from one buffer to another. This method allows for efficient data transfer between GPU buffers.\n\n**Parameters:**\n- `source`: The source `GPUBuffer` from which data will be copied.\n- `sourceOffset`: The offset within the source buffer where the copy operation will start.\n- `destination`: The destination `GPUBuffer` to which data will be copied.\n- `destinationOffset`: The offset within the destination buffer where the copy operation will start.\n- `size`: An optional parameter specifying the size of the data to be copied. If not provided, the entire range from `sourceOffset` to the end of the source buffer is copied.\n\n**See Also:**\n- [GPUBuffer](https://www.w3.org/TR/webgpu/#gpubuffer)",
    "GPUComputePassEncoder": "The `GPUComputePassEncoder` interface represents a compute pass encoder, which is used to encode commands for a compute pass. This interface allows you to set the pipeline, dispatch workgroups, and end the compute pass.\n\nA compute pass encoder is created by a [GPUCommandEncoder] and is used to record commands that will be executed on the GPU. The primary purpose of this interface is to manage the execution of compute shaders, which are used for general-purpose computations on the GPU.\n\n**Inherited from:**\n- [GPUObjectBase]\n- [GPUCommandsMixin]\n- [GPUDebugCommandsMixin]\n- [GPUBindingCommandsMixin]\n\n**Device Timeline Properties:**\n- `[[command_encoder]]`: The GPUCommandEncoder that created this compute pass encoder.\n- `[[endTimestampWrite]]`: A GPU command, if any, writing a timestamp when the pass ends. Defaults to null.\n- `[[pipeline]]`: The current [GPUComputePipeline]. Initially null.",
    "GPUComputePassEncoder#setPipeline(pipeline)": "Sets the compute pipeline for this compute pass encoder.\n\n**Parameters:**\n- `pipeline`: The [GPUComputePipeline] to set for this compute pass encoder.\n\n**Returns:** Nothing",
    "GPUComputePassEncoder#dispatchWorkgroups(workgroupCountX, workgroupCountY, workgroupCountZ)": "Dispatches the specified number of workgroups to be executed by the compute pipeline.\n\n**Parameters:**\n- `workgroupCountX`: The number of workgroups to dispatch in the X dimension. Must be greater than 0.\n- `workgroupCountY`: (Optional) The number of workgroups to dispatch in the Y dimension. Defaults to 1 if not specified.\n- `workgroupCountZ`: (Optional) The number of workgroups to dispatch in the Z dimension. Defaults to 1 if not specified.\n\n**Returns:** Nothing",
    "GPUComputePassEncoder#dispatchWorkgroupsIndirect(indirectBuffer, indirectOffset)": "Dispatches the specified number of workgroups to be executed by the compute pipeline using an indirect buffer.\n\n**Parameters:**\n- `indirectBuffer`: The [GPUBuffer] containing the indirect parameters.\n- `indirectOffset`: The offset in bytes within the indirect buffer where the indirect parameters start.\n\n**Returns:** Nothing",
    "GPUComputePassEncoder#end()": "Ends the compute pass encoder.\n\n**Returns:** Nothing\n\nThis method finalizes the commands recorded by the `GPUComputePassEncoder`. It must be called to complete the encoding of a compute pass. After calling this method, no further commands can be added to the encoder.",
    "GPURenderCommandsMixin": "The `GPURenderCommandsMixin` interface defines rendering commands that are common to both [GPURenderPassEncoder](https://www.w3.org/TR/webgpu/#gpurenderpassencoder) and [GPURenderBundleEncoder](https://www.w3.org/TR/webgpu/#gpurenderbundleencoder). This mixin is used to encapsulate the rendering commands that can be executed within a render pass or bundle.\n\nThe `GPURenderCommandsMixin` assumes the presence of members from [GPUObjectBase](https://www.w3.org/TR/webgpu/#gpuobjectbase), [GPUCommandsMixin](https://www.w3.org/TR/webgpu/#gpucommandsmixin), and [GPUBindingCommandsMixin](https://www.w3.org/TR/webgpu/#gpubindingcommandsmixin) on the same object. It must only be included by interfaces that also include those mixins.",
    "GPURenderCommandsMixin#setPipeline(pipeline)": "Sets the rendering pipeline to be used for subsequent drawing commands.\n\n**Parameters:**\n- `pipeline`: The [GPURenderPipeline](https://www.w3.org/TR/webgpu/#gpurenderpipeline) to set as the current pipeline.",
    "GPURenderCommandsMixin#setIndexBuffer(buffer, indexFormat, offset, size)": "Sets the index buffer to be used for indexed drawing commands.\n\n**Parameters:**\n- `buffer`: The [GPUBuffer](https://www.w3.org/TR/webgpu/#gpubuffer) containing the index data.\n- `indexFormat`: The format of the indices in the buffer, specified as a [GPUIndexFormat](https://www.w3.org/TR/webgpu/#enumdef-gpuindexformat).\n- `offset`: An optional offset within the buffer where the index data starts. Defaults to 0.\n- `size`: An optional size of the index data in bytes. If not specified, the entire buffer is used.",
    "GPURenderCommandsMixin#setVertexBuffer(slot, buffer, offset, size)": "Sets the vertex buffer at a specific slot to be used for subsequent drawing commands.\n\n**Parameters:**\n- `slot`: The index of the vertex buffer slot.\n- `buffer`: The [GPUBuffer](https://www.w3.org/TR/webgpu/#gpubuffer) containing the vertex data. Can be null to unset the buffer.\n- `offset`: An optional offset within the buffer where the vertex data starts. Defaults to 0.\n- `size`: An optional size of the vertex data in bytes. If not specified, the entire buffer is used.",
    "GPURenderCommandsMixin#draw(vertexCount, instanceCount, firstVertex, firstInstance)": "Issues a draw command to render vertices.\n\n**Parameters:**\n- `vertexCount`: The number of vertices to draw.\n- `instanceCount`: An optional number of instances to draw. Defaults to 1.\n- `firstVertex`: An optional offset into the vertex buffer. Defaults to 0.\n- `firstInstance`: An optional offset into the instance data. Defaults to 0.",
    "GPUQueue": "The `GPUQueue` interface represents a queue that allows for the submission of command buffers and other operations related to GPU execution. It is part of the WebGPU API, providing a way to manage and execute commands on the GPU.\n\nThis interface inherits from [GPUObjectBase](https://www.w3.org/TR/webgpu/#gpuobjectbase), which provides basic object management functionality.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#gpuqueue).",
    "GPUQueue#submit(commandBuffers)": "Submits a list of command buffers to the GPU queue for execution. This method allows you to enqueue commands that will be processed by the GPU in the order they are submitted.\n\n@param commandBuffers A list of [GPUCommandBuffer](https://www.w3.org/TR/webgpu/#gpucommandbuffer) objects to be executed.",
    "GPUQueue#onSubmittedWorkDone()": "Returns a promise that resolves when all previously submitted work is complete. This method can be used to synchronize GPU operations and ensure that certain tasks have finished executing before proceeding with other operations.\n\n@return A [Result](https://kotlinlang.org/api/latest/kotlinx-coroutines/core/kotlinx.coroutines/-result/) object that completes when the submitted work is done.",
    "GPUQueue#writeBuffer(buffer, bufferOffset, data, dataOffset, size)": "Writes data from a buffer source to a GPU buffer. This method allows you to transfer data from a host buffer (e.g., an ArrayBuffer) to a GPU buffer for use in GPU operations.\n\n@param buffer The [GPUBuffer](https://www.w3.org/TR/webgpu/#gpubuffer) object to which the data will be written.\n@param bufferOffset The offset within the GPU buffer where the data will be written.\n@param data The source data to be written to the GPU buffer. This can be an [ArrayBuffer](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/ArrayBuffer).\n@param dataOffset The offset within the source data from which to start reading. Defaults to 0.\n@param size The number of bytes to write. If null, the entire buffer is written.",
    "GPUQueue#writeTexture(destination, data, dataLayout, size)": "Writes texture data from a buffer source to a GPU texture. This method allows you to transfer texture data from a host buffer to a GPU texture for use in rendering operations.\n\n@param destination The [GPUTexelCopyTextureInfo](https://www.w3.org/TR/webgpu/#gputexelcopytextureinfo) object specifying the destination texture and its properties.\n@param data The source data to be written to the GPU texture. This can be an [ArrayBuffer](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/ArrayBuffer).\n@param dataLayout The [GPUTexelCopyBufferLayout](https://www.w3.org/TR/webgpu/#gputexelcopybufferlayout) object specifying the layout of the source data.\n@param size The extent of the texture data to be written.",
    "GPUQuerySet": "Represents a set of queries in the WebGPU API. A `GPUQuerySet` is used to manage and retrieve information about GPU operations such as occlusion queries, pipeline statistics queries, etc.\n\nThis interface inherits from [GPUObjectBase](https://www.w3.org/TR/webgpu/#gpuobjectbase) and implements [AutoCloseable](https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-auto-closeable/) to ensure proper resource management. The `destroy` method must be called to release the resources associated with this query set.\n\nFor more details, refer to the [WebGPU specification on GPUQuerySet](https://www.w3.org/TR/webgpu/#gpuqueryset).",
    "GPUQuerySet#type": "The type of the queries managed by this `GPUQuerySet`. This property is read-only and specifies the kind of queries that can be performed using this query set.\n\n**Type:** [GPUQueryType](https://www.w3.org/TR/webgpu/#enumdef-gpuquerytype)",
    "GPUQuerySet#count": "The number of queries managed by this `GPUQuerySet`. This property is read-only and indicates the total count of queries that can be performed using this query set.\n\n**Type:** [GPUSize32Out](https://www.w3.org/TR/webgpu/#typedefdef-gpusize32out)",
    "GPUError": "The `GPUError` interface represents the base class for all errors that can be surfaced from WebGPU operations. This includes errors returned by [popErrorScope()] and those triggered by the `uncapturederror` event.\n\n**Context:** Errors are generated under specific conditions defined in the respective algorithms of WebGPU operations. No errors are generated from a lost device. For more details, refer to the [Errors & Debugging section] of the WebGPU specification.\n\n**Note:** Future versions of this specification may introduce new subtypes of `GPUError`. Applications should handle this possibility by using the error's `message` property when possible and specializing using `instanceof`. Use `error.constructor.name` for serialization purposes, such as generating debug reports.",
    "GPUError#message": "A read-only string that provides a human-readable message describing the error.\n\n**Type:** [String]\n\n**Behavior:** This property contains a descriptive message that can be used to understand the nature of the error. It is particularly useful for debugging and logging purposes.",
    "GPUDeviceDescriptor": "The `GPUDeviceDescriptor` interface describes a device request. It specifies the features, limits, and default queue descriptor required by the GPU device.\n\nThis interface is used to configure the creation of a [GPUDevice] object, which represents a GPU adapter and provides methods for creating GPU resources such as buffers, textures, and pipelines.\n\nFor more details, refer to the [WebGPU specification on `GPUDeviceDescriptor`](https://www.w3.org/TR/webgpu/#gpudevicedescriptor).",
    "GPUDeviceDescriptor#requiredFeatures": "Specifies the features that are required by the device request. The request will fail if the adapter cannot provide these features.\n\nExactly the specified set of features, and no more or less, will be allowed in validation of API calls on the resulting device.\n\n**Type:** `List<GPUFeatureName>`\n\n**Default Value:** An empty list\n\nFor more details, refer to the [WebGPU specification on `requiredFeatures`](https://www.w3.org/TR/webgpu/#dom-gpudevicedescriptor-requiredfeatures).",
    "GPUDeviceDescriptor#requiredLimits": "Specifies the limits that are required by the device request. The request will fail if the adapter cannot provide these limits.\n\nEach key with a non-`undefined` value must be the name of a member of [supported limits](https://www.w3.org/TR/webgpu/#supported-limits).\n\nAPI calls on the resulting device perform validation according to the exact limits of the device (not the adapter; see [§ 3.6.2 Limits](https://www.w3.org/TR/webgpu/#limits)).\n\n**Type:** `GPUSupportedLimits?`\n\n**Default Value:** An empty map\n\nFor more details, refer to the [WebGPU specification on `requiredLimits`](https://www.w3.org/TR/webgpu/#dom-gpudevicedescriptor-requiredlimits).",
    "GPUDeviceDescriptor#defaultQueue": "The descriptor for the default [GPUQueue].\n\n**Type:** `GPUQueueDescriptor`\n\n**Default Value:** An empty `GPUQueueDescriptor`\n\nFor more details, refer to the [WebGPU specification on `defaultQueue`](https://www.w3.org/TR/webgpu/#dom-gpudevicedescriptor-defaultqueue).",
    "GPUBufferDescriptor": "Represents a descriptor for creating GPU buffers. This interface extends [GPUObjectDescriptorBase](https://www.w3.org/TR/webgpu/#gpuobjectdescriptorbase) and is used to specify the properties of a buffer, such as its size, usage flags, and whether it should be mapped at creation.\n\nFor more details, refer to the [WebGPU specification on GPUBufferDescriptor](https://www.w3.org/TR/webgpu/#gpubufferdescriptor).",
    "GPUBufferDescriptor#size": "The size of the buffer in bytes. This value must be a multiple of 4 and greater than or equal to 4.\n\n**Type:** [GPUSize64](https://www.w3.org/TR/webgpu/#typedefdef-gpusize64)",
    "GPUBufferDescriptor#usage": "Specifies the allowed usages for the buffer. This is a bitmask of [GPUBufferUsageFlags](https://www.w3.org/TR/webgpu/#typedefdef-gpubufferusageflags) that indicates how the buffer will be used.\n\n**Type:** [GPUBufferUsageFlags](https://www.w3.org/TR/webgpu/#typedefdef-gpubufferusageflags)",
    "GPUBufferDescriptor#mappedAtCreation": "Indicates whether the buffer should be created in an already mapped state. If `true`, the buffer can be immediately accessed using [getMappedRange()](https://www.w3.org/TR/webgpu/#dom-gpubuffer-getmappedrange). This is useful for setting the buffer's initial data.\n\n**Type:** Boolean\n\n**Default Value:** `false`",
    "GPUTextureDescriptor": "Represents a descriptor for creating GPU textures. This interface extends [GPUObjectDescriptorBase](https://www.w3.org/TR/webgpu/#gpuobjectdescriptorbase) and defines the properties required to specify the characteristics of a texture.\n\nFor more details, refer to the [WebGPU specification on GPUTextureDescriptor](https://www.w3.org/TR/webgpu/#gputexturedescriptor).",
    "GPUTextureDescriptor#size": "Specifies the size of the texture in 3D space. This is a required property.\n\n**Type:** [GPUExtent3D]",
    "GPUTextureDescriptor#mipLevelCount": "Specifies the number of mipmap levels in the texture. The default value is 1.\n\n**Type:** [GPUIntegerCoordinate]",
    "GPUTextureDescriptor#sampleCount": "Specifies the number of samples for multisampling. The default value is 1.\n\n**Type:** [GPUSize32]",
    "GPUTextureDescriptor#dimension": "Specifies the dimension of the texture. The default value is \"2d\".\n\n**Type:** [GPUTextureDimension]",
    "GPUTextureDescriptor#format": "Specifies the format of the texture data. This is a required property.\n\n**Type:** [GPUTextureFormat]",
    "GPUTexelCopyBufferLayout": "The `GPUTexelCopyBufferLayout` interface describes the layout of texels in a buffer of bytes during a texel copy operation. This interface is used to define how data is organized in a [GPUBuffer](https://www.w3.org/TR/webgpu/#gpubuffer) or an [AllowSharedBufferSource](https://webidl.spec.whatwg.org/#AllowSharedBufferSource) when performing texel copy operations.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#gputexelcopybufferlayout).",
    "GPUTexelCopyBufferLayout#offset": "The `offset` property specifies the starting offset in bytes from the beginning of the buffer where the texel data begins. This value is of type [GPUSize64], which represents a 64-bit unsigned integer.\n\n**Default Value:** `0`",
    "GPUTexelCopyBufferLayout#bytesPerRow": "The `bytesPerRow` property specifies the number of bytes per row in the texel data. This value is of type [GPUSize32], which represents a 32-bit unsigned integer.",
    "GPUTexelCopyBufferLayout#rowsPerImage": "The `rowsPerImage` property specifies the number of rows per image in the texel data. This value is of type [GPUSize32], which represents a 32-bit unsigned integer.",
    "GPUTexelCopyBufferInfo": "The `GPUTexelCopyBufferInfo` interface describes the information about a buffer source or destination of a texel copy operation. This includes details such as the buffer itself and its layout.\n\nTogether with the `copySize`, it defines the footprint of a region of texels in a [GPUBuffer](https://www.w3.org/TR/webgpu/#gpubuffer). This interface is essential for operations that involve copying texel data between buffers and textures.\n\nFor more details, refer to the [WebGPU specification on GPUTexelCopyBufferInfo](https://www.w3.org/TR/webgpu/#gputexelcopybufferinfo).",
    "GPUTexelCopyBufferInfo#buffer": "The `buffer` property represents a buffer that either contains texel data to be copied or will store the texel data being copied, depending on the method it is being passed to.\n\nThis property is of type [GPUBuffer](https://www.w3.org/TR/webgpu/#gpubuffer) and must be a valid GPU buffer. The validity of this buffer is checked during the validation process of `GPUTexelCopyBufferInfo`.",
    "GPUQueueDescriptor": "The `GPUQueueDescriptor` interface describes a queue request in the WebGPU API. This dictionary inherits from [GPUObjectDescriptorBase](https://www.w3.org/TR/webgpu/#dictdef-gpuobjectdescriptorbase), which means it includes all properties and methods defined by that base class.\n\nThe `GPUQueueDescriptor` is used to configure and create GPU queues, which are responsible for submitting commands to the GPU. This interface does not define any additional properties beyond those inherited from [GPUObjectDescriptorBase].\n\n**See Also:**\n- [GPUObjectDescriptorBase](https://www.w3.org/TR/webgpu/#dictdef-gpuobjectdescriptorbase) for inherited properties and methods.",
    "GPUSupportedLimits#maxDynamicStorageBuffersPerPipelineLayout": "The maximum number of dynamic storage buffers per pipeline layout. This value represents the largest allowable number of dynamic storage buffers for a single pipeline layout.\n\n**Type:** `UInt`",
    "GPUSupportedLimits#maxSampledTexturesPerShaderStage": "The maximum number of sampled textures per shader stage. This value represents the largest allowable number of sampled textures for a single shader stage.\n\n**Type:** `UInt`",
    "GPUSupportedLimits#maxSamplersPerShaderStage": "The maximum number of samplers per shader stage. This value represents the largest allowable number of samplers for a single shader stage.\n\n**Type:** `UInt`",
    "GPUSupportedLimits#maxStorageBuffersPerShaderStage": "The maximum number of storage buffers per shader stage. This value represents the largest allowable number of storage buffers for a single shader stage.\n\n**Type:** `UInt`",
    "GPUSupportedLimits#maxStorageTexturesPerShaderStage": "The maximum number of storage textures per shader stage. This value represents the largest allowable number of storage textures for a single shader stage.\n\n**Type:** `UInt`",
    "GPUSupportedLimits#maxUniformBuffersPerShaderStage": "The maximum number of uniform buffers per shader stage. This value represents the largest allowable number of uniform buffers for a single shader stage.\n\n**Type:** `UInt`",
    "GPUSupportedLimits#maxUniformBufferBindingSize": "The maximum size of a uniform buffer binding. This value represents the largest allowable size for a single uniform buffer binding in bytes.\n\n**Type:** `ULong`",
    "GPUSupportedLimits#maxStorageBufferBindingSize": "The maximum size of a storage buffer binding. This value represents the largest allowable size for a single storage buffer binding in bytes.\n\n**Type:** `ULong`",
    "GPUSupportedLimits#minUniformBufferOffsetAlignment": "The minimum alignment for uniform buffer offsets. This value represents the smallest allowable offset alignment for a uniform buffer in bytes.\n\n**Type:** `UInt`",
    "GPUSupportedLimits#minStorageBufferOffsetAlignment": "The minimum alignment for storage buffer offsets. This value represents the smallest allowable offset alignment for a storage buffer in bytes.\n\n**Type:** `UInt`",
    "GPUSupportedLimits#maxVertexBuffers": "The maximum number of vertex buffers that can be used in a single pipeline. This value represents the largest allowable number of vertex buffers for a pipeline.\n\n**Type:** `UInt`",
    "GPUSupportedLimits#maxBufferSize": "The maximum size of a buffer. This value represents the largest allowable size for a single buffer in bytes.\n\n**Type:** `ULong`",
    "GPUSupportedLimits#maxVertexAttributes": "The maximum number of vertex attributes that can be used in a single pipeline. This value represents the largest allowable number of vertex attributes for a pipeline.\n\n**Type:** `UInt`",
    "GPUSupportedLimits#maxVertexBufferArrayStride": "The maximum stride for a vertex buffer array. This value represents the largest allowable stride for a single vertex buffer array in bytes.\n\n**Type:** `UInt`",
    "GPUSupportedLimits#maxInterStageShaderVariables": "The maximum number of inter-stage shader variables that can be used in a single pipeline. This value represents the largest allowable number of inter-stage shader variables for a pipeline.\n\n**Type:** `UInt`",
    "GPUSupportedLimits#maxColorAttachments": "The maximum number of color attachments that can be used in a single render pass. This value represents the largest allowable number of color attachments for a render pass.\n\n**Type:** `UInt`",
    "GPUSupportedLimits#maxColorAttachmentBytesPerSample": "The maximum number of bytes per sample for a color attachment. This value represents the largest allowable number of bytes per sample for a single color attachment.\n\n**Type:** `UInt`",
    "GPUSupportedLimits#maxComputeWorkgroupStorageSize": "The maximum size of storage for a compute workgroup. This value represents the largest allowable size for a single compute workgroup's storage in bytes.\n\n**Type:** `UInt`",
    "GPUSupportedLimits#maxComputeInvocationsPerWorkgroup": "The maximum number of compute invocations per workgroup. This value represents the largest allowable number of compute invocations for a single workgroup.\n\n**Type:** `UInt`",
    "GPUSupportedLimits#maxComputeWorkgroupSizeX": "The maximum size for the X dimension of a compute workgroup. This value represents the largest allowable size for the X dimension of a single compute workgroup.\n\n**Type:** `UInt`",
    "GPUSupportedLimits#maxComputeWorkgroupSizeY": "The maximum size for the Y dimension of a compute workgroup. This value represents the largest allowable size for the Y dimension of a single compute workgroup.\n\n**Type:** `UInt`",
    "GPUSupportedLimits#maxComputeWorkgroupSizeZ": "The maximum size for the Z dimension of a compute workgroup. This value represents the largest allowable size for the Z dimension of a single compute workgroup.\n\n**Type:** `UInt`",
    "GPUSupportedLimits#maxComputeWorkgroupsPerDimension": "The maximum number of compute workgroups per dimension. This value represents the largest allowable number of compute workgroups for a single dimension.\n\n**Type:** `UInt`",
    "GPUDevice#createBindGroupLayout(descriptor)": "Creates a new bind group layout object based on the provided descriptor.\n\n**Parameters:**\n- `descriptor`: A [GPUBindGroupLayoutDescriptor] that specifies the properties of the bind group layout to be created.\n\n**Returns:** A new [GPUBindGroupLayout] object.\n\n**See also:**\n- [WebGPU Specification: createBindGroupLayout](https://www.w3.org/TR/webgpu/#dom-gpudevice-createbindgrouplayout)",
    "GPUDevice#createPipelineLayout(descriptor)": "Creates a new pipeline layout object based on the provided descriptor.\n\n**Parameters:**\n- `descriptor`: A [GPUPipelineLayoutDescriptor] that specifies the properties of the pipeline layout to be created.\n\n**Returns:** A new [GPUPipelineLayout] object.\n\n**See also:**\n- [WebGPU Specification: createPipelineLayout](https://www.w3.org/TR/webgpu/#dom-gpudevice-createpipelinelayout)",
    "GPUDevice#createBindGroup(descriptor)": "Creates a new bind group object based on the provided descriptor.\n\n**Parameters:**\n- `descriptor`: A [GPUBindGroupDescriptor] that specifies the properties of the bind group to be created.\n\n**Returns:** A new [GPUBindGroup] object.\n\n**See also:**\n- [WebGPU Specification: createBindGroup](https://www.w3.org/TR/webgpu/#dom-gpudevice-createbindgroup)",
    "GPUDevice#createShaderModule(descriptor)": "Creates a new shader module object based on the provided descriptor.\n\n**Parameters:**\n- `descriptor`: A [GPUShaderModuleDescriptor] that specifies the properties of the shader module to be created.\n\n**Returns:** A new [GPUShaderModule] object.\n\n**See also:**\n- [WebGPU Specification: createShaderModule](https://www.w3.org/TR/webgpu/#dom-gpudevice-createshadermodule)",
    "GPUDevice#createComputePipeline(descriptor)": "Creates a new compute pipeline object based on the provided descriptor.\n\n**Parameters:**\n- `descriptor`: A [GPUComputePipelineDescriptor] that specifies the properties of the compute pipeline to be created.\n\n**Returns:** A new [GPUComputePipeline] object.\n\n**See also:**\n- [WebGPU Specification: createComputePipeline](https://www.w3.org/TR/webgpu/#dom-gpudevice-createcomputepipeline)",
    "GPUDevice#createRenderPipeline(descriptor)": "Creates a new render pipeline object based on the provided descriptor.\n\n**Parameters:**\n- `descriptor`: A [GPURenderPipelineDescriptor] that specifies the properties of the render pipeline to be created.\n\n**Returns:** A new [GPURenderPipeline] object.\n\n**See also:**\n- [WebGPU Specification: createRenderPipeline](https://www.w3.org/TR/webgpu/#dom-gpudevice-createrenderpipeline)",
    "GPUDevice#createComputePipelineAsync(descriptor)": "Asynchronously creates a new compute pipeline object based on the provided descriptor.\n\n**Parameters:**\n- `descriptor`: A [GPUComputePipelineDescriptor] that specifies the properties of the compute pipeline to be created.\n\n**Returns:** A [Result] containing the newly created [GPUComputePipeline] object or an error if the creation fails.\n\n**See also:**\n- [WebGPU Specification: createComputePipelineAsync](https://www.w3.org/TR/webgpu/#dom-gpudevice-createcomputepipelineasync)",
    "GPUDevice#createRenderPipelineAsync(descriptor)": "Asynchronously creates a new render pipeline object based on the provided descriptor.\n\n**Parameters:**\n- `descriptor`: A [GPURenderPipelineDescriptor] that specifies the properties of the render pipeline to be created.\n\n**Returns:** A [Result] containing the newly created [GPURenderPipeline] object or an error if the creation fails.\n\n**See also:**\n- [WebGPU Specification: createRenderPipelineAsync](https://www.w3.org/TR/webgpu/#dom-gpudevice-createrenderpipelineasync)",
    "GPUDevice#createCommandEncoder(descriptor)": "Creates a new command encoder object based on the provided descriptor.\n\n**Parameters:**\n- `descriptor`: An optional [GPUCommandEncoderDescriptor] that specifies the properties of the command encoder to be created. If not provided, default values are used.\n\n**Returns:** A new [GPUCommandEncoder] object.\n\n**See also:**\n- [WebGPU Specification: createCommandEncoder](https://www.w3.org/TR/webgpu/#dom-gpudevice-createcommandencoder)",
    "GPUDevice#createRenderBundleEncoder(descriptor)": "Creates a new render bundle encoder object based on the provided descriptor.\n\n**Parameters:**\n- `descriptor`: A [GPURenderBundleEncoderDescriptor] that specifies the properties of the render bundle encoder to be created.\n\n**Returns:** A new [GPURenderBundleEncoder] object.\n\n**See also:**\n- [WebGPU Specification: createRenderBundleEncoder](https://www.w3.org/TR/webgpu/#dom-gpudevice-createrenderbundleencoder)",
    "GPUDevice#createQuerySet(descriptor)": "Creates a new query set object based on the provided descriptor.\n\n**Parameters:**\n- `descriptor`: A [GPUQuerySetDescriptor] that specifies the properties of the query set to be created.\n\n**Returns:** A new [GPUQuerySet] object.\n\n**See also:**\n- [WebGPU Specification: createQuerySet](https://www.w3.org/TR/webgpu/#dom-gpudevice-createqueryset)",
    "GPUDevice#pushErrorScope(filter)": "Pushes an error scope onto the device's error stack with the specified filter.\n\n**Parameters:**\n- `filter`: A [GPUErrorFilter] that specifies which errors should be captured within this scope.\n\n**See also:**\n- [WebGPU Specification: pushErrorScope](https://www.w3.org/TR/webgpu/#dom-gpudevice-pusherrorscope)",
    "GPUDevice#popErrorScope()": "Pops the top error scope from the device's error stack and returns any captured errors.\n\n**Returns:** A [Result] containing a [GPUError] object if an error was captured, or `null` if no error occurred.\n\n**See also:**\n- [WebGPU Specification: popErrorScope](https://www.w3.org/TR/webgpu/#dom-gpudevice-poperrorscope)",
    "GPUTexture": "Represents a texture in the WebGPU API. A texture is composed of 1D, 2D, or 3D arrays of data that can contain multiple values per element to represent things like colors.\nTextures can be read and written in various ways depending on their usage flags. They are often stored in GPU memory with a layout optimized for multidimensional access.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#texture-interface).",
    "GPUTexture#width": "Represents the width of the texture in texels.\n\n**Type:** [GPUIntegerCoordinateOut](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinateout)",
    "GPUTexture#height": "Represents the height of the texture in texels.\n\n**Type:** [GPUIntegerCoordinateOut](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinateout)",
    "GPUTexture#depthOrArrayLayers": "Represents the depth of the texture in texels for 3D textures or the number of array layers for 2D array textures.\n\n**Type:** [GPUIntegerCoordinateOut](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinateout)",
    "GPUTexture#mipLevelCount": "Represents the number of mipmap levels in the texture.\n\n**Type:** [GPUIntegerCoordinateOut](https://www.w3.org/TR/webgpu/#typedefdef-gpuintegercoordinateout)",
    "GPUTexture#sampleCount": "Represents the number of samples per pixel in the texture.\n\n**Type:** [GPUSize32Out](https://www.w3.org/TR/webgpu/#typedefdef-gpusize32out)",
    "GPUTexture#dimension": "Specifies the dimension of the texture (1D, 2D, or 3D).\n\n**Type:** [GPUTextureDimension](https://www.w3.org/TR/webgpu/#enumdef-gputexturedimension)",
    "GPUTexture#format": "Specifies the format of the texture data.\n\n**Type:** [GPUTextureFormat](https://www.w3.org/TR/webgpu/#enumdef-gputextureformat)",
    "GPUTexture#usage": "Specifies the usage flags for the texture, indicating how it can be used (e.g., as a render target, sampler, etc.).\n\n**Type:** [GPUTextureUsageFlags](https://www.w3.org/TR/webgpu/#namespacedef-gputextureusage)",
    "GPUTexture#createView(descriptor)": "Creates a view of the texture.\n\n**Parameters:**\n- `descriptor`: An optional [GPUTextureViewDescriptor](https://www.w3.org/TR/webgpu/#dictdef-gputextureviewdescriptor) that specifies the parameters for creating the texture view. If not provided, default values are used.\n\n**Return Type:** [GPUTextureView](https://www.w3.org/TR/webgpu/#gputextureview)",
    "GPUCommandEncoder#copyBufferToTexture(source, destination, copySize)": "Copies data from a buffer to a texture. This method allows for efficient transfer of data from a GPU buffer to a GPU texture.\n\n**Parameters:**\n- `source`: A `GPUTexelCopyBufferInfo` object that specifies the source buffer and its layout.\n- `destination`: A `GPUTexelCopyTextureInfo` object that specifies the destination texture and its layout.\n- `copySize`: A `GPUExtent3D` object that specifies the size of the data to be copied.\n\n**See Also:**\n- [GPUTexelCopyBufferInfo](https://www.w3.org/TR/webgpu/#gputexelcopybufferinfo)\n- [GPUTexelCopyTextureInfo](https://www.w3.org/TR/webgpu/#gputexelcopytextureinfo)",
    "GPUCommandEncoder#copyTextureToBuffer(source, destination, copySize)": "Copies data from a texture to a buffer. This method allows for efficient transfer of data from a GPU texture to a GPU buffer.\n\n**Parameters:**\n- `source`: A `GPUTexelCopyTextureInfo` object that specifies the source texture and its layout.\n- `destination`: A `GPUTexelCopyBufferInfo` object that specifies the destination buffer and its layout.\n- `copySize`: A `GPUExtent3D` object that specifies the size of the data to be copied.\n\n**See Also:**\n- [GPUTexelCopyTextureInfo](https://www.w3.org/TR/webgpu/#gputexelcopytextureinfo)\n- [GPUTexelCopyBufferInfo](https://www.w3.org/TR/webgpu/#gputexelcopybufferinfo)",
    "GPUCommandEncoder#copyTextureToTexture(source, destination, copySize)": "Copies data from one texture to another. This method allows for efficient transfer of data between GPU textures.\n\n**Parameters:**\n- `source`: A `GPUTexelCopyTextureInfo` object that specifies the source texture and its layout.\n- `destination`: A `GPUTexelCopyTextureInfo` object that specifies the destination texture and its layout.\n- `copySize`: A `GPUExtent3D` object that specifies the size of the data to be copied.\n\n**See Also:**\n- [GPUTexelCopyTextureInfo](https://www.w3.org/TR/webgpu/#gputexelcopytextureinfo)",
    "GPUCommandEncoder#clearBuffer(buffer, offset, size)": "Clears the contents of a buffer. This method sets the specified range of the buffer to zero.\n\n**Parameters:**\n- `buffer`: The `GPUBuffer` to be cleared.\n- `offset`: An optional parameter specifying the starting offset within the buffer where the clear operation will begin. Defaults to 0 if not provided.\n- `size`: An optional parameter specifying the size of the range to be cleared. If not provided, the entire range from `offset` to the end of the buffer is cleared.\n\n**See Also:**\n- [GPUBuffer](https://www.w3.org/TR/webgpu/#gpubuffer)",
    "GPUCommandEncoder#resolveQuerySet(querySet, firstQuery, queryCount, destination, destinationOffset)": "Resolves a set of queries and writes the results to a buffer. This method is used for performance monitoring and debugging.\n\n**Parameters:**\n- `querySet`: The `GPUQuerySet` containing the queries to be resolved.\n- `firstQuery`: The index of the first query in the query set to resolve.\n- `queryCount`: The number of queries to resolve starting from `firstQuery`.\n- `destination`: The `GPUBuffer` where the results of the resolved queries will be written.\n- `destinationOffset`: The offset within the destination buffer where the results will be written.\n\n**See Also:**\n- [GPUQuerySet](https://www.w3.org/TR/webgpu/#gpuqueryset)",
    "GPUCommandEncoder#finish(descriptor)": "Finishes the command encoding process and returns a `GPUCommandBuffer` that can be submitted to the GPU for execution.\n\n**Parameters:**\n- `descriptor`: An optional `GPUCommandBufferDescriptor` object that specifies configuration options for the command buffer. If not provided, default values are used.\n\n**Returns:**\n- A `GPUCommandBuffer` instance that contains all the recorded commands and can be submitted to the GPU.\n\n**See Also:**\n- [GPUCommandBuffer](https://www.w3.org/TR/webgpu/#gpucommandbuffer)",
    "GPURenderPassEncoder": "The `GPURenderPassEncoder` interface represents a render pass encoder, which is used to encode commands into a render pass. This interface allows for the configuration of various rendering states and the execution of draw calls within a render pass.\n\nA render pass encoder is created by a [GPUCommandEncoder] and is used to record commands that will be executed on the GPU. The `GPURenderPassEncoder` interface includes methods for setting viewport, scissor rectangle, blend constant, stencil reference, beginning and ending occlusion queries, executing render bundles, and ending the render pass.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#gpurenderpassencoder).",
    "GPURenderPassEncoder#setViewport(x, y, width, height, minDepth, maxDepth)": "Sets the viewport for the render pass. The viewport defines a clipping rectangle in normalized device coordinates (NDC) that specifies the region of the render target to which rendering commands are directed.\n\n**Parameters:**\n- `x`: The x-coordinate of the viewport's origin.\n- `y`: The y-coordinate of the viewport's origin.\n- `width`: The width of the viewport.\n- `height`: The height of the viewport.\n- `minDepth`: The minimum depth value for the viewport.\n- `maxDepth`: The maximum depth value for the viewport.",
    "GPURenderPassEncoder#setScissorRect(x, y, width, height)": "Sets the scissor rectangle for the render pass. The scissor rectangle defines a clipping region in pixel coordinates that restricts rendering to a specific area of the render target.\n\n**Parameters:**\n- `x`: The x-coordinate of the scissor rectangle's origin.\n- `y`: The y-coordinate of the scissor rectangle's origin.\n- `width`: The width of the scissor rectangle.\n- `height`: The height of the scissor rectangle.",
    "GPURenderPassEncoder#setBlendConstant(color)": "Sets the blend constant color for the render pass. The blend constant color is used in blending operations to provide a constant color value that can be blended with the source and destination colors.\n\n**Parameters:**\n- `color`: The blend constant color, represented as a [GPUColor](https://www.w3.org/TR/webgpu/#typedefdef-gpucolor).",
    "GPURenderPassEncoder#setStencilReference(reference)": "Sets the stencil reference value for the render pass. The stencil reference value is used in stencil testing to compare against the stencil buffer values.\n\n**Parameters:**\n- `reference`: The stencil reference value, represented as a [GPUStencilValue](https://www.w3.org/TR/webgpu/#typedefdef-gpustencilvalue).",
    "GPURenderPassEncoder#beginOcclusionQuery(queryIndex)": "Begins an occlusion query at the specified index. Occlusion queries are used to determine whether a specific region of the render target is visible or occluded by other geometry.\n\n**Parameters:**\n- `queryIndex`: The index of the occlusion query, represented as a [GPUSize32](https://www.w3.org/TR/webgpu/#typedefdef-gpusize32).",
    "GPURenderPassEncoder#endOcclusionQuery()": "Ends the current occlusion query. This method should be called after the commands that are to be tested for occlusion have been recorded.",
    "GPURenderPassEncoder#executeBundles(bundles)": "Executes a list of render bundles within the render pass. Render bundles are pre-recorded sequences of commands that can be executed multiple times with different parameters.\n\n**Parameters:**\n- `bundles`: A list of [GPURenderBundle](https://www.w3.org/TR/webgpu/#gpurenderbundle) objects to execute.",
    "GPURenderPassEncoder#end()": "Ends the render pass. This method should be called after all rendering commands have been recorded to finalize the render pass.",
    "GPURenderCommandsMixin#drawIndexed(indexCount, instanceCount, firstIndex, baseVertex, firstInstance)": "Issues an indexed draw command to render vertices using indices.\n\n**Parameters:**\n- `indexCount`: The number of indices to draw.\n- `instanceCount`: An optional number of instances to draw. Defaults to 1.\n- `firstIndex`: An optional offset into the index buffer. Defaults to 0.\n- `baseVertex`: An optional base vertex offset. Defaults to 0.\n- `firstInstance`: An optional offset into the instance data. Defaults to 0.",
    "GPURenderCommandsMixin#drawIndirect(indirectBuffer, indirectOffset)": "Issues an indirect draw command to render vertices using data from a buffer.\n\n**Parameters:**\n- `indirectBuffer`: The [GPUBuffer](https://www.w3.org/TR/webgpu/#gpubuffer) containing the indirect draw parameters.\n- `indirectOffset`: The offset within the buffer where the indirect draw parameters start.",
    "GPURenderCommandsMixin#drawIndexedIndirect(indirectBuffer, indirectOffset)": "Issues an indirect indexed draw command to render vertices using data from a buffer.\n\n**Parameters:**\n- `indirectBuffer`: The [GPUBuffer](https://www.w3.org/TR/webgpu/#gpubuffer) containing the indirect indexed draw parameters.\n- `indirectOffset`: The offset within the buffer where the indirect indexed draw parameters start.",
    "GPUTextureDescriptor#usage": "Specifies the usage flags for the texture. This is a required property.\n\n**Type:** [GPUTextureUsageFlags]",
    "GPUTextureDescriptor#viewFormats": "Specifies a list of formats that can be used to create views of the texture. The default value is an empty list.\n\n**Type:** List<[GPUTextureFormat]>",
    "GPUBindGroupLayoutEntry#storageTexture": "When provided, indicates that the binding resource type for this `GPUBindGroupLayoutEntry` is [GPUTextureView](https://www.w3.org/TR/webgpu/#gputextureview).\n\n**Type:** [GPUStorageTextureBindingLayout?](https://www.w3.org/TR/webgpu/#dictdef-gpustoragetexturebindinglayout)",
    "GPUShaderModuleDescriptor": "Represents a descriptor for creating a [GPUShaderModule] in WebGPU. This interface extends `GPUObjectDescriptorBase` and is used to specify the WGSL source code and compilation hints required to create a shader module. The shader module is a compiled version of the shader code that can be used in rendering or compute pipelines.\n\n**See also:**\n- [W3C WebGPU Specification: GPUShaderModuleDescriptor](https://www.w3.org/TR/webgpu/#dictdef-gpushadermoduledescriptor)",
    "GPUShaderModuleDescriptor#code": "The WGSL source code for the shader module. This string contains the shader program written in the WebGPU Shading Language (WGSL). The shader code defines the vertex and fragment shaders or compute shaders that will be used in the rendering or compute pipeline.\n\n**Type:** `String`\n\n**See also:**\n- [W3C WebGPU Specification: GPUShaderModuleDescriptor.code](https://www.w3.org/TR/webgpu/#dom-gpushadermoduledescriptor-code)",
    "GPUShaderModuleDescriptor#compilationHints": "A list of `GPUShaderModuleCompilationHint` objects that provide additional information to the compiler about the shader module. These hints can include details about entry points, resource bindings, and other compilation-specific information. Providing these hints can improve performance by allowing the compiler to perform more optimizations during the creation of the shader module.\n\n**Type:** `List<GPUShaderModuleCompilationHint>`\n\n**Default Value:** An empty list (`[]`)\n\n**See also:**\n- [W3C WebGPU Specification: GPUShaderModuleDescriptor.compilationHints](https://www.w3.org/TR/webgpu/#dom-gpushadermoduledescriptor-compilationhints)",
    "GPUProgrammableStage": "Represents a programmable stage in a GPU pipeline. This interface describes the entry point in a user-provided [GPUShaderModule] that controls one of the programmable stages of a pipeline.\nEntry point names follow the rules defined in [WGSL identifier comparison](https://gpuweb.github.io/gpuweb/wgsl/#identifier-comparison).",
    "GPUProgrammableStage#module": "The shader module containing the entry point for this programmable stage. This is a required field and must be provided when creating an instance of [GPUProgrammableStage].",
    "GPUProgrammableStage#entryPoint": "The name of the entry point in the shader module. This is an optional field and can be null if not specified.\nEntry point names must follow the rules defined in [WGSL identifier comparison](https://gpuweb.github.io/gpuweb/wgsl/#identifier-comparison).",
    "GPUProgrammableStage#constants": "A map of constant values that can be passed to the shader module. The keys are strings representing the names of the constants, and the values are of type [GPUPipelineConstantValue].\nThis field is optional and defaults to an empty map if not provided.",
    "GPUPrimitiveState": "Represents the state of a primitive in WebGPU, defining how primitives are rendered. This interface is used to configure various aspects of primitive rendering such as topology, strip index format, front face orientation, cull mode, and depth clipping behavior.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpuprimitivestate).",
    "GPUPrimitiveState#topology": "Specifies the type of primitive topology used for rendering. This determines how vertices are interpreted when drawing primitives.\n\n**Default Value:** `GPUPrimitiveTopology.TriangleList`\n\n**See Also:**\n- [GPUPrimitiveTopology](https://www.w3.org/TR/webgpu/#enumdef-gpuprimitivetopology)",
    "GPUPrimitiveState#stripIndexFormat": "Specifies the format of the strip index buffer, if used. This is relevant when rendering primitives that use strip indexing.\n\n**Default Value:** `null`\n\n**See Also:**\n- [GPUIndexFormat](https://www.w3.org/TR/webgpu/#enumdef-gpuindexformat)",
    "GPUPrimitiveState#frontFace": "Specifies the orientation of the front face of primitives. This determines which side of a triangle is considered the front face for culling and other operations.\n\n**Default Value:** `GPUFrontFace.CCW`\n\n**See Also:**\n- [GPUFrontFace](https://www.w3.org/TR/webgpu/#enumdef-gpufrontface)",
    "GPUPrimitiveState#cullMode": "Specifies the culling mode for primitives. This determines which faces of a primitive are discarded during rendering.\n\n**Default Value:** `GPUCullMode.None`\n\n**See Also:**\n- [GPUCullMode](https://www.w3.org/TR/webgpu/#enumdef-gpucullmode)",
    "GPUPrimitiveState#unclippedDepth": "Specifies whether depth values are clipped or unclipped. This feature requires the `\"depth-clip-control\"` feature to be enabled.\n\n**Default Value:** `false`\n\n**See Also:**\n- [WebGPU Features](https://www.w3.org/TR/webgpu/#features)",
    "GPUDepthStencilState": "Represents the depth and stencil state configuration for a GPU render pipeline. This interface defines various properties that control how depth and stencil tests are performed during rendering.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#depth-stencil-state).",
    "GPUDepthStencilState#format": "Specifies the format of the depth/stencil texture. This property determines how depth and stencil values are stored in the texture.\n\n**Type:** [GPUTextureFormat](https://www.w3.org/TR/webgpu/#enumdef-gputextureformat)",
    "GPUDepthStencilState#depthWriteEnabled": "Indicates whether depth values are written to the depth buffer. When set to `true`, depth values are written; when set to `false` or `null`, depth values are not written.\n\n**Type:** Boolean?",
    "GPUDepthStencilState#depthCompare": "Specifies the comparison function used for depth tests. This property determines how the current depth value is compared to the stored depth value.\n\n**Type:** [GPUCompareFunction](https://www.w3.org/TR/webgpu/#enumdef-gpucomparefunction)",
    "GPUDepthStencilState#stencilFront": "Defines the stencil state for front-facing primitives. This property configures how stencil tests are performed for front-facing geometry.\n\n**Type:** [GPUStencilFaceState](https://www.w3.org/TR/webgpu/#dictdef-gpustencilfacestate)",
    "GPUDepthStencilState#stencilBack": "Defines the stencil state for back-facing primitives. This property configures how stencil tests are performed for back-facing geometry.\n\n**Type:** [GPUStencilFaceState](https://www.w3.org/TR/webgpu/#dictdef-gpustencilfacestate)",
    "GPUDepthStencilState#stencilReadMask": "Specifies the mask used for reading stencil values. This property determines which bits of the stencil value are considered during read operations.\n\n**Type:** [GPUStencilValue](https://www.w3.org/TR/webgpu/#typedefdef-gpustencilvalue)\n\n**Default Value:** `0xFFFFFFFF`",
    "GPUDepthStencilState#stencilWriteMask": "Specifies the mask used for writing stencil values. This property determines which bits of the stencil value are modified during write operations.\n\n**Type:** [GPUStencilValue](https://www.w3.org/TR/webgpu/#typedefdef-gpustencilvalue)\n\n**Default Value:** `0xFFFFFFFF`",
    "GPUDepthStencilState#depthBias": "Specifies the depth bias value. This property is used to adjust the depth values for polygon offset.\n\n**Type:** [GPUDepthBias](https://www.w3.org/TR/webgpu/#typedefdef-gpudepthbias)\n\n**Default Value:** `0`",
    "GPUDepthStencilState#depthBiasSlopeScale": "Specifies the slope scale factor for depth bias. This property is used to adjust the depth bias based on the slope of the polygon.\n\n**Type:** Float\n\n**Default Value:** `0.0`",
    "GPUDepthStencilState#depthBiasClamp": "Specifies the clamp value for depth bias. This property limits the maximum depth bias that can be applied.\n\n**Type:** Float\n\n**Default Value:** `0.0`",
    "GPURenderPassDepthStencilAttachment": "The `GPURenderPassDepthStencilAttachment` interface represents a depth/stencil attachment for a render pass. It specifies the texture view and various operations to be performed on the depth and stencil components of that view during the render pass.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#gpurenderpassdepthstencilattachment).",
    "GPURenderPassDepthStencilAttachment#view": "A `GPUTextureView` describing the texture subresource that will be output to and read from for this depth/stencil attachment.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpassdepthstencilattachment-view).",
    "GPURenderPassDepthStencilAttachment#depthClearValue": "Indicates the value to clear the `view`'s depth component to prior to executing the render pass. This value is ignored if `depthLoadOp` is not set to `GPULoadOp.CLEAR`. The value must be between 0.0 and 1.0, inclusive.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpassdepthstencilattachment-depthclearvalue).",
    "GPURenderPassDepthStencilAttachment#depthLoadOp": "Indicates the load operation to perform on the `view`'s depth component prior to executing the render pass. It is recommended to prefer clearing; see `GPULoadOp.CLEAR` for details.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpassdepthstencilattachment-depthloadop).",
    "GPURenderPassDepthStencilAttachment#depthStoreOp": "The store operation to perform on the `view`'s depth component after executing the render pass.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpassdepthstencilattachment-depthstoreop).",
    "GPURenderPassDepthStencilAttachment#depthReadOnly": "Indicates that the depth component of the `view` is read-only. Defaults to `false`.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpassdepthstencilattachment-depthreadonly).",
    "GPURenderPassDepthStencilAttachment#stencilClearValue": "Indicates the value to clear the `view`'s stencil component to prior to executing the render pass. This value is ignored if `stencilLoadOp` is not set to `GPULoadOp.CLEAR`. The value will be converted to the type of the stencil aspect of the `view` by taking the same number of least significant bits (LSBs) as the number of bits in the stencil aspect of one texel of the `view`.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpassdepthstencilattachment-stencilclearvalue).",
    "GPURenderPassDepthStencilAttachment#stencilLoadOp": "Indicates the load operation to perform on the `view`'s stencil component prior to executing the render pass. It is recommended to prefer clearing; see `GPULoadOp.CLEAR` for details.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpassdepthstencilattachment-stencilloadop).",
    "GPURenderPassDepthStencilAttachment#stencilStoreOp": "The store operation to perform on the `view`'s stencil component after executing the render pass.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpassdepthstencilattachment-stencilstoreop).",
    "GPURenderPassDepthStencilAttachment#stencilReadOnly": "Indicates that the stencil component of the `view` is read-only. Defaults to `false`.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurenderpassdepthstencilattachment-stencilreadonly).",
    "GPUCommandsMixin": "The `GPUCommandsMixin` interface defines state common to all interfaces which encode commands. This mixin does not include any methods but serves as a base for other command-encoding interfaces in the WebGPU API.\n\n**Context and Purpose:**\nThis interface is part of the WebGPU specification and is used to provide a consistent way to manage command encoding across different GPU-related interfaces. It ensures that all command-encoding interfaces share a common set of properties or behaviors, even if it does not define any methods itself.\n\n**References:**\n- [WebGPU Specification: GPUCommandsMixin](https://www.w3.org/TR/webgpu/#gpucommandsmixin)",
    "GPURenderBundle": "/**\n * Represents a render bundle in the WebGPU API. A `GPURenderBundle` encapsulates a list of GPU commands that can be executed by a [GPURenderPassEncoder](https://www.w3.org/TR/webgpu/#dom-gpurenderpassencoder).\n * \n * This interface is part of the WebGPU API, which provides a low-level, cross-platform graphics API for the web. For more details, refer to the [official W3C specification](https://www.w3.org/TR/webgpu/#gpurenderbundle).\n * \n * @see [GPUObjectBase](https://www.w3.org/TR/webgpu/#dom-gpuobjectbase)\n */\ninterface GPURenderBundle : GPUObjectBase",
    "GPURequestAdapterOptions": "The `GPURequestAdapterOptions` interface provides hints to the user agent indicating what configuration is suitable for the application. This interface allows developers to specify preferences and constraints for the GPU adapter selection process.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpurequestadapteroptions).",
    "GPURequestAdapterOptions#featureLevel": "The `featureLevel` property specifies the feature level for the adapter request. This string value influences which features of the GPU are enabled or restricted.\n\n**Allowed Values:**\n- \"core\": No effect.\n- \"compatibility\": Reserved for future use to opt into additional validation restrictions. Applications should not use this value at this time.\n\n**Default Value:** \"core\"\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurequestadapteroptions-featurelevel).",
    "GPURequestAdapterOptions#powerPreference": "The `powerPreference` property provides a hint indicating what class of adapter should be selected from the system’s available adapters. This value can influence which GPU is used in a multi-GPU system, affecting power consumption and performance.\n\n**Allowed Values:**\n- null: Provides no hint to the user agent.\n- \"low-power\": Indicates a request to prioritize power savings over performance.\n- \"high-performance\": Indicates a request to prioritize performance over power consumption.\n\n**Default Value:** null\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurequestadapteroptions-powerpreference).",
    "GPURequestAdapterOptions#forceFallbackAdapter": "The `forceFallbackAdapter` property indicates whether only a fallback adapter may be returned. If set to `true`, the user agent will return a fallback adapter if available, or `null` if not supported.\n\n**Default Value:** false\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurequestadapteroptions-forcefallbackadapter).",
    "GPURequestAdapterOptions#xrCompatible": "The `xrCompatible` property indicates whether the best adapter for rendering to a WebXR session must be returned. If set to `true`, the user agent will prioritize adapters suitable for WebXR rendering.\n\n**Default Value:** false\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpurequestadapteroptions-xrcompatible).",
    "GPUSamplerDescriptor": "The `GPUSamplerDescriptor` interface defines the properties of a sampler used in WebGPU. This descriptor specifies how textures are sampled during rendering, including addressing modes, filtering modes, and level-of-detail (LOD) clamping. It is part of the GPUObjectDescriptorBase hierarchy and is used to create `GPUSampler` objects.\n\nFor more details, refer to the [WebGPU specification on GPUSamplerDescriptor](https://www.w3.org/TR/webgpu/#dictdef-gpusamplerdescriptor).",
    "GPUSamplerDescriptor#addressModeU": "Specifies the addressing mode for the U coordinate of the texture. This determines how texture coordinates are handled when they extend beyond the bounds of the texture. The default value is `GPUAddressMode.CLAMP_TO_EDGE`.\n\nFor more details, refer to the [WebGPU specification on GPUAddressMode](https://www.w3.org/TR/webgpu/#enumdef-gpuaddressmode).",
    "GPUSamplerDescriptor#addressModeV": "Specifies the addressing mode for the V coordinate of the texture. This determines how texture coordinates are handled when they extend beyond the bounds of the texture. The default value is `GPUAddressMode.CLAMP_TO_EDGE`.\n\nFor more details, refer to the [WebGPU specification on GPUAddressMode](https://www.w3.org/TR/webgpu/#enumdef-gpuaddressmode).",
    "GPUSamplerDescriptor#addressModeW": "Specifies the addressing mode for the W coordinate of the texture. This determines how texture coordinates are handled when they extend beyond the bounds of the texture. The default value is `GPUAddressMode.CLAMP_TO_EDGE`.\n\nFor more details, refer to the [WebGPU specification on GPUAddressMode](https://www.w3.org/TR/webgpu/#enumdef-gpuaddressmode).",
    "GPUSamplerDescriptor#magFilter": "Specifies the filtering mode used when the sampled area is smaller than or equal to one texel. The default value is `GPUFilterMode.NEAREST`.\n\nFor more details, refer to the [WebGPU specification on GPUFilterMode](https://www.w3.org/TR/webgpu/#enumdef-gpufiltermode).",
    "GPUSamplerDescriptor#minFilter": "Specifies the filtering mode used when the sampled area is larger than one texel. The default value is `GPUFilterMode.NEAREST`.\n\nFor more details, refer to the [WebGPU specification on GPUFilterMode](https://www.w3.org/TR/webgpu/#enumdef-gpufiltermode).",
    "GPUSamplerDescriptor#mipmapFilter": "Specifies the filtering mode used when sampling between mipmap levels. The default value is `GPUMipmapFilterMode.NEAREST`.\n\nFor more details, refer to the [WebGPU specification on GPUMipmapFilterMode](https://www.w3.org/TR/webgpu/#enumdef-gpumipmapfiltermode).",
    "GPUSamplerDescriptor#lodMinClamp": "Specifies the minimum level of detail (LOD) used internally when sampling a texture. The default value is `0.0`.\n\nFor more details, refer to the [WebGPU specification on levels of detail](https://www.w3.org/TR/webgpu/#levels-of-detail).",
    "GPUSamplerDescriptor#lodMaxClamp": "Specifies the maximum level of detail (LOD) used internally when sampling a texture. The default value is `32.0`.\n\nFor more details, refer to the [WebGPU specification on levels of detail](https://www.w3.org/TR/webgpu/#levels-of-detail).",
    "GPUSamplerDescriptor#compare": "Specifies the comparison function used by a comparison sampler. When provided, the sampler will be a comparison sampler with the specified `GPUCompareFunction`. Comparison samplers may use filtering, but the sampling results will be implementation-dependent and may differ from the normal filtering rules.\n\nFor more details, refer to the [WebGPU specification on GPUCompareFunction](https://www.w3.org/TR/webgpu/#enumdef-gpucomparefunction).",
    "GPUSamplerDescriptor#maxAnisotropy": "Specifies the maximum anisotropy value clamp used by the sampler. Anisotropic filtering is enabled when `maxAnisotropy` is greater than 1 and the implementation supports it. The default value is `1`.\n\nFor more details, refer to the [WebGPU specification on anisotropic filtering](https://www.w3.org/TR/webgpu/#dom-gpusamplerdescriptor-maxanisotropy).",
    "GPUTexelCopyTextureInfo": "Represents the information about a texture source or destination for a texel copy operation. This interface describes the sub-region of a texture that spans one or more contiguous texture subresources at the same mip-map level.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#gputexelcopytextureinfo).",
    "GPUTexelCopyTextureInfo#texture": "The texture to copy to or from. This is a required field and must be specified.\n\n**Type:** GPUTexture",
    "GPUTexelCopyTextureInfo#mipLevel": "The mip-map level of the texture to copy to or from. This field defaults to `0` if not specified.\n\n**Type:** GPUIntegerCoordinate\n\n**Default Value:** 0",
    "GPUTexelCopyTextureInfo#origin": "Defines the origin of the copy, which is the minimum corner of the texture sub-region to copy to or from. Together with `copySize`, this defines the full copy sub-region. This field defaults to `{}` if not specified.\n\n**Type:** GPUOrigin3D\n\n**Default Value:** `{}` (an empty GPUOrigin3D object)",
    "GPUTexelCopyTextureInfo#aspect": "Defines which aspects of the texture to copy to or from. This field defaults to `all` if not specified.\n\n**Type:** GPUTextureAspect\n\n**Default Value:** GPUTextureAspect.ALL",
    "GPURenderPassColorAttachment": "Represents a color attachment for a render pass in the WebGPU API. This interface defines the properties required to configure how colors are rendered and stored during a rendering operation.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dictdef-gpurenderpasscolorattachment).",
    "GPURenderPassColorAttachment#view": "A GPUTextureView describing the texture subresource that will be output to for this color attachment.\n\nThis property is required and must be a valid renderable texture view. The format of the view must be a color renderable format.",
    "GPURenderPassColorAttachment#depthSlice": "Indicates the depth slice index of the GPUTextureView that will be output to for this color attachment when the view's dimension is \"3d\".\n\nThis property is optional and must only be provided if the GPUTextureView's dimension is \"3d\"",
    "GPURenderPassColorAttachment#resolveTarget": "A GPUTextureView describing the texture subresource that will receive the resolved output for this color attachment if the GPUTextureView is multisampled.\n\nThis property is optional and must only be provided if the GPUTextureView's sample count is greater than 1. The resolve target must have a sample count of 1.",
    "GPURenderPassColorAttachment#clearValue": "Indicates the value to clear the GPUTextureView to prior to executing the render pass.\n\nThis property is optional and defaults to {r: 0, g: 0, b: 0, a: 0} if not provided. It is ignored if the loadOp is not \"clear\". The components of clearValue are converted to a texel value of the texture format matching the render attachment.",
    "GPURenderPassColorAttachment#loadOp": "Indicates the load operation to perform on the GPUTextureView prior to executing the render pass.\n\nThis property is required and specifies how the contents of the view should be handled before rendering. It can be one of the following values: \"clear\", \"load\", or \"dont-care\".",
    "GPURenderPassColorAttachment#storeOp": "The store operation to perform on the GPUTextureView after executing the render pass.\n\nThis property is required and specifies how the contents of the view should be handled after rendering. It can be one of the following values: \"store\", or \"dont-store\"",
    "GPURenderPipeline": "A [GPURenderPipeline](https://www.w3.org/TR/webgpu/#gpurenderpipeline) is a type of pipeline that controls the vertex and fragment shader stages. It can be used in both [GPURenderPassEncoder] and [GPURenderBundleEncoder].\n\nThis interface extends [GPUObjectBase](https://www.w3.org/TR/webgpu/#gpuobjectbase), [GPUPipelineBase](https://www.w3.org/TR/webgpu/#gpupipelinebase), and implements [AutoCloseable](https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-auto-closeable/) to manage resource lifecycle.\n\n### Render Pipeline Inputs\n- **Bindings**: According to the given [GPUPipelineLayout].\n- **Vertex and Index Buffers**: Described by [GPUVertexState](https://www.w3.org/TR/webgpu/#dictdef-gpuvertexstate).\n- **Color Attachments**: Described by [GPUColorTargetState](https://www.w3.org/TR/webgpu/#dictdef-gpucolortargetstate).\n- **Depth-Stencil Attachment** (optional): Described by [GPUDepthStencilState](https://www.w3.org/TR/webgpu/#dictdef-gpudepthstencilstate).",
    "GPUDebugCommandsMixin": "The `GPUDebugCommandsMixin` interface provides methods to apply debug labels to groups of commands or insert a single label into the command sequence. This is useful for debugging and profiling purposes, allowing developers to create a hierarchy of labeled commands that can be visualized in browser developer tools.\n\nDebug groups can be nested to create a hierarchy of labeled commands. These groups must be well-balanced, meaning every `pushDebugGroup` call must have a corresponding `popDebugGroup` call. Like [object labels](https://www.w3.org/TR/webgpu/#dom-gpuobjectbase-label), these labels have no required behavior but may be shown in error messages and browser developer tools, and may be passed to native API backends.\n\nThis interface assumes the presence of `GPUObjectBase` and `GPUCommandsMixin` members on the same object. It must only be included by interfaces which also include those mixins.",
    "GPUDebugCommandsMixin#pushDebugGroup(groupLabel)": "Pushes a debug group onto the command buffer with the specified label.\n\n@param groupLabel The label for the debug group. This is a string that will be used to identify the group in debugging tools. @throws IllegalArgumentException if `groupLabel` is null or empty.",
    "GPUDebugCommandsMixin#popDebugGroup()": "Pops the topmost debug group from the command buffer.\n\nThis method must be called after a corresponding `pushDebugGroup` call to maintain a well-balanced hierarchy of debug groups. @throws IllegalStateException if there is no debug group to pop (i.e., the stack is empty).",
    "GPUDebugCommandsMixin#insertDebugMarker(markerLabel)": "Inserts a debug marker into the command buffer with the specified label.\n\nThis method is useful for inserting single labels at specific points in the command sequence, which can be helpful for debugging and profiling. @param markerLabel The label for the debug marker. This is a string that will be used to identify the marker in debugging tools. @throws IllegalArgumentException if `markerLabel` is null or empty.",
    "GPUAddressMode": "The `GPUAddressMode` enum defines how texture coordinates are handled outside the range [0.0, 1.0]. This enumeration is used to specify the addressing mode for sampling textures in WebGPU. For more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuaddressmode).\n\n**Possible values:**\n- `ClampToEdge`: Texture coordinates are clamped between 0.0 and 1.0, inclusive.\n- `Repeat`: Texture coordinates wrap to the other side of the texture.\n- `MirrorRepeat`: Texture coordinates wrap to the other side of the texture, but the texture is flipped when the integer part of the coordinate is odd.",
    "GPUAddressMode#ClampToEdge": "Texture coordinates are clamped between 0.0 and 1.0, inclusive. This means that any coordinate outside this range will be snapped to the nearest edge of the texture.",
    "GPUAddressMode#Repeat": "Texture coordinates wrap to the other side of the texture. This means that coordinates outside the range [0.0, 1.0] will be wrapped around to the opposite side of the texture.",
    "GPUAddressMode#MirrorRepeat": "Texture coordinates wrap to the other side of the texture, but the texture is flipped when the integer part of the coordinate is odd. This creates a mirroring effect as the coordinates wrap around.",
    "GPUBlendFactor": "The `GPUBlendFactor` enum defines how either a source or destination blend factor is calculated. This enum is used to specify the blending factors for color components in the rendering pipeline. For more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpublendfactor).",
    "GPUBlendOperation": "The `GPUBlendOperation` enum defines the algorithm used to combine source and destination blend factors in WebGPU. This is crucial for controlling how colors are blended during rendering operations.\n\nFor more details, refer to the [WebGPU specification on GPUBlendOperation](https://www.w3.org/TR/webgpu/#enumdef-gpublendoperation).",
    "GPUBufferBindingType": "Represents the type of binding for a buffer in WebGPU. This enum defines the possible types of buffer bindings that can be used when creating bind groups.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpubufferbindingtype).",
    "GPUBufferMapState": "The `GPUBufferMapState` enum represents the current mapping state of a GPU buffer. This enumeration is used to determine whether a buffer is unmapped, pending a mapping request, or currently mapped and accessible for reading or writing.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpubuffermapstate).",
    "GPUCompareFunction": "The `GPUCompareFunction` enum defines the possible comparison functions used in depth and stencil operations within WebGPU. These functions determine how values are compared during rendering processes, such as depth testing or stencil testing.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpucomparefunction).",
    "GPUCompareFunction#Never": "The `Never` comparison function ensures that no values pass the comparison test. This means that the test will always fail, regardless of the input values.",
    "GPUCompareFunction#Equal": "The `Equal` comparison function allows a provided value to pass the test if it is equal to the sampled value. This can be used in stencil testing to perform exact comparisons.",
    "GPUCompareFunction#LessEqual": "The `LessEqual` comparison function allows a provided value to pass the test if it is less than or equal to the sampled value. This is useful in depth testing for scenarios where equality should also allow the fragment to pass.",
    "GPUCompareFunction#Greater": "The `Greater` comparison function allows a provided value to pass the test if it is greater than the sampled value. This can be used in reverse depth testing scenarios.",
    "GPUCompareFunction#NotEqual": "The `NotEqual` comparison function allows a provided value to pass the test if it is not equal to the sampled value. This is useful in stencil testing for scenarios where inequality should allow the fragment to pass.",
    "GPUCompareFunction#GreaterEqual": "The `GreaterEqual` comparison function allows a provided value to pass the test if it is greater than or equal to the sampled value. This can be used in depth testing for scenarios where equality should also allow the fragment to pass.",
    "GPUCompareFunction#Always": "The `Always` comparison function ensures that all values pass the comparison test. This means that the test will always succeed, regardless of the input values.",
    "GPUCompilationMessageType": "Enum class representing the type of compilation message generated by the GPUShaderModule compiler. This enum is used to categorize messages as errors, warnings, or informational notices.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#gpucompilationmessagetype).",
    "GPUCullMode": "Represents the culling mode used in rasterization, specifying which faces of a primitive to discard during rendering.\\n\\nThis enum corresponds to the `GPUCullMode` defined in the [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpucullmode).\\n\\nThe possible values are:\\n- [None]: No culling is performed.\\n- [Front]: Front-facing triangles are culled.\\n- [Back]: Back-facing triangles are culled.",
    "GPUCullMode#None": "Specifies that no culling is performed. Both front-facing and back-facing triangles are rendered.\\n\\n**See also:**\\n- [WebGPU specification: `none`](https://www.w3.org/TR/webgpu/#dom-gpucullmode-none)",
    "GPUCullMode#Front": "Specifies that front-facing triangles are culled. Only back-facing triangles are rendered.\\n\\n**See also:**\\n- [WebGPU specification: `front`](https://www.w3.org/TR/webgpu/#dom-gpucullmode-front)",
    "GPUCullMode#Back": "Specifies that back-facing triangles are culled. Only front-facing triangles are rendered.\\n\\n**See also:**\\n- [WebGPU specification: `back`](https://www.w3.org/TR/webgpu/#dom-gpucullmode-back)",
    "GPUDeviceLostReason": "The `GPUDeviceLostReason` enum represents the reasons why a GPU device might be lost. This is crucial for handling errors and managing resources in WebGPU applications.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpudevicelostreason).",
    "GPUErrorFilter": "The `GPUErrorFilter` enum defines the types of errors that should be caught when calling [pushErrorScope]. This enum is used to specify which kinds of GPU errors are to be monitored within a particular scope.\n\nFor more details, refer to the [W3C WebGPU specification on GPUErrorFilter](https://www.w3.org/TR/webgpu/#enumdef-gpuerrorfilter).",
    "GPUErrorFilter#Validation": "Indicates that the error scope will catch a `GPUValidationError`. This is useful for catching errors related to validation failures in GPU operations.\n\nFor more details, refer to the [W3C WebGPU specification on GPUValidationError](https://www.w3.org/TR/webgpu/#gpuvalidationerror).",
    "GPUErrorFilter#OutOfMemory": "Indicates that the error scope will catch a `GPUOutOfMemoryError`. This is useful for catching errors related to memory allocation failures in GPU operations.\n\nFor more details, refer to the [W3C WebGPU specification on GPUOutOfMemoryError](https://www.w3.org/TR/webgpu/#gpuoutofmemoryerror).",
    "GPUErrorFilter#Internal": "Indicates that the error scope will catch a `GPUInternalError`. This is useful for catching internal errors that occur within the GPU implementation.\n\nFor more details, refer to the [W3C WebGPU specification on GPUInternalError](https://www.w3.org/TR/webgpu/#gpuinternalerror).",
    "GPUFeatureName": "The `GPUFeatureName` enum defines a set of feature names that identify specific functionalities available in WebGPU. Each feature name corresponds to an additional usage of WebGPU that would otherwise be invalid if the feature is not supported.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#gpufeaturename).",
    "GPUFilterMode": "Represents the filtering mode used for sampling textures. This enum defines two possible values: `Nearest` and `Linear`.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpufiltermode).",
    "GPUFrontFace": "The `GPUFrontFace` enum defines which polygons are considered front-facing by a [GPURenderPipeline](https://www.w3.org/TR/webgpu/#gpurenderpipeline). This is crucial for determining the visibility of polygons during rendering. For more details, refer to the [Polygon Rasterization section](https://www.w3.org/TR/webgpu/#polygon-rasterization) of the WebGPU specification.\n\n**Enum Values:**\n- `CCW`: Counter-clockwise winding order.\n- `CW`: Clockwise winding order.",
    "GPUFrontFace#CCW": "Specifies that polygons with vertices whose framebuffer coordinates are given in counter-clockwise order are considered front-facing. This is useful for determining the visibility of polygons during rendering.",
    "GPUFrontFace#CW": "Specifies that polygons with vertices whose framebuffer coordinates are given in clockwise order are considered front-facing. This is useful for determining the visibility of polygons during rendering.",
    "GPUIndexFormat": "Represents the format of index data used in GPU operations. This enumeration defines the possible types of indices that can be used when drawing primitives with the GPU.\n\nThe `GPUIndexFormat` enum is crucial for specifying how index data should be interpreted by the GPU. It determines the size and type of each index, which affects rendering performance and accuracy.\n\nFor more details, refer to the [WebGPU specification on GPUIndexFormat](https://www.w3.org/TR/webgpu/#enumdef-gpuindexformat).",
    "GPULoadOp": "Represents the operations that can be performed to load values into an attachment during a render pass.\n\nThis enum defines two possible operations: `Load` and `Clear`. These operations determine how the initial value for an attachment is handled at the beginning of a render pass. For more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuloadop).\n\n**See also:**\n- [GPULoadOp.Load]\n- [GPULoadOp.Clear]",
    "GPULoadOp#Load": "Loads the existing value for this attachment into the render pass.\n\nThis operation is used when you want to preserve the current contents of the attachment and use it as the starting point for the render pass. For more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpuloadop-load).",
    "GPULoadOp#Clear": "Loads a clear value for this attachment into the render pass.\n\nThis operation is used when you want to start with a cleared (typically zeroed or black) value for the attachment. On some GPU hardware, particularly mobile devices, using `Clear` can be more efficient because it avoids loading data from main memory into tile-local memory. For more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#dom-gpuloadop-clear).\n\n**Note:** It is recommended to use `Clear` in cases where the initial value doesn't matter, such as when the render target will be cleared using a skybox.",
    "GPUMipmapFilterMode": "Represents the filtering mode used for mipmapping in WebGPU. This enum defines two possible values: `Nearest` and `Linear`.\n\nFor more details, refer to the [WebGPU specification on GPUMipmapFilterMode](https://www.w3.org/TR/webgpu/#enumdef-gpumipmapfiltermode).",
    "GPUPowerPreference": "Represents the power preference for GPU operations. This enum is used to specify whether the application prefers low power consumption or high performance.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpupowerpreference).",
    "GPUPrimitiveTopology": "The `GPUPrimitiveTopology` enum defines the types of primitives that can be used in draw calls made with a [GPURenderPipeline](https://www.w3.org/TR/webgpu/#gpurenderpipeline). This enumeration specifies how vertices are interpreted to form geometric primitives during rendering. For more details, see the [Rasterization section](https://www.w3.org/TR/webgpu/#rasterization) of the WebGPU specification.",
    "GPUPrimitiveTopology#PointList": "Each vertex defines a point primitive. This is useful for rendering individual points, such as particles or markers.",
    "GPUPrimitiveTopology#LineList": "Each consecutive pair of two vertices defines a line primitive. This is useful for rendering lines, such as wireframes or outlines.",
    "GPUPrimitiveTopology#LineStrip": "Each vertex after the first defines a line primitive between it and the previous vertex. This is useful for rendering connected lines, such as polylines.",
    "GPUPrimitiveTopology#TriangleList": "Each consecutive triplet of three vertices defines a triangle primitive. This is the most common topology for rendering 3D models and scenes.",
    "GPUPrimitiveTopology#TriangleStrip": "Each vertex after the first two defines a triangle primitive between it and the previous two vertices. This is useful for rendering connected triangles, such as in terrain or mesh rendering.",
    "GPUQueryType": "Represents the type of query that can be performed using the WebGPU API. This enum defines two types of queries: occlusion and timestamp.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuquerytype).",
    "GPUSamplerBindingType": "Represents the type of sampler binding used in WebGPU. This enum defines how textures are sampled when bound to a pipeline.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpusamplerbindingtype).",
    "GPUSamplerBindingType#BindingNotUsed": "Indicates that no sampler binding is used. This can be useful for bindings that do not require sampling operations.",
    "GPUSamplerBindingType#Filtering": "Specifies that filtering is applied when sampling textures. This is typically used for mipmapping and anisotropic filtering.",
    "GPUSamplerBindingType#NonFiltering": "Indicates that no filtering is applied when sampling textures. This can be used for performance-critical applications where filtering is not required.",
    "GPUSamplerBindingType#Comparison": "Specifies that comparison sampling is used. This is typically employed for depth textures and shadow mapping.",
    "GPUStencilOperation": "Represents the operations that can be performed on the stencil buffer during rendering. This enum is used to specify how the stencil values are modified in a [render pass](https://www.w3.org/TR/webgpu/#dom-gpurenderpass).\n\nThe `GPUStencilOperation` enum defines several constants, each representing a different operation that can be applied to the stencil buffer. These operations control how the stencil test affects the stencil values during rendering.\n\n**See also:**\n- [WebGPU Specification: GPUStencilOperation](https://www.w3.org/TR/webgpu/#enumdef-gpustenciloperation)",
    "GPUStencilOperation#Keep": "Keeps the current stencil value unchanged. This operation does not modify the stencil buffer.",
    "GPUStencilOperation#Zero": "Sets the stencil value to `0`. This operation replaces the current stencil value with zero.",
    "GPUStencilOperation#Replace": "Sets the stencil value to the reference value specified in the [render state](https://www.w3.org/TR/webgpu/#dom-renderstate-stencilreference-slot). This operation replaces the current stencil value with the reference value.",
    "GPUStencilOperation#Invert": "Bitwise-inverts the current stencil value. This operation flips all the bits of the current stencil value.",
    "GPUStencilOperation#IncrementClamp": "Increments the current stencil value, clamping it to the maximum representable value of the depth-stencil attachment's stencil aspect. This operation increases the stencil value but ensures it does not exceed the maximum value.",
    "GPUStencilOperation#DecrementClamp": "Decrements the current stencil value, clamping it to `0`. This operation decreases the stencil value but ensures it does not go below zero.",
    "GPUStencilOperation#IncrementWrap": "Increments the current stencil value, wrapping it to zero if it exceeds the maximum representable value of the depth-stencil attachment's stencil aspect. This operation increases the stencil value and wraps around to zero if necessary.",
    "GPUStencilOperation#DecrementWrap": "Decrements the current stencil value, wrapping it to the maximum representable value of the depth-stencil attachment's stencil aspect if it goes below `0`. This operation decreases the stencil value and wraps around to the maximum value if necessary.",
    "GPUStorageTextureAccess": "Represents the access mode for a storage texture binding, indicating whether the texture can be read from, written to, or both. This enum is used to specify the intended usage of a texture in a GPU pipeline.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpustoragetextureaccess).",
    "GPUStorageTextureAccess#BindingNotUsed": "Indicates that the binding is not used. This value can be used when a texture binding is intentionally left unused in a pipeline.",
    "GPUStorageTextureAccess#WriteOnly": "Specifies that the texture can only be written to. This mode is useful for scenarios where the texture is used as an output target, such as render targets or storage textures.",
    "GPUStorageTextureAccess#ReadOnly": "Specifies that the texture can only be read from. This mode is suitable for textures that are used as input sources, such as samplers or storage textures that are read by shaders.",
    "GPUStorageTextureAccess#ReadWrite": "Specifies that the texture can be both read from and written to. This mode is used for textures that need to be updated and read within the same pipeline stage.",
    "GPUStoreOp": "Represents the operations that can be performed on the resulting value of a render pass for an attachment.\n\nThis enum defines two possible values: `Store` and `Discard`. These values determine whether the result of a render pass is stored or discarded. For more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpustoreop).",
    "GPUTextureAspect": "The `GPUTextureAspect` enum defines the set of aspects that can be accessed in a texture view. Each value corresponds to different combinations of color, depth, and stencil aspects.\n\nFor more details, refer to the [WebGPU specification on GPUTextureAspect](https://www.w3.org/TR/webgpu/#enumdef-gputextureaspect).",
    "GPUTextureDimension": "Represents the dimensionality of a texture in WebGPU. This enum defines three possible dimensions for textures: one-dimensional, two-dimensional, and three-dimensional.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gputexturedimension).",
    "GPUTextureDimension#OneD": "Specifies a texture that has one dimension, width. \"OneD\" textures cannot have mipmaps, be multisampled, use compressed or depth/stencil formats, or be used as a render target.",
    "GPUTextureDimension#TwoD": "Specifies a texture that has a width and height, and may have layers.",
    "GPUTextureDimension#ThreeD": "Specifies a texture that has a width, height, and depth. \"ThreeD\" textures cannot be multisampled, and their format must support 3D textures (all [plain color formats](https://www.w3.org/TR/webgpu/#plain-color-formats) and some [packed/compressed formats](https://www.w3.org/TR/webgpu/#packed-formats)).",
    "GPUTextureFormat": "The `GPUTextureFormat` enum defines various texture formats that can be used with the WebGPU API. Each format specifies how pixel data is stored and interpreted, including details such as color channels, bit depth, and compression methods.\n\nFor more information, refer to the [WebGPU specification on GPUTextureFormat](https://www.w3.org/TR/webgpu/#enumdef-gputextureformat).",
    "GPUTextureFormat#R8Unorm": "Represents an 8-bit unsigned normalized format. Each pixel component is stored as an 8-bit value, where 0 represents the minimum value and 255 represents the maximum value.",
    "GPUTextureFormat#R8Snorm": "Represents an 8-bit signed normalized format. Each pixel component is stored as an 8-bit value, where -128 represents the minimum value and 127 represents the maximum value.",
    "GPUTextureFormat#R8Uint": "Represents an 8-bit unsigned integer format. Each pixel component is stored as an 8-bit unsigned integer, ranging from 0 to 255.",
    "GPUTextureFormat#R8Sint": "Represents an 8-bit signed integer format. Each pixel component is stored as an 8-bit signed integer.",
    "GPUTextureFormat#R16Uint": "Represents a 16-bit unsigned integer format. Each pixel component is stored as a 16-bit unsigned integer.",
    "GPUTextureFormat#R16Sint": "Represents a 16-bit signed integer format. Each pixel component is stored as a 16-bit signed integer.",
    "GPUTextureFormat#R16Float": "Represents a 16-bit floating-point format. Each pixel component is stored as a 16-bit floating-point value.",
    "GPUTextureFormat#RG8Unorm": "Represents an 8-bit unsigned normalized format for two channels (red and green). Each channel is stored as an 8-bit value, where 0 represents the minimum value and 255 represents the maximum value.",
    "GPUTextureFormat#RG8Snorm": "Represents an 8-bit signed normalized format for two channels (red and green). Each channel is stored as an 8-bit value, where -128 represents the minimum value and 127 represents the maximum value.",
    "GPUTextureFormat#RG8Uint": "Represents an 8-bit unsigned integer format for two channels (red and green). Each channel is stored as an 8-bit unsigned integer, ranging from 0 to 255.",
    "GPUTextureFormat#RG8Sint": "Represents an 8-bit signed integer format for two channels (red and green). Each channel is stored as an 8-bit signed integer.",
    "GPUTextureFormat#R32Float": "Represents a 32-bit floating-point format. Each pixel component is stored as a 32-bit floating-point value.",
    "GPUTextureFormat#R32Uint": "Represents a 32-bit unsigned integer format. Each pixel component is stored as a 32-bit unsigned integer.",
    "GPUTextureFormat#R32Sint": "Represents a 32-bit signed integer format. Each pixel component is stored as a 32-bit signed integer.",
    "GPUTextureFormat#RG16Uint": "Represents a 16-bit unsigned integer format for two channels (red and green). Each channel is stored as a 16-bit unsigned integer.",
    "GPUTextureFormat#RG16Sint": "Represents a 16-bit signed integer format for two channels (red and green). Each channel is stored as a 16-bit signed integer.",
    "GPUTextureFormat#RG16Float": "Represents a 16-bit floating-point format for two channels (red and green). Each channel is stored as a 16-bit floating-point value.",
    "GPUTextureFormat#RGBA8Unorm": "Represents an 8-bit unsigned normalized format for four channels (red, green, blue, alpha). Each channel is stored as an 8-bit value, where 0 represents the minimum value and 255 represents the maximum value.",
    "GPUTextureFormat#RGBA8UnormSrgb": "Represents an 8-bit unsigned normalized format for four channels (red, green, blue, alpha) in sRGB color space. Each channel is stored as an 8-bit value, where 0 represents the minimum value and 255 represents the maximum value.",
    "GPUTextureFormat#RGBA8Snorm": "Represents an 8-bit signed normalized format for four channels (red, green, blue, alpha). Each channel is stored as an 8-bit value, where -128 represents the minimum value and 127 represents the maximum value.",
    "GPUTextureFormat#RGBA8Uint": "Represents an 8-bit unsigned integer format for four channels (red, green, blue, alpha). Each channel is stored as an 8-bit unsigned integer, ranging from 0 to 255.",
    "GPUTextureFormat#RGBA8Sint": "Represents an 8-bit signed integer format for four channels (red, green, blue, alpha). Each channel is stored as an 8-bit signed integer.",
    "GPUTextureFormat#BGRA8Unorm": "Represents an 8-bit unsigned normalized format for four channels (blue, green, red, alpha). Each channel is stored as an 8-bit value, where 0 represents the minimum value and 255 represents the maximum value.",
    "GPUTextureFormat#BGRA8UnormSrgb": "Represents an 8-bit unsigned normalized format for four channels (blue, green, red, alpha) in sRGB color space. Each channel is stored as an 8-bit value, where 0 represents the minimum value and 255 represents the maximum value.",
    "GPUTextureFormat#RGB10A2Uint": "Represents a packed 32-bit unsigned integer format for four channels (red, green, blue, alpha). The red, green, and blue channels are each 10 bits, and the alpha channel is 2 bits.",
    "GPUTextureFormat#RGB10A2Unorm": "Represents a packed 32-bit unsigned normalized format for four channels (red, green, blue, alpha). The red, green, and blue channels are each 10 bits, and the alpha channel is 2 bits.",
    "GPUTextureFormat#RG11B10Ufloat": "Represents a packed 32-bit unsigned floating-point format for three channels (red, green, blue). The red and green channels are each 11 bits, and the blue channel is 10 bits.",
    "GPUTextureFormat#RGB9E5Ufloat": "Represents a packed 32-bit unsigned floating-point format for three channels (red, green, blue) with a shared exponent. The red, green, and blue channels are each 9 bits, and the shared exponent is 5 bits.",
    "GPUTextureFormat#RG32Float": "Represents a 64-bit floating-point format for two channels (red, green). Each channel is stored as a 32-bit floating-point value.",
    "GPUTextureFormat#RG32Uint": "Represents a 64-bit unsigned integer format for two channels (red, green). Each channel is stored as a 32-bit unsigned integer.",
    "GPUTextureFormat#RG32Sint": "Represents a 64-bit signed integer format for two channels (red, green). Each channel is stored as a 32-bit signed integer.",
    "GPUTextureFormat#RGBA16Uint": "Represents a 64-bit unsigned integer format for four channels (red, green, blue, alpha). Each channel is stored as a 16-bit unsigned integer.",
    "GPUTextureFormat#RGBA16Sint": "Represents a 64-bit signed integer format for four channels (red, green, blue, alpha). Each channel is stored as a 16-bit signed integer.",
    "GPUTextureFormat#RGBA16Float": "Represents a 64-bit floating-point format for four channels (red, green, blue, alpha). Each channel is stored as a 16-bit floating-point value.",
    "GPUTextureFormat#RGBA32Float": "Represents a 128-bit floating-point format for four channels (red, green, blue, alpha). Each channel is stored as a 32-bit floating-point value.",
    "GPUTextureFormat#RGBA32Uint": "Represents a 128-bit unsigned integer format for four channels (red, green, blue, alpha). Each channel is stored as a 32-bit unsigned integer.",
    "GPUTextureFormat#RGBA32Sint": "Represents a 128-bit signed integer format for four channels (red, green, blue, alpha). Each channel is stored as a 32-bit signed integer.",
    "GPUTextureFormat#Stencil8": "Represents an 8-bit stencil format. This format is used for storing stencil values in depth-stencil textures.",
    "GPUTextureFormat#Depth16Unorm": "Represents a 16-bit unsigned normalized depth format. This format is used for storing depth values in depth textures.",
    "GPUTextureFormat#Depth24Plus": "Represents a 24-bit or 32-bit unsigned normalized depth format. This format is used for storing depth values in depth textures.",
    "GPUTextureFormat#Depth24PlusStencil8": "Represents a combined 24-bit or 32-bit unsigned normalized depth and 8-bit stencil format. This format is used for storing both depth and stencil values in depth-stencil textures.",
    "GPUTextureFormat#Depth32Float": "Represents a 32-bit floating-point depth format. This format is used for storing high-precision depth values in depth textures.",
    "GPUTextureFormat#Depth32FloatStencil8": "Represents a combined 32-bit floating-point depth and 8-bit stencil format. This format is used for storing both high-precision depth and stencil values in depth-stencil textures.",
    "GPUTextureFormat#BC1RGBAUnorm": "Represents a BC1 (DXT1) compressed format for RGBA textures with unsigned normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#BC1RGBAUnormSrgb": "Represents a BC1 (DXT1) compressed format for RGBA textures with unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#BC2RGBAUnorm": "Represents a BC2 (DXT3) compressed format for RGBA textures with unsigned normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#BC2RGBAUnormSrgb": "Represents a BC2 (DXT3) compressed format for RGBA textures with unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#BC3RGBAUnorm": "Represents a BC3 (DXT5) compressed format for RGBA textures with unsigned normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#BC3RGBAUnormSrgb": "Represents a BC3 (DXT5) compressed format for RGBA textures with unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#BC4RUnorm": "Represents a BC4 compressed format for R textures with unsigned normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#BC4RSnorm": "Represents a BC4 compressed format for R textures with signed normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#BC5RGUnorm": "Represents a BC5 compressed format for RG textures with unsigned normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#BC5RGSnorm": "Represents a BC5 compressed format for RG textures with signed normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#BC6HRGBUfloat": "Represents a BC6H compressed format for RGB textures with unsigned floating-point values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#BC6HRGBFloat": "Represents a BC6H compressed format for RGB textures with floating-point values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#BC7RGBAUnorm": "Represents a BC7 compressed format for RGBA textures with unsigned normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#BC7RGBAUnormSrgb": "Represents a BC7 compressed format for RGBA textures with unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ETC2RGB8Unorm": "Represents an ETC2 compressed format for RGB textures with unsigned normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ETC2RGB8UnormSrgb": "Represents an ETC2 compressed format for RGB textures with unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ETC2RGB8A1Unorm": "Represents an ETC2 compressed format for RGB textures with 1-bit alpha channel and unsigned normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ETC2RGB8A1UnormSrgb": "Represents an ETC2 compressed format for RGB textures with 1-bit alpha channel and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ETC2RGBA8Unorm": "Represents an ETC2 compressed format for RGBA textures with unsigned normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ETC2RGBA8UnormSrgb": "Represents an ETC2 compressed format for RGBA textures with unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#EACR11Unorm": "Represents an EAC compressed format for R textures with 11-bit unsigned normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#EACR11Snorm": "Represents an EAC compressed format for R textures with 11-bit signed normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#EACRG11Unorm": "Represents an EAC compressed format for RG textures with 11-bit unsigned normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#EACRG11Snorm": "Represents an EAC compressed format for RG textures with 11-bit signed normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC4x4Unorm": "Represents an ASTC compressed format for textures with 4x4 block size and unsigned normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC4x4UnormSrgb": "Represents an ASTC compressed format for textures with 4x4 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC5x4Unorm": "Represents an ASTC compressed format for textures with 5x4 block size and unsigned normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC5x4UnormSrgb": "Represents an ASTC compressed format for textures with 5x4 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC5x5Unorm": "Represents an ASTC compressed format for textures with 5x5 block size and unsigned normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC5x5UnormSrgb": "Represents an ASTC compressed format for textures with 5x5 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC6x5Unorm": "Represents an ASTC compressed format for textures with 6x5 block size and unsigned normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC6x5UnormSrgb": "Represents an ASTC compressed format for textures with 6x5 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC6x6Unorm": "Represents an ASTC compressed format for textures with 6x6 block size and unsigned normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC6x6UnormSrgb": "Represents an ASTC compressed format for textures with 6x6 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC8x5Unorm": "Represents an ASTC compressed format for textures with 8x5 block size and unsigned normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC8x5UnormSrgb": "Represents an ASTC compressed format for textures with 8x5 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC8x6Unorm": "Represents an ASTC compressed format for textures with 8x6 block size and unsigned normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC8x6UnormSrgb": "Represents an ASTC compressed format for textures with 8x6 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC8x8Unorm": "Represents an ASTC compressed format for textures with 8x8 block size and unsigned normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC8x8UnormSrgb": "Represents an ASTC compressed format for textures with 8x8 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC10x5Unorm": "Represents an ASTC compressed format for textures with 10x5 block size and unsigned normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC10x5UnormSrgb": "Represents an ASTC compressed format for textures with 10x5 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC10x6Unorm": "Represents an ASTC compressed format for textures with 10x6 block size and unsigned normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC10x6UnormSrgb": "Represents an ASTC compressed format for textures with 10x6 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC10x8Unorm": "Represents an ASTC compressed format for textures with 10x8 block size and unsigned normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC10x8UnormSrgb": "Represents an ASTC compressed format for textures with 10x8 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC10x10Unorm": "Represents an ASTC compressed format for textures with 10x10 block size and unsigned normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC10x10UnormSrgb": "Represents an ASTC compressed format for textures with 10x10 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC12x10Unorm": "Represents an ASTC compressed format for textures with 12x10 block size and unsigned normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC12x10UnormSrgb": "Represents an ASTC compressed format for textures with 12x10 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC12x12Unorm": "Represents an ASTC compressed format for textures with 12x12 block size and unsigned normalized values. This format is used for texture compression in WebGPU.",
    "GPUTextureFormat#ASTC12x12UnormSrgb": "Represents an ASTC compressed format for textures with 12x12 block size and unsigned normalized values in sRGB color space. This format is used for texture compression in WebGPU.",
    "GPUTextureSampleType": "Represents the sample type for textures in WebGPU. This enum defines the possible formats that a texture can have, which determines how the texture data is sampled and interpreted.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gputexturesampletype).",
    "GPUTextureSampleType#BindingNotUsed": "Indicates that the binding is not used. This value is typically used when a texture binding is not required for a particular operation.",
    "GPUTextureSampleType#Float": "Specifies that the texture samples are in floating-point format. This is commonly used for high dynamic range (HDR) rendering and other effects that require precise color representation.",
    "GPUTextureSampleType#UnfilterableFloat": "Specifies that the texture samples are in an unfilterable floating-point format. This format is used when the texture data should not be filtered (e.g., for depth textures or other specialized uses).",
    "GPUTextureSampleType#Depth": "Specifies that the texture samples are in depth format. Depth textures are used for depth buffering and shadow mapping, where the depth information is stored in the texture.",
    "GPUTextureSampleType#Sint": "Specifies that the texture samples are in signed integer format. This format is used for textures that store signed integer data, such as normal maps or other specialized textures.",
    "GPUTextureSampleType#Uint": "Specifies that the texture samples are in unsigned integer format. This format is used for textures that store unsigned integer data, such as stencil buffers or other specialized textures.",
    "GPUTextureViewDimension": "The `GPUTextureViewDimension` enum defines the possible dimensions for a texture view in WebGPU. This enumeration is used to specify how a texture should be interpreted when creating a texture view.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gputextureviewdimension).",
    "GPUVertexFormat": "The `GPUVertexFormat` enum defines the possible formats for vertex attributes in WebGPU. Each format specifies the data type, number of components, and byte size of the vertex attribute. This enumeration is crucial for configuring vertex buffers and ensuring compatibility with shader programs.\n\nFor more details, refer to the [WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexformat).",
    "GPUVertexStepMode": "The `GPUVertexStepMode` enum defines the step mode that configures how an address for vertex buffer data is computed, based on the current vertex or instance index.\n\nThis enumeration is used to specify whether the vertex buffer data should be stepped per vertex or per instance. It is crucial for configuring vertex input in GPU rendering pipelines.\n\nFor more details, refer to the [W3C WebGPU specification](https://www.w3.org/TR/webgpu/#enumdef-gpuvertexstepmode).",
    "GPUVertexStepMode#VertexBufferNotUsed": "Indicates that the vertex buffer is not used. This mode is typically used when no vertex data needs to be fetched from a buffer.",
    "GPUVertexStepMode#Vertex": "The address is advanced by `arrayStride` for each vertex, and reset between instances.\n\nThis mode is used when the vertex data should be stepped per vertex. It is useful in scenarios where each vertex in a mesh has its own set of attributes.",
    "GPUVertexStepMode#Instance": "The address is advanced by `arrayStride` for each instance.\n\nThis mode is used when the vertex data should be stepped per instance. It is useful in scenarios where multiple instances of a mesh share the same vertex data but have different transformations or attributes.",
    "GPUBufferBindingType#BindingNotUsed": "Indicates that the buffer binding is not used. This value signifies that no data will be bound to this slot in the bind group.",
    "GPUBufferBindingType#Uniform": "Indicates that the buffer binding is used for uniform data. Uniform buffers are typically used to pass constant data to shaders, such as transformation matrices or global parameters.",
    "GPUBufferBindingType#Storage": "Indicates that the buffer binding is used for storage data. Storage buffers are used to read from and write to in shaders, allowing for more dynamic data manipulation.",
    "GPUBufferBindingType#ReadOnlyStorage": "Indicates that the buffer binding is used for read-only storage data. Read-only storage buffers allow shaders to read from them but not write to them, providing a way to pass large datasets efficiently.",
    "GPUCompareFunction#Less": "The `Less` comparison function allows a provided value to pass the test if it is less than the sampled value. This is commonly used in depth testing to determine if a fragment should be discarded based on its depth.",
    "GPUBlendFactor#Zero": "Specifies a blend factor where all RGBA components are set to (0, 0, 0, 0). This effectively disables the blending for the specified component.",
    "GPUBlendFactor#One": "Specifies a blend factor where all RGBA components are set to (1, 1, 1, 1). This fully enables the blending for the specified component.",
    "GPUBlendFactor#Src": "Specifies a blend factor where the RGBA components are taken from the source color. The values are (R<sub>src</sub>, G<sub>src</sub>, B<sub>src</sub>, A<sub>src</sub>).",
    "GPUBlendFactor#OneMinusSrc": "Specifies a blend factor where the RGBA components are the inverse of the source color. The values are (1 - R<sub>src</sub>, 1 - G<sub>src</sub>, 1 - B<sub>src</sub>, 1 - A<sub>src</sub>).",
    "GPUBlendFactor#SrcAlpha": "Specifies a blend factor where the RGBA components are taken from the source alpha. The values are (A<sub>src</sub>, A<sub>src</sub>, A<sub>src</sub>, A<sub>src</sub>).",
    "GPUBlendFactor#OneMinusSrcAlpha": "Specifies a blend factor where the RGBA components are the inverse of the source alpha. The values are (1 - A<sub>src</sub>, 1 - A<sub>src</sub>, 1 - A<sub>src</sub>, 1 - A<sub>src</sub>).",
    "GPUBlendFactor#Dst": "Specifies a blend factor where the RGBA components are taken from the destination color. The values are (R<sub>dst</sub>, G<sub>dst</sub>, B<sub>dst</sub>, A<sub>dst</sub>).",
    "GPUBlendFactor#OneMinusDst": "Specifies a blend factor where the RGBA components are the inverse of the destination color. The values are (1 - R<sub>dst</sub>, 1 - G<sub>dst</sub>, 1 - B<sub>dst</sub>, 1 - A<sub>dst</sub>).",
    "GPUBlendFactor#DstAlpha": "Specifies a blend factor where the RGBA components are taken from the destination alpha. The values are (A<sub>dst</sub>, A<sub>dst</sub>, A<sub>dst</sub>, A<sub>dst</sub>).",
    "GPUBlendFactor#OneMinusDstAlpha": "Specifies a blend factor where the RGBA components are the inverse of the destination alpha. The values are (1 - A<sub>dst</sub>, 1 - A<sub>dst</sub>, 1 - A<sub>dst</sub>, 1 - A<sub>dst</sub>).",
    "GPUBlendFactor#SrcAlphaSaturated": "Specifies a blend factor where the RGBA components are the minimum of the source alpha and the inverse of the destination alpha. The values are (min(A<sub>src</sub>, 1 - A<sub>dst</sub>), min(A<sub>src</sub>, 1 - A<sub>dst</sub>), min(A<sub>src</sub>, 1 - A<sub>dst</sub>), 1).",
    "GPUBlendFactor#Constant": "Specifies a blend factor where the RGBA components are taken from a constant color. The values are (R<sub>const</sub>, G<sub>const</sub>, B<sub>const</sub>, A<sub>const</sub>).",
    "GPUBlendFactor#OneMinusConstant": "Specifies a blend factor where the RGBA components are the inverse of a constant color. The values are (1 - R<sub>const</sub>, 1 - G<sub>const</sub>, 1 - B<sub>const</sub>, 1 - A<sub>const</sub>).",
    "GPUBlendFactor#Src1": "Specifies a blend factor where the RGBA components are taken from an additional source color (src1). The values are (R<sub>src1</sub>, G<sub>src1</sub>, B<sub>src1</sub>, A<sub>src1</sub>). This feature requires [dual-source blending](https://www.w3.org/TR/webgpu/#dom-gpufeaturename-dual-source-blending).",
    "GPUBlendFactor#OneMinusSrc1": "Specifies a blend factor where the RGBA components are the inverse of an additional source color (src1). The values are (1 - R<sub>src1</sub>, 1 - G<sub>src1</sub>, 1 - B<sub>src1</sub>, 1 - A<sub>src1</sub>). This feature requires [dual-source blending](https://www.w3.org/TR/webgpu/#dom-gpufeaturename-dual-source-blending).",
    "GPUBlendFactor#Src1Alpha": "Specifies a blend factor where the RGBA components are taken from an additional source alpha (src1). The values are (A<sub>src1</sub>, A<sub>src1</sub>, A<sub>src1</sub>, A<sub>src1</sub>). This feature requires [dual-source blending](https://www.w3.org/TR/webgpu/#dom-gpufeaturename-dual-source-blending).",
    "GPUBlendFactor#OneMinusSrc1Alpha": "Specifies a blend factor where the RGBA components are the inverse of an additional source alpha (src1). The values are (1 - A<sub>src1</sub>, 1 - A<sub>src1</sub>, 1 - A<sub>src1</sub>, 1 - A<sub>src1</sub>). This feature requires [dual-source blending](https://www.w3.org/TR/webgpu/#dom-gpufeaturename-dual-source-blending).",
    "GPUDeviceLostReason#Unknown": "Indicates that the reason for the GPU device being lost is unknown. This can occur due to unforeseen errors or issues not covered by other reasons.",
    "GPUDeviceLostReason#Destroyed": "Indicates that the GPU device was explicitly destroyed, typically through a call to `GPUDevice.destroy()`. This is a normal operation and should be handled gracefully.",
    "GPUDeviceLostReason#InstanceDropped": "Indicates that the GPU device was lost because the instance (e.g., the browser tab or worker) was dropped. This can happen if the user navigates away from a page or closes a tab.",
    "GPUDeviceLostReason#FailedCreation": "Indicates that the GPU device failed to be created. This can occur due to hardware limitations, driver issues, or other initialization problems."
}